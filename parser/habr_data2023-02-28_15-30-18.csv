post_id'post_id'title'meta_description'link'body'image'images
0'719468'Кофеиновая трилогия. Часть 3. Как не перепить и топ ошибочных мифов о вреде кофеина'Хрупкие кости, снижение либидо и зависимость похлеще, чем от кокаина. При этом, в комментариях под любой схожей статьей присутствует едва ли не Иисус, который превозносит чистоту и прелесть своей...'https://habr.com/ru/post/719468/'"Хрупкие кости, снижение либидо и зависимость похлеще, чем от кокаина. При этом, в комментариях под любой схожей статьей присутствует едва ли не Иисус, который превозносит чистоту и прелесть своей жизни после отказа от кофе. Есть ли смысл отказываться от кофеина, и в чем действительно риски его потребления?

На связи сообщество биохакеров RISE. Писать про кофе сложно, так как он проходит гематоэнцефалический барьер , комплексно воздействует на организм, работает с ЦНС и сосудами. Все это вместе открывает широкое поле для спекуляций. Первый материал рассказал про общие эффекты от употребления кофе . Второй сосредоточен на специфике потребления . Пришла пора взяться за мифы и легенды о черном напитке.

Кофе: наркотик или нет?

Нет, кофе не наркотик. Он не вызывает физиологическую зависимость и не вынуждает пить кофе только для того, чтобы снять симптомы его дефицита. Есть примеры кофеиновой мигрени, но они свидетельствуют о чрезмерном употреблении черного напитка. Как писал в прошлом материале , оптимальная дозировка: 1-3 мг кофеина на 1 кг веса. А то, что называют наркотической кофеиновой зависимостью — проблема в неумении увидеть разницу между толерантностью и адаптивностью человека к кофеину.

Толерантность, предрасположенность, адаптация. В чем между ними разница, и почему она так важна?

В контексте потребления кофе есть три отдельных фактора, которые индивидуальныдля каждого человека. Их определяет совокупность генетического наследия, социальной среды, и даже личных убеждений. Чаще всего, атрибуты этих факторов специально путают друг с другом, чтобы демонизировать кофе, или придать ему Божественного Эффекта. На практике всё немного проще.

Толерантность к кофе. Буквально означает, что организм человека перестает ощущать бодрость и вдохновение. Из-за этого, якобы, потребителю кофе придется постоянно повышать дозировку, чтобы получать тот же эффект. Вот только период выведения кофе из организма 8 часов. И 1-2 кружки в первой половине дня будут ощущаться так же бодро и на следующий день, и через неделю. Толерантность к кофе есть, но она и близко не такая сильная, как её стараются преподнести сторонники чистоты. Можно попробовать воздержаться от кофе на 3-5 дней. Эффект новой кружки будет достаточно сильным. Но он уже связан с адаптацией к кофе.

Адаптация к кофе. Сколько вам нужно выпить кофе, чтобы почувствовать его эффект? Кому-то достаточно капучино в 11 утра, чтобы бодрячком доработать до 6-ти вечера. А кто-то фигачит порцию эспрессо каждые 2 часа с момента пробуждения и до отбоя. Адаптация завязана как на толерантности, и связана с частотой потребления кофе, так и на личной предрасположенности.

Личная предрасположенность. Тот самый бэкграунд генетики, состояния ЦНС, образа жизни, съеденной пищи, возбужденности до того, как вы пили кофе и личного чувства тревоги. В этом материале речь шла о том , что кофе не стимулятор, а подкреплятор. Он усиливает то чувство, которое уже сейчас испытывает организм.

Эти три фактора характеризуют отношение конкретного человека к кофе. С учетом того, сколько он пьет кружек, сколько потребляет миллиграмм, какой у него организм и т.д. Само собой, если насильно пить по 5 кружек в день, ища ответ на вопрос как сохранить работоспособность , то повысишь только прибыль брендов кофе. Но, если вы держитесь своей оптимальной дозировки 1-3 мг на 1 кг веса, чувствуете эффект бодрости и вам это нравится, то ни о какой зависимости речь точно не идет.

Оптимальный ритуал потребления кофе

Наш организм развивается по принципу: выбери успешный шаблон поведения, и придерживайся его. Разные коучи и гуру успеха говорят о том, что нужно ходить разными дорогами на работу, бриться разными руками, пробовать что-то новое. Но есть и другая сторона. В материале про рост продуктивности предлагается простая концепция:

Автоматизируй все, что можешь. Переведи базовые потребности в рутину, дай организму стабильную основу, а в личном развитии креативь так, как душе угодно.

Это важно для потребления кофе, так как выработав свою систему ритуалов и рецепт идеального напитка, вам будет проще следить за уровнем своей продуктивности. Оптимальный рецепт выглядит так:

Если вы любите кофе в кофейнях, не стесняйтесь, спрашивайте баристу о том, какую порцию закладывают в кофемашину, что это за сорт, арабика или робуста. Это позволит для начала понять, сколько мг кофе вы уже сейчас потребляете. Можно ли увеличить дозировку, или стоит уже уменьшать.Если вы берете большой американо, особенно в стаканах под американский стиль — огромных таких, на 450 мл, то в них может быть 1000 мг кофе, что оптимально для человека весом в 300 кг!

Если готовите кофе дома, то почитайте больше о том, как проходит этот процесс. Сколько выделяется кофеина на вашу кружку. Как можно увеличить или сократить этот объем.

Пейте кофе спустя 2 часа после пробуждения. В противном случае, уже в 2-3 часа дня будете клевать носом. А выпитый кофе, даже за 8 часов до отбоя, все равно будет оказывать незначительное влияние на характер сна.

Утро оптимально начинать с легкой прохлады и солнечного света. Хотя бы на 5 минут. Если нет солнца, то 15-30. Особенно здорово собачникам, хочешь, не хочешь, а кортизол повышаешь. При чем кофе к утреннему подъему? Выпитый кофе рано утром не дает аденозину снизиться, и поэтому днем-вечером мозг тупит, а ты немного вялый. Отложи кофе на 2 часа с момента пробуждения и жизнь заиграет новыми красками.

Пьешь кофе — загрузись водичкой и электролитами. Особенно здорово, если есть бутылка минералочки. Один стакан до или после чашечки кофе, это просто топ! Поможет уберечь организм от перепада в балансе солей.

Мой личный рецепт: френч пресс на 150 мл, в нем 50 мг кофеина. Завариваю в 11:00 и в 14:00. Если день сложный, есть дедлайны и нужно поработать вечером, то добавляю еще в 19:00. Бывало и такое, что пил по 2 френч-пресса по 800 мл в день, По 100 мг кофеина на каждый. Но это опять очень «нежная» дозировка.

Последствия злоупотребления кофе, и как от них избавиться

https://www.youtube.com/watch?app=desktop&v=IhejOr-xxa4

Кофе истощает нервную систему, вызывает тревожность, панику, тремор… Все это симптомы того, что доза была слишком большой. Опять же, силу действия кофе можно снизить, если использовать даже молоко. Меньше кофе впитается в ЖКТ, да и вкус будет более нежным. Но для тех, кто не хочет идти на компромиссы есть отдельное средство!

L-теанин, и что делать, когда перепил кофе?

Это вечная связка на всех энергетических напитках, предтренировочных комплексах и некоторых сортах кофе. В чем-то это даже маркетинговый ход, так как L-теанин помогает проглотить больше кофе без побочного эффекта, а значит компания продаст большее количество драгоценного напитка. Вообще использовать L-теанин для снижения побочек кофе я не рекомендую, куда эффективнее определить свою дозировку и её придерживаться.

L-теанин очень схож с глутаматом и работает с теми же рецепторами, проходя через ГЭБ. Но, вот это достаточно крупное и комплексное исследование , показывает, что при попадании L-теанина в мозг, количество внеклеточного глутамата падает, а синтез ГАМК наоборот растет. То есть, L-теанин успокаивает ЦНС, и не дает мозгу перевозбудиться от кофеина.

Оптимальная доза L-теанина, которая убережет от кофейного перевозбуждения: 200-400 мг, однако я бы рекомендовал начать со 100-200 мг. При этом его можно принимать просто как пищевую добавку, наблюдая за результатами.

Если вы уже перепили кофе, то вам может помочь:

2-3 щепотки соли и запить их пол стаканом воды. Повторить процедуру через 15-20 минут. Если пить только воду, то тремор может усилиться, а с ним и рост тревоги.

Если дома есть капсула магния, речь о пищевой добавке, то она отлично дополнит соль. Но помните про пол стакана воды.

Сок лимона, в совокупности и перечисленными выше элементами, также поможет снять симптомы злоупотребления кофе.

Если есть возможность купить минеральную водичку, в частности Боржоми или аналоги, то это будет лучшим решением. Причем эти же рекомендации могут помочь при борьбе со стрессом и тревожностью .

L-теанин, как и приведенные методы, важны только в том случае, когда речь идет о переизбытке кофе, его чрезмерном воспитии и выходе за рамки возможностей организма. Во всех остальных случаях, кофе — это кофе. Хоть и сопровождаемый страшными мифами.

Популярные мифы о вреде кофеина

Тема кофе, как и других добавок, вроде Магния , окружена мифами и сомнениями. Но если от кофеина и есть побочные эффекты, то они — результат злоупотребления. А как на счет регулярного наслаждения черной жидкостью? Быть может, кофе разрушает наш организм с годами, просто делает это незаметно?

Вымывание кальция и снижение прочности костей. Кофеин действительно вымывает соли из организма, но важно то, из каких именно участков. Кофеин — диуретик, он выводит воду через почки. А с ней и все витамины и минералы, которые организм не успел получить. С другой стороны, если ваше питание сбалансировано, или вы используете мультивитаминные комплексы, опасаться нечего!

Кофе сужает сосуды сердца и головного мозга. Из-за этого мозг недополучает питательных веществ, а сердце изнашивается. На самом деле, кофе расслабляет сосуды сердца. А сужение сосудов мозга компенсируется ростом активности за счет повышенного тока крови. А также за счет того, что активно синтезируются два брата: дофамин и норадреналин.

Кофе снижает тестостерон у мужчин и эстроген у женщин. Это крайне незначительная корреляция, и связана она не с гормонами, а с белком глобулином.

Глобулин связывает половые гормоны в кровотоке, не давая им оказывать свой прямой эффект. Кофеин крайне незначительно повышает выработку глобулина. При этом, если вы используете кофеин как предтрен или пьете перед пешей прогулкой на работу, ваши половые гормоны, из-за физической активности, будут выделяться куда интенсивнее, чем глобулин.

Вреден ли кофе, как его описывают в «страшилках»?

Эспрессо под микроскопом намекает, что кофе — это золото)

Кофе — это инструмент. Иногда он действует мощно и поднимает эффективность. Иногда вызывает только тревогу и спазмы в ЖКТ. Ведь не существует идеальной таблетки для продуктивности или повышения эффективности, и все познается методом проб и ошибок.

Если в тема биохакинга интересна и хотите чаще читать подобный контент, то можете подписаться на наш паблик mind_rise в телеграме, будем рады."'https://habrastorage.org/getpro/habr/upload_files/343/3a0/378/3433a0378968787719b3a3059b551801.png'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
1'719466'Настройка кластера K8S на 3 хостах CentOS'Друзья, привет! Как-то томным осеннем вечером взбрело мне в голову начать изучать Kubernetes. Прочитал много разных статей и литературы, и понял, что нужно приступать к опытам на живую. И для этого...'https://habr.com/ru/post/719466/'"Друзья, привет!

Как-то томным осеннем вечером взбрело мне в голову начать изучать Kubernetes. Прочитал много разных статей и литературы, и понял, что нужно приступать к опытам на живую. И для этого мне необходимо поднять кластер у себя локально на компьютере. Minikube использовать не хотел так как в реальности одноузлового кластера нигде не встретишь. Поэтому было решено развернуть его у себя локально на трех узлах с использованием VirtualBox. Но полностью рабочего гайда по настройке, без каких-либо подводных камней я так и не нашел. Поэтому пропустив через себя множество всяких статей, страницы официальной доки кубера и всякую литературу по нему, хочу поделиться с вами своим опытом настройки кластера. Не судите, пожалуйста, строго это моя первая статья и первый кластер K8S.

Настройка виртуалок

В качестве OS для наших узлов я выбрал CentOS 9. Скачиваем его с http://centos-mirror.rbc.ru/pub/centos/7.9.2009/isos/x86_64/ и выбираем минимальный образ CentOS-7-x86_64-Minimal-2009.iso

Далее настроим наши виртуальные машины (ВМ), на которых будет развернут кластер. Я буду делать это в VirtualBox версии 6.1.34 r150636 (https://www.virtualbox.org)

Создадим шаблонную ВМ с именем kube_node_template. И задаем ей 2Гб оперативы.

Дадим ему 10 ГБ места на диске.

Дадим ему 2 ядра

И установим адаптер сети

В разделе «Носители» нужно будет выбрать виртуальный привод. Здесь уже отображается файл виртуального диска, но он почти пустой, так как операционная система еще не была установлена. Поэтому для установки системы нужно будет выбрать ISO файл образа с операционной системой.

Нажмите на «Пусто», в правой части окна напротив пункта «Оптический привод» нажмите на кнопку с изображением диска, а затем в контекстном меню выберите пункт «Выбрать файл диска ». И выбираем свой скаченный iso файл CentOS-7-x86_64-Minimal-2009.iso.

Переходим к установке операционной системы и создания пользователя. Нажимаем ""Запустить"" нашу ВМ.

И выбираем Install CentOS 7

Создаем пользователей.

Задаю пароль для root и создаю пользователя kube_admin.

После того как наша ОС установится, отключим работу со swap памяти, так как K8S работу с ним не поддерживает. (Swap -это файл подкачки, механизм виртуальной памяти перемещающий отдельные фрагменты памяти из оперативной памяти на жёсткий диск, внешний накопитель, специально выделенный раздел или файл, тем самым выполняя своё предназначение и освобождая оперативную память для других активных фрагментов памяти.)

Проверим что он есть командой SUDO SWAPON -S а затем отключим его SUDO SWAPOFF -A

И сделаем так чтобы при перезагрузке системы он опять не включился. В sudo vi /etc/fstab комментируем последнюю строку

После чего для применения настроек делаем ребут системы и проверяем sudo shutdown -r now

Далее включим ethernet adapter. Для этого отредактируем файл sudo vi /etc/sysconfig/network-scripts/ifcfg-enp0s3 и включим ONBOOT=yes

Сделаем рестрат sudo shutdown -r now и проверим командой ip addr

Далее мы из нашего шаблона создадим 3 ВМ, которые будут нашими нодами кластера. Одна будет мастером и две воркер. Выбираем в VirtualBox клонировать. Указываю имя и в политике MAC-адреса выбираем сгенерировать новый MAC

Получилось 3 виртуалки

Запускаем их. Далее нам необходимо сделать статические IP для наших ВМ. Для этого нужно отредактировать файлы ifcfg-enp0s3 в каталоге sudo vi /etc/sysconfig/network-scripts/ifcfg-enp0s в ipaddr указываем нужный нам ip

Выполняем ребут сервера sudo shutdown -r now и проверим командой ip addr что IP адресс для адаптера enp0s3 изменился на указанный нами в конфиге

Делаем это на всех наших ВМ кластер, только указываем другой IPADDR.

Теперь для удобства мы можем подклюичться к нашим ВМ машинам по SSH. Я буду делать это через MobaXterm (https://mobaxterm.mobatek.net) это также можно сделать через обычную командную строку вашего компьютера. Но я привык к MOBA.

Жмем создать сессию и указываем IP адрес ВМ

Переименуем наши хосты чтобы в дальнейшем не путаться (пример для мастера). Для этого в sudo vi /etc/hostname указываем имя нашей ноды. В данном случае это master

Добавим все наши хосты в файлик /etc/hosts, чтобы можно было обращаться к нашим хостам по имени узла

Делаем ребут сервера и проверяем (Ну или можно перезапустить службу sudo systemctl restart systemd-hostnamed но нужно будет перезайти в виртуалку). Проверяем чьл поменялось имя машины с localhost на master и можно сделать пинг по имени машины например worker2

Теперь необходимо открыть следующий список TCP-портов в брандмауре firewalld. Проверить что он запущен можно с помощью sudo systemctl status firewalld.service. Проверить список открытых портов sudo firewall-cmd --list-all

На мастер ноде откроем следующие порты и перезапустим службу firewalld. Чтобы это правило действовало постоянно добавьте –permanent

sudo firewall-cmd --permanent --add-port=6443/tcp sudo firewall-cmd --permanent --add-port=2379-2380/tcp sudo firewall-cmd --permanent --add-port=10250/tcp sudo firewall-cmd --permanent --add-port=10251/tcp sudo firewall-cmd --permanent --add-port=10252/tcp sudo firewall-cmd --permanent --add-port=10255/tcp sudo firewall-cmd --permanent --add-port=8472/udp sudo firewall-cmd --add-masquerade --permanent sudo firewall-cmd --permanent --add-port=30000-32767/tcp

И рестартуем службу sudo systemctl restart firewalld

Проверяем sudo firewall-cmd --list-all

На воркерах открываем следующие и также ребутаем службу.

sudo firewall-cmd --permanent --add-port=10250/tcp sudo firewall-cmd --permanent --add-port=10255/tcp sudo firewall-cmd --permanent --add-port=8472/udp sudo firewall-cmd --permanent --add-port=30000-32767/tcp sudo firewall-cmd --add-masquerade --permanent

Отключим SELinux. Для этого в sudo vi /etc/sysconfig/selinux нужно указать disabled

Также для K8S необходимо чтобы все пакеты проходящие через сетевые мосты обрабатывались через iptables. Для этого необходимо установить переменную ядра net.bridge.bridge-nf-call-iptables=1:

sudo cat << EOF > /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables=1 EOF

И загрузим его в ядро командой sudo modprobe br_netfilter

И выполняем рестарт sudo sysctl --system

Для выкачивания пакетов из интернета нам необходимо сделать следующие настройки. В sudo vi /etc/resolv.conf добавив в него nameserver 8.8.8.8

А также в sudo vi /etc/sysconfig/network добавить NETWORKING=yes и GATEWAY=192.168.1.1

И выполняем рестарт сервера sudo shutdown -r now

Настройка master ноды

Устанавливаем containerd

sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo mkdir -p /etc/containerd containerd config default | sudo tee /etc/containerd/config.toml

Перезаупскаем службу

sudo systemctl enable containerd sudo systemctl start containerd sudo systemctl status containerd

Переходим к установке K8S

Добавим репозиторий кубера в пакетный менеджер:

sudo cat > tee /etc/yum.repos.d/kubernetes.repo << EOF [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF

Перезачитаем кэш yum sudo yum makecache fast

Переходим к настройке мастер узла:

sudo yum -y install kubelet kubeadm kubectl sudo systemctl enable kubelet.service sudo systemctl start kubelet.service sudo systemctl status kubelet.service

Ставим Flannel

Сетевой плагин Flannel настраивает сетевое взаимодействие между контейнерами.

sudo yum install wget sudo wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml grep -i network kube-flannel.yml

Далее запускаем инициализацию нашей мастер ноды с указанием подсети которую создал flannel 10.244.0.0/16

sudo kubeadm init --pod-network-cidr 10.244.0.0/16

Инициализация занимает несколько минут и результатом ее выполнения будет:

Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run ""kubectl apply -f [podnetwork].yaml"" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.1.100:6443 --token 1lbb8b.o2haph49cvjdc679 --discovery-token-ca-cert-hash sha256:b16ceb25ebf3b9f04e82c32310f2e98f0d755b9127cb85f225bff5cab495ee12

на мастер ноде выполним команды из строк 5-7. Таким образом мы скопируем конфигурационный файл в домашнюю директорию. Строка 19 это токен для подключения воркер узлов к мастеру.

Настраиваем воркеры

Настраиваем containerd и kubernetes также как и для мастер узла. После настройки используем наш токен из 19 строки. И затем проверяем что все наши ноды добавились и активны командой kubectl get nodes

Установка веб консоли K8S

На мастер ноде выполняем команду с помощью которой мы скачали файлик со всеми ресурсами для настройки UI

wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml

Дальше нам необходимо чтобы была возможность подключаться с нашего компьютера к кластеру через браузер. Нам нужно настроить ресурс Service. Добавляем type: NodePort и указываем любой порт nodePort в диапазоне 30000-32767.

kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 30555 selector: k8s-app: kubernetes-dashboard

После выполняем kubectl apply -f recommended.yaml В результате которого создаются все описанные в файле recommended.yaml ресурсы.

Проверяем что создалась наша служба (Service) с типом NodePort: kubectl get svc -n kubernetes-dashboard

Смотрим на какой ноде развернут наш pod для UI: kubectl get pods -o wide -n kubernetes-dashboard

В моем случае это worker2 у которого айпишник 192.168.1.52

Идем в браузер и проверяем https://192.168.1.52:30555

Теперь необходимо настроить админскую учетку. Для примера можно посмотреть тут https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md. Создадим файл sudo vi admin-user.yaml

apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard

И применим его kubectl apply -f admin-user.yaml

После создадим токен с помощью которого залогинимся в UI kubectl -n kubernetes-dashboard create token admin-user копируем его и заходим.

Готово: мы настроили свой кластер!"'https://habr.com/share/publication/719466/09b2f223cbe3c8e1b0375a3c51b3143b/'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
2'719260'Security Week 2309: безопасность голосовой биометрии'Журналисты издания Motherboard на прошлой неделе показали ( оригинальная статья , новость на Хабре) практическую атаку на систему аутентификации по голосу. Голосовую биометрию используют некоторые...'https://habr.com/ru/post/719260/'Журналисты издания Motherboard на прошлой неделе показали ( оригинальная статья новость на Хабре) практическую атаку на систему аутентификации по голосу. Голосовую биометрию используют некоторые банковские организации для идентификации клиентов, позвонивших в службу поддержки. Автор статьи Джозеф Кокс при помощи одного из сервисов генерации голосовых сообщений по образцу смог получить доступ к персональным данным собственной учетной записи в британском банке Lloyds Bank.Общение с голосовым помощником банка происходило следующим образом. Сначала автор статьи попросил его сообщить баланс на счете. Начался процесс аутентификации: Джозефу потребовалось указать дату рождения, а затем произнести фразу «мой голос — это мой пароль». После этого исследователь успешно авторизовался и мог, например, проверить список последних транзакций по счету. Все фразы в эксперименте произносил не человек: они генерировались с помощью AI-сервиса компании Eleven Labs.Эту атаку нельзя назвать принципиально новой. Еще в 2020 году у некой компании украли крупную сумму денег (35 миллионов долларов) при помощи сгенерированного голоса. Менеджеру в банке якобы позвонил клиент, гендиректор компании, которого он знал лично. Их общение перешло в электронную почту, и в итоге денежный перевод успешно отправился на счет мошенников. Эксперимент издания Motherboard показывает, что подобная атака больше не требует особой подготовки, а главное — что распространенные системы идентификации по голосу легко «взламываются» при помощи общедоступных инструментов.Хотя биометрия делает нашу жизнь проще и регулярно применяется для работы с финансами (например, для оплаты покупок телефоном после идентификации по отпечатку пальца), у нее есть фундаментальный недостаток. Если биометрические данные смогут подделать, их не получится сменить, как обычный пароль. Эксперимент показал, что для доступа к чувствительным банковским данным аутентификации по голосу явно недостаточно, а дополнительная проверка с помощью даты рождения не особо усложняет потенциальную атаку. Что касается Eleven Labs, то после ряда инцидентов, в которых ее услуги применили для создания фейковых голосовых записей от имени известных личностей, компания ввела дополнительные ограничения на использование сервиса. Что, конечно же, никак не решает фундаментальную проблему — побочный эффект развития новых технологий.Вслед за Apple компания Samsung вводит защиту от атак типа zero-click во встроенном мессенджере. Фича Samsung Message Guard доступна в смартфонах серии S23. Технических деталей не приводится, говорится только о некоем сканировании вложений (графических файлов) на наличие вредоносного кода. Предложенное в прошлом году решение такой же проблемы от Apple несколько отличается: режим Lockdown Mode урезает функциональность смартфона с целью не допустить эксплуатации новых уязвимостей.«Лаборатория Касперского» публикует отчет об эволюции мобильных угроз за 2022 год. В другой публикации описываются фишинговые атаки на пользователей Telegram с помощью поддельных веб-версий мессенджера. А в этой статье описываются эксперименты с ботом ChatGPT на тему информационной безопасности. Среди результатов: ChatGPT не смог определить известное вредоносное ПО по его хешу, но корректно распознал вредоносные процессы, когда ему показали список задач с зараженной системы.Тем временем под видом «десктопного клиента ChatGPT» в Сети распространяется вредоносное программное обеспечение.Издание Bleeping Computer рассказывает о любопытном методе идентификации читеров в игре Dota 2. Разработчик игры, компания Valve, создала «ханипот», который помог идентифицировать тех, кто использует сторонние инструменты для доступа к технической информации. Если говорить точнее, в клиенте для многопользовательской игры были размещены блоки данных, к которым честный игрок никогда не обращается. Запросы к ним фиксировались, что в итоге привело к бану 40 тысяч игроков.'https://habr.com/share/publication/719260/274f88009a06915431a7ae65b8208960/'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
3'719438'Как экспертиза в области мониторинга событий ИБ помогает создавать качественные продукты. Часть 2'Друзья, всем привет. Недавно мы анонсировали серию публикаций о детектировании атак (attack detection) и тех вызовах, c которыми сталкиваются пользователи средств защиты. В первой статье этого цикла...'https://habr.com/ru/post/719438/'"Друзья, всем привет. Недавно мы анонсировали серию публикаций о детектировании атак (attack detection) и тех вызовах, c которыми сталкиваются пользователи средств защиты. В первой статье этого цикла материалов мы уже раскрыли секреты attack detection в привязке к SIEM-решениям (системам мониторинга событий ИБ и выявления инцидентов, security information and event management) и поделились лайфхаками, как облегчить работу операторов и автоматизировать часть рутинных задач. В этом материале — подробнее о том, как механизм построения цепочек запускаемых процессов в MaxPatrol SIEM помогает выявлять атакующих в сети.

Любая интерактивная атака злоумышленников на инфраструктуру компании не обойдется без запуска каких-либо процессов независимо от операционной системы, в которой у злоумышленника появилась возможность выполнять команды. Большое количество правил корреляции для выявления TTP, то есть tactics, techniques, and procedures (тактики, техники, процедуры), атакующих в MaxPatrol SIEM основано на событиях, в которых присутствуют данные о процессе.

Во время анализа сработок правил корреляции у специалистов SOC Positive Technologies много времени уходит на «раскручивание» цепочки запускаемых процессов (последовательности запуска связанных между собой процессов), так как для принятия решения, что это — true positive или false negative, — зачастую недостаточно данных только о родителе процесса. Это было основным фактором, побудившим нас, сотрудников PT Expert Security Center (PT ESC), разработать механизм, автоматизирующий построение цепочек запускаемых процессов на основе событий безопасности Windows EID 4688, Sysmon EID 1 и событий подсистемы аудита Linux (auditd). Мы придумали механизм, обогащающий любое скоррелированное событие, в котором есть информация о процессе, его полной цепочкой и записывающий данную информацию в отдельное поле таксономии.

Рис. 1. Пример нормализованного события запуска процессов Sysmon EID 1

Рис. 2. Пример нормализованного события подсистемы аудита Linux (auditd)

Это решение позволило не только разгрузить операторов SOC за счет автоматизации задач по «раскручиванию» цепочек процессов, но и расширить возможности продукта: новое поле таксономии с данными о цепочках процессов в некоторых случаях облегчает написание правил корреляции, используется для вайтлистинга , блэклистинга , применение моделей Machine learning (ML).

По собственному опыту работы с другими продуктами этого класса и по результатам анализа их возможностей могу сказать, что я пока нигде больше не встречал реализации подобной функциональности. Некоторые производители применяют визуализацию цепочек процессов при реагировании на инциденты, используя данные от своих же EDR -решений или расширения, которые анализируют соответствующие события из базы данных и визуализируют деревья процессов при необходимости (кстати, для MaxPatrol SIEM есть подобное расширение — найти его можно вот тут (см. рис. 3)). При активации механизма в MaxPatrol SIEM цепочки процессов строятся независимо от данных EDR или дополнительных расширений в режиме реального времени и без участия человека; с этими данными можно работать как с любым другим полем таксономии. Об этом поговорим дальше.

Рис. 3. Пример расширения для браузера, строящего дерево процессов по событиям из базы данных по запросу пользователя

Анализ атомарных сработок правил корреляции

В сработках правил корреляции нам, как правило, не хватало дополнительного контекста о цепочке процессов. Задача механизма построения цепочки запускаемых процессов состоит не в их визуализации как таковой для расследования, а в записи в отдельное поле таксономии для быстрого визуального анализа прямо из карточки события или практического применения этих данных в корреляциях, обогащениях и т. д.

Наличие в карточке события данных о цепочке процессов в разы сокращает время, необходимое операторам на понимание контекста сработки даже путем визуального анализа данных. Любая сработка правила корреляции в MaxPatrol SIEM, имеющая данные о процессе (имя процесса и его PID), будет обогащаться цепочкой запускаемых процессов независимо от типа события.

Рассмотрим несколько практических примеров обнаружения различных TTP, относящихся к данному разделу.

1. Discovery. Account Discovery. Пример сработки правила корреляции на рекогносцировку активности пользователей через взломанный сервер Exchange.

Рис. 4. Сработка правила корреляции на рекогносцировку активности пользователей с механизмом построения цепочек запускаемых процессов

2. Discovery. Remote System Discovery. Пример сработки правила корреляции на рекогносцировку контроллера домена, основанного на событии запуска процесса без данных о цепочке процессов, и та же сработка правила корреляции с данными о цепочке процессов.

Рис. 5. Сработка правила корреляции на рекогносцировку контроллера домена без механизма построения цепочек запускаемых процессов

Рис. 6. Сработка правила корреляции на рекогносцировку контроллера домена с механизмом построения цепочек запускаемых процессов

3. Discovery. System Network Configuration Discovery. Пример сработки правила корреляции на рекогносцировку конфигурации сетевого подключения в операционной системе Linux с механизмом построения цепочек запускаемых процессов.

Рис. 7. Сработка правила корреляции на рекогносцировку конфигурации сетевого адаптера с механизмом построения цепочек запускаемых процессов

4. Discovery. System Network Connections Discovery. Пример сработки правила корреляции после запуска пользователем вредоносного офисного документа.

Рис. 8. Сработка правила корреляции на рекогносцировку сетевых подключений с механизмом построения цепочек запускаемых процессов

Даже квалифицированному сотруднику потребуется немало времени для нахождения вредоносного процесса, который инициировал последующую активность, и сработки правил корреляции. Однако, имея в карточке события поля с цепочкой процессов, относящиеся к конкретной сработке, оператор MaxPatrol SIEM освободит себя от необходимости выяснять это.

Написание правил корреляции на основе данных о цепочке процесса

Для того чтобы учесть в корреляции цепочку из нескольких процессов, необходимо писать минимум два правила корреляции или использовать табличный список для записи временных данных. Благодаря наличию поля таксономии с данными о цепочке процесса, оператору не нужно будет писать дополнительные правила корреляции или использовать дополнительные табличные списки.

Рис. 9. Пример фильтра события в правиле корреляции, обнаруживающего аномальные цепочки запуска процессов, родителем которых является агент антивируса Kaspersky klnagent

Рис. 10. Пример фильтра события в правиле корреляции, обнаруживающего цепочку запуска процессов с утилитами веб-сервера

В данном случае хорошими кейсами являются правила, выявляющие аномальную активность процессов веб-серверов, и правила, выявляющие целевой фишинг через мессенджеры.

Особенности механизма построения цепочек процессов

Как будет выглядеть цепочка процесса, когда пользователем был запущен файл, загруженный через мессенджер или браузер? И как она будет выглядеть до процесса, если злоумышленнику удастся мигрировать в другой процесс и продолжить свою активность в нем?

При анализе сработок правил корреляции бывают случаи, когда с первого взгляда оператор может посчитать сработку false positive, но активность является нелегитимной. Рассмотрим два сценария.

Первый сценарий. Пользователю пришло фишинговое письмо, он перешел по ссылке, скачал и запустил вредоносный файл — у злоумышленника появилась возможность выполнять команды на зараженном компьютере. В случае, если какое-либо правило корреляции сработает на последующую активность данного вредоносного процесса, то цепочка до процесса будет начинаться от процесса explorer.exe. Однако разработанный нами механизм предусматривает такой сценарий и продолжает выстраивать цепочку процесса с момента загрузки файла из браузера.

Рис. 11. Пример построения цепочки процессов

Второй сценарий. Часто после успешного «пробива» узла злоумышленнику необходимо мигрировать в другой процесс для сохранения доступа на скомпрометированном компьютере или для сокрытия следов активности за счет работы внутри легитимного процесса. В случае если такая ситуация произошла, а после этого сработало правило на какую-либо последующую активность, то в цепочке процессов будет формироваться цепочка до процесса, в который произошла миграция. Разработанный нами механизм предусматривает и такие кейсы и строит всю цепочку процессов до момента миграции.

Рис. 12. Отображение процесса, в который мигрировал злоумышленник (в фигурных скобках)

После визуального анализа только по одному полю с цепочкой процессов можно сразу сделать вывод, что компьютер пользователя был скомпрометирован.

«Тюнинг» сработок правил корреляции

Данные о цепочке процесса можно использовать при осуществлении «тюнинга» системы — вайтлистинга. Иногда целесообразнее добавить в исключение цепочку процессов, вместо того чтобы писать регулярные выражения. А в случае, если цепочка процессов является вредоносной, ее можно добавить в блэклист. Подробнее о механизмах работы с исключениями в MaxPatrol SIEM мы рассказали тут и тут.

Рис. 13. Пример шаблона исключений для данных с цепочкой процесса

Надеюсь, что данный материал был полезен и вы найдете добавленному в продукт механизму свое применение. Мы будем продолжать знакомить вас с историями о том, как наша экспертиза помогает делать продукты еще более удобными для специалистов по ИБ. Так что следите за выходом новых материалов 😊

До новых встреч!

Автор: Алексей Потапов, эксперт отдела обнаружения атак, PT Expert Security Center"'https://habrastorage.org/getpro/habr/upload_files/a7f/528/aec/a7f528aecebc76786752f6227cdcb7bc.gif'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
4'719460'Современный способ глубокого клонирования объектов в JavaScript'Вы знали, что теперь в JavaScript есть нативный способ делать глубокие копии объектов? Это стало возможным с помощью функции structuredClone , встроенной в среду выполнения JavaScript: const...'https://habr.com/ru/post/719460/'"Вы знали, что теперь в JavaScript есть нативный способ делать глубокие копии объектов? Это стало возможным с помощью функции structuredClone , встроенной в среду выполнения JavaScript:

const calendarEvent = { title: ""Builder.io Conf"", date: new Date(123), attendees: [""Steve""] } // 😍 const copied = structuredClone(calendarEvent)

Вы заметили, что в этом примере мы скопировали не только объект, но и вложенный массив, и даже объект Date?

И код работает именно так, как мы и ожидали:

copied.attendees // [""Steve""] copied.date // Date: Wed Dec 31 1969 16:00:00 cocalendarEvent.attendees === copied.attendees // false

structuredClone может делать не только вышеперечисленное, но и также:

Клонировать бесконечно вложенные объекты и массивы.

Клонировать циклические ссылки.

Клонировать широкий спектр типов JavaScript, таких как: Date , Set , Map , Error , RegExp , ArrayBuffer , Blob , File , ImageData и многие другие .

Передавать любые передаваемые объекты .

Это безумие даже будет работать так, как мы и ожидали:

const kitchenSink = { set: new Set([1, 3, 3]), map: new Map([[1, 2]]), regex: /foo/, deep: { array: [ new File(someBlobData, 'file.txt') ] }, error: new Error('Hello!') } kitchenSink.circular = kitchenSink // ✅ Выполнено полное глубокое копирование const clonedSink = structuredClone(kitchenSink)

Почему бы просто не сделать object spread?

Важным отметить, что мы говорим о глубоком копировании. Если же нужно просто выполнить поверхностное копирование, то есть копирование без включения вложенных объектов или массивов, то можно просто выполнить spread объекта :

const simpleEvent = { title: ""Builder.io Conf"", } // ✅ нет вложенных объектов или массивов const shallowCopy = {...calendarEvent}

Или даже один из этих вариантов, если хотите:

const shallowCopy = Object.assign({}, simpleEvent) const shallowCopy = Object.create(simpleEvent)

Но как только появляются вложенные элементы, мы сталкиваемся с проблемой:

const calendarEvent = { title: ""Builder.io Conf"", date: new Date(123), attendees: [""Steve""] } const shallowCopy = {...calendarEvent} // 🚩 упс - мы добавили ""Bob"" и в копию и в воригинальное событие shallowCopy.attendees.push(""Bob"") // 🚩 упс - мы обновили дату копии и исходного события shallowCopy.date.setTime(456)

Как видно, мы не сделали полную копию этого объекта.

Вложенные дата и массив по-прежнему являются общей ссылкой для оригинала и «копии». Это может привести к проблеме – если мы захотим отредактировать их, думая, что обновляем только скопированный объект события календаря.

Почему не JSON.parse(JSON.stringify(x))?

На самом деле это отличный хак и на удивление производительный, но с некоторыми недостатками, которые устраняет structuredClone .

Возьмем для примера:

const calendarEvent = { title: ""Builder.io Conf"", date: new Date(123), attendees: [""Steve""] } // 🚩 JSON.stringify преобразовал дату в строку const problematicCopy = JSON.parse(JSON.stringify(calendarEvent))

Если вывести ProblematicCopy , мы получим:

{ title: ""Builder.io Conf"", date: ""1970-01-01T00:00:00.123Z"" attendees: [""Steve""] }

Мы хотели не этого. date должен быть не строкой, а объектом Date .

Это произошло потому, что JSON.stringify может обрабатывать только базовые объекты, массивы и примитивы. Любой другой тип может быть обработан непредсказуемым образом. Например, Dates преобразуются в string. Но Set просто преобразуется в {} .

Что-то JSON.stringify даже игнорирует – например, undefined или функции.

Скажем, если мы скопируем пример kitchenSink с помощью этого метода:

const kitchenSink = { set: new Set([1, 3, 3]), map: new Map([[1, 2]]), regex: /foo/, deep: { array: [ new File(someBlobData, 'file.txt') ] }, error: new Error('Hello!') } const veryProblematicCopy = JSON.parse(JSON.stringify(kitchenSink))

То мы получим:

{ ""set"": {}, ""map"": {}, ""regex"": {}, ""deep"": { ""array"": [ {} ] }, ""error"": {}, }

Фу!

И да, пришлось удалить циклическую ссылку, которая у нас изначально для этого была, поскольку JSON.stringify просто выдает ошибки, если встречается с одной из них.

Метод JSON.stringify удобен, в случае если наши требования соответствуют его возможностям. Однако с помощью StructuredClone можно сделать многое из того, чего не может JSON.stringify .

Почему не _.cloneDeep?

До сих пор распространенным решением этой проблемы была функция cloneDeep библиотеки Lodash.

Она действительно работает так, как ожидается:

import cloneDeep from 'lodash/cloneDeep' const calendarEvent = { title: ""Builder.io Conf"", date: new Date(123), attendees: [""Steve""] } // ✅ Все в порядке const clonedEvent = structuredClone(calendarEvent)

Но с одной оговоркой. Согласно данным работы расширения Import Cost в IDE, которое выводит вес в Кб всего, что я импортирую, эта функция занимает 17,4 Кб в сжатом виде (5,3 Кб в архиве):

Это предполагает, что вы импортируете только эту функцию. Если вместо этого импортировать более распространенным способом, не принимая в расчет, что tree shaking не всегда работает так, как ожидается, можно случайно импортировать до 25 Кб только для этой одной функции.

Хотя это и не станет концом света, в нашем случае это просто не нужно – не тогда, когда браузеры уже имеют встроенный structuredClone .

Что structuredClone не может клонировать

Функции

Иначе они вызовут исключение DataCloneError :

// 🚩 Ошибка! structuredClone({ fn: () => { } })

Узлы DOM

Также выбрасывают исключение DataCloneError :

// 🚩 Ошибка! structuredClone({ el: document.body })

Дескрипторы свойств, сеттеры и геттеры

Также не клонируются аналогичные метадата-подобные фичи.

К примеру, при использовании геттера клонируется результирующее значение, но не сама функция геттера (или любые другие метаданные свойства):

structuredClone({ get foo() { return 'bar' } }) // Становится: { foo: 'bar' }

Прототипы объектов

Не происходит обход цепочки прототипов. Поэтому в случае клонирования экземпляра MyClass клонированный объект больше не будет известен как экземпляр этого класса. Но все валидные свойства этого класса будут клонированы.

class MyClass { foo = 'bar' myMethod() { /* ... */ } } const myClass = new MyClass() const cloned = structuredClone(myClass) // Становится: { foo: 'bar' } cloned instanceof myClass // ложь

Полный список поддерживаемых типов

Все, что не входит в приведенный ниже список, клонировать нельзя:

JS Built-ins

Array , ArrayBuffer , Boolean , DataView , Date , Error types (указанные в списке ниже), Map , Object (но только простые объекты – например, из объектных литералов), примитивные типы (за исключением symbol – number , string , null , undefined , boolean , BigInt ), RegExp , Set , TypedArray

Error types (Ошибки типизации)

Error , EvalError , RangeError , ReferenceError , SyntaxError , TypeError , URIError

Web/API типы

AudioData , Blob , CryptoKey , DOMException , DOMMatrix , DOMMatrixReadOnly , DOMPoint , DomQuad , DomRect , File , FileList , FileSystemDirectoryHandle , FileSystemFileHandle , FileSystemHandle , ImageBitmap , ImageData , RTCCertificate , VideoFrame

Поддержка браузеров и сред выполнения

И здесь самое интересное – structuredClone поддерживается во всех основных браузерах, и даже в Node.js и Deno.

Правда, с одной оговоркой – поддержка Web Workers более ограничена:

Источник: MDN

Заключение

Мы долго этого ждали, и теперь у нас наконец-то есть structuredClone , благодаря которому глубокое клонирование объектов в JavaScript становится простым делом. Спасибо, Surma .

В заключение статьи приглашаем на открытое занятие «Прототипное наследование в JavaScript», которое состоится завтра вечером. На занятии мы разберемся, что такое прототипное наследование и как оно может помочь при разработке программ. В результате вы лучше поймете объектную модель Javascript и сможете писать ООП код с экономией памяти. Запись на урок открыта по ссылке."'https://habrastorage.org/getpro/habr/upload_files/7df/375/07a/7df37507a8a05df6239aa16d3f4d9fc7.png'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
5'719446'Ложь на собеседовании: ваше преимущество или риск?'Все мы с какой-то частотой ищем работу. Новая итерация — новое резюме, фокус на том, что сейчас нужно компаниям и рынку. К использованию “мы” в резюме под предлогом своего результата, кажется, уже...'https://habr.com/ru/post/719446/'"Все мы с какой-то частотой ищем работу. Новая итерация — новое резюме, фокус на том, что сейчас нужно компаниям и рынку.

К использованию “мы” в резюме под предлогом своего результата, кажется, уже привыкли все, но это было только начало. В целом, все объяснимо, если основная задача соискателя — привлечь внимание рекрутера по наличию ключевых слов или цифр в CV.

Но фантазии (читать как огромное желание найти хорошую работу) не заканчиваются в написании резюме. Ложь на собеседованиях встречается довольно часто, и не всегда она выявляется по щелчку пальцев. Заканчивая серию постов #ihateinterview, разберемся, какие лайфхаки помогают кандидатам в текущих реалиях находить работу быстрее.

Наиболее распространенные примеры лжи кандидатов при поиске работы:

1. Сменить возраст в резюме

Как правило, HR ставят фильтр по возрасту “не более 45 лет”, поэтому какой бы не был у вас опыт, ваше резюме может не появиться в поле выдачи. Зачем это делается: кто-то считает, что кандидату не хватит духа бодрости и заряженности, а все хотят видеть “горящие глаза”. Другие уверены, что кандидат просто не впишется в команду, а когда это поймет, сам покинет компанию.

Но поскольку дискриминация в любом ее виде запрещена, никто вам об этом не скажет. Тем не менее ситуация улучшается. 7-10 лет назад, цифра 40 была знаком для завершения карьеры в продуктовых командах, сейчас люди в таком возрасте делают крутые продукты и занимают ТОПовые позиции, к ним тянутся, они эксперты.

2. Сменить в резюме фамилию на “не русскую” для прохождения скрининга HR зарубежных компаний

Мы как HR можем сказать, что на уровне зарубежных компаний запрета на найм людей родом из России нет. Это только и только дополнительная подстраховка самих соискателей. Безусловно, никто не застрахован от дискриминации в любой сфере, но в текущих реалиях это не тренд, а единичные случаи.

Не путайте это с необходимым требованием наличия резидентства другой страны или территориальным нахождением человека.

3. Убрать лишний / менеджерский опыт работы в резюме

Зачастую такое решение основывается на частых отказах ввиду overqualified’а (уровня кандидата выше необходимого). Компании понимают риск того, что сотрудник может заскучать (непривычные и более легкие задачи, другой уровень влияния, на уровень ниже). Еще одна распространенная проблема — руководители не готовы брать более сильного кандидата или с идентичным уровнем из-за конкуренции. Это в корне неправильно, но очень редко, когда удается сломить психологию.

4. Добавить в резюме задачи, которых не делали сами

В ситуации, когда мастхэв требования — это 3 года коммерческой разработки и опыт работы с Angular (а не другими инструментами, фреймворками, Vue, например. При условии, что переход между ними быстрый и несложный), кандидаты добавляют в резюме необходимые данные, чтобы пройти скрининг HR. Объясняют они это тем, что задачи такого рода делали их коллеги, поэтому с легкостью смогут повторить это самостоятельно. Откуда уверенность? Они же наблюдали, кругозор появился, да и об ошибках наслышаны.

5. Добавить в резюме опыт работы / +1 грейд (на деле уровень junior, но в резюме как middle)

HR не проверяет технические навыки, а служит одним из интрументов-помощников для отсечения кандидатов, неподходящих по требованиям. Поскольку у всех критерии оценки различаются, а единого подхода к грейдированию нет, кандидаты пытаются любыми способами снова “проскочить” HR.

Так, встречаются случаи, когда при отсутствии коммерческого опыта работы, кандидаты уверенно рассказывают о 2 годах опыта работы в компании, опыте работы с конкретной задачей (например, уход от монолитной архитектуры к микросервисной), потому что именно этот опыт является основной причиной найма человека. Получается, человек похож на идеального кандидата, потому что по каждому критерию у него стоит галочка от рекрутера, и он попадает на техническое интервью к нанимающему менеджеру.

6. Добавить в резюме опыт работы менеджером (Lead)

Не все компании готовы рассматривать развитие из senior в Lead. А на рынке все еще продолжается тренд профессионального развития, а не горизонтального. Поэтому кандидаты смело приписывают опыт работы в роли руководителя, объясняя сами себе это тем, что по отдельности нет ничего сложного в выполнении базовых задач лида: декомпозиции задач, оценке сроков, коммуникации внутри команды (1to1, встречи, поддержка, развитие), найме. Рассматривают все это по отдельности, но не как комплексную роль и навык владения инструментами для решения конкретных проблем бизнеса. А если еще и за главного человек оставался, когда лид уходил в отпуск, то он точно уверен в себе и, конечно, же в коммерческом опыте управления командой.

7. Добавить в резюме опыт работы в престижной известной компании (Яндекс, например)

Некоторые работодатели в поисках специалистов высокого уровня, рассматривают кандидатов из определенных компаний, зная, что они нанимают людей исключительно с сильными навыками. Соответственно, наличие в резюме опыта работы в таких компаниях воспринимается как “кандидат senior уровня”. Таких людей хантят и идут им навстречу (предлагают уровень З.П. выше, готовы обсуждать финансовую поддержку, пакет бенефитов).

Основной риск даже не в том, что ваш новый потенциальный работодатель проверит, работали ли вы в этой компании или нет, а в том, что HR или нанимающий менеджер могут намного лучше знать специфику того же Яндекса, например, чем вы ожидаете. Если Яндекс ваше преимущество перед другими кандидатами, будьте готовы, что и разговор у вас будет строиться вокруг вашей работы в Яндексе.

8. Рассказывать о пет-проектах как о коммерческом опыте

Даже на junior позиции требуется год коммерческого опыта, как его получать, если никто не рассматривает “зеленых” кандидатов, — считают соискатели и прибегают к представленному методу.

9. На вопрос о личностных навыках или ментальном состоянии говорить о недостатках как о преимуществах

— Есть ли что-то, что может вызвать у вас негативные эмоции на работе (вспыльчивость или стресс, например?)

— Нет, ни в коем случае. Я очень стрессоустойчив и подхожу к любым вопросам с холодной головой. Люди, в ситуации, когда работа нужна здесь и сейчас, а финансовая подушка безопасности закончилась еще 3 месяца назад, отвечают так. Хотя на самом деле у человека может проявляться злость при любом совете или обратной связи в его сторону.

10. Увеличить продолжительность работы на одном месте (работал 7 месяцев, написал год)

“Работал по несколько месяцев, значит, ветряный, нестабильный. У нас долго не продержится, нет смысла рассматривать”. Так мыслит большинство. И даже не HR, а нанимающих менеджеров, которые транслируют требования HR. Действительно, частая смена работы может свидетельствовать о завышенных ожиданиях кандидата или, например, о проблемах на И.С. (сложно сработаться с командой), однако независящие от сотрудника обстоятельства встречаются еще чаще: закрыли юнит, стартап не поднял раунд, токсичное руководство, обязательных переход в офис и ваша неготовность и т.д. Что важно — писать о причинах ухода в резюме. Тогда частая смена будет воспринимать совершенно по-другому.

Какие могут быть риски при красочных рассказах?

Нанимающие менеджеры возьмут рекомендацию на вашу кандидатуру от предыдущего работодателя. Из-за фантазий это может обернуться не просто отказом, но вероятностью шеринга кейса в коммьюнити HR (история обмана + ваше ФИО и CV). В перспективе месяца-двух будет затишье с откликами. Потом — забудется. Единицы внесут в черный список, у остальных нет для этого инструмента. Не в заметках же писать :) Увольнение на И.С. или после его продления. Не всегда 3 месяца хватает, чтобы с точностью сказать, насколько эффективно работает кандидат (особенно часто это бывает у компаний с невыстроенными процессами, нехваткой ролей, отсутствием выделенных людей для онбординга новеньких и т.д.). Понижение зарплаты. Схватывать на лету получилось, но результаты все же не такие, как ожидали от человека с нужным опытом. Однако перспективы есть! Вы уйдете сами. У вас получилось неимоверно быстро улучшить навыки и знания, не допустить критичных ошибок и проявить себя как сильного специалиста. Все, казалось бы, в порядке, но работать вам самим некомфортно: задачи оказались не вашей зоной интереса / корпоративная культура вам не близка (микроменеджмент или отсутствие ролей, задачи которых распределяются на других, непривычные и неудобные для вас процессы). Вроде бы по отдельности не так критично, но в совокупности — работать сложно. Вас будет ждать выгорание. Когда человек получает то, что на самом деле ему не нужно / не хочет / не готов, вероятность выгорания быстро растет. А при условии, что путь к точке В. был нелегким, просто так отказаться от результата он не сможет, значит, будет пытаться обмануть самого себя. А время, которое потребуется, чтобы прийти в себя, прибавится ко времени, которое человек потратит на поиск работы.

Ложь дорого обходится бизнесу, усложняет и замедляет поиск. Но заключение соглашения между двумя сторонами — это процесс, когда они договариваются и отстаивают свои интересы, то есть каждый сам за себя. Не все методы в бою надо использовать, хотя бы потому что некоторые могут сильно сыграть против, но некоторые, действительно, помогут найти работу быстрее. Потому что успешность прохождения тех. интервью зависит только и только от вас.

Наше мнение насчет того, какая ложь допустима в резюме:(не является единственно верным)

Допустимо:

Сменить возраст в резюме

Сменить в резюме фамилию на “не русскую” для прохождения скрининга HR зарубежных компаний

Убрать лишний / менеджерский опыт работы в резюме

Добавить в резюме опыт работы / +1 грейд (на деле уровень junior, но в резюме как middle)

Рассказывать о пет-проектах как о коммерческом опыте (но сильно опасно, т.к. выявляется очень просто и быстро).

Увеличить продолжительность работы на одном месте (работал 7 месяцев, написал год)

Недопустимо:

Добавить в резюме задачи, которых не делали сами

Добавить в резюме опыт работы менеджером (Lead)

Добавить в резюме опыт работы в престижной известной компании (Яндекс, например)

На вопрос о личностных навыках или ментальном состоянии говорить о недостатках как о преимуществах

Почему такое распределение?

Тех. интервью проверяет ваше знания и навыки, а не количество лет карьеры.

Отсечение кандидатов по возрасту, опыту, интсрументам лишь повысят вероятность быстрее найти подходящего, но не факт, что люди, получившие отказ, не смогут пройти собеседование.

И в конце концов, задача HR и нанимающего менеджера не только проверять знания, но и выявлять ложь.

Это статья не для того, чтобы научить морали. Просто при заполнении пробелов вашего опыта оценивайте риски, задавайте вопрос сами себе: а будет ли мне комфортно в такой компании, на такой роли, с такими коллегами, руководителем и фаундером?

Как показывает практика, ложь позволит найти работу быстро, но это точно не будет вашим лучшим местом, долго вы там не задержитесь. Открытость и честность — залог успеха и комфортной рабочей атмосферы. Быстро и легко не будет, зато потом окупится. Получается, вопрос приоритетов. А судьи мы сами себе."'https://habr.com/share/publication/719446/4f4c8181eafca4f6f919a1ece6c5bde1/'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
6'715426'В Kubernetes-платформе Deckhouse появилась система виртуализации нового поколения'Привет, Хабр! Сегодня у меня для вас отличные новости. В последние несколько лет мы во «Фланте» внимательно следили за технологиями-лидерами в cloud-native. Но это вовсе не праздное любопытство: из...'https://habr.com/ru/post/715426/'"Привет, Хабр! Сегодня у меня для вас отличные новости. В последние несколько лет мы во «Фланте» внимательно следили за технологиями-лидерами в cloud-native. Но это вовсе не праздное любопытство: из них мы собрали кое-что интересное и теперь готовы представить вам. Речь о новой системе виртуализации , которая появилась в сегодняшнем релизе Deckhouse v1.43.

Для начала давайте разберемся, зачем понадобилась ещё одна система виртуализации, когда рынок наводнен ими настолько, что порой бывает сложно сориентироваться. Дело в принципиально новом подходе. Идея гиперконвергентной виртуальной инфраструктуры на базе Kubernetes не нова, однако пока на рынке нет решений которые реализовали бы эту идею в полной мере. Такие решения оставляют за собой право так или иначе отходить от некоторых принципов, которые подарил нам Kubernetes.

Выпуская платформу виртуализации, каждый производитель ориентируется прежде всего на свои нужды. Мы — не исключение, поэтому пара слов о наших целях и потребностях:

Удобный интерфейс . В первую очередь нам хотелось предоставить максимально простой и понятный интерфейс пользователям Deckhouse.

Управление из Kubernetes . Как крупнейшие K8s adopter'ы на российском рынке, мы стремились сделать управление платформой виртуализации частью оркестратора. Другими словами, платформа виртуализации должна расширять и дополнять стандартный API Kubernetes, чтобы управление виртуальными машинами было таким же простым, как управление другими рабочими нагрузками в кластере.

Максимальная производительность при минимальном потреблении ресурсов. Перед тем, как выбирать ту или иную технологию, мы проводили нагрузочное тестирование и делились его результатами с общественностью. Выбранные технологии, на наш взгляд, — лучшие из тех, что есть на рынке, и реальные тесты это доказывают.

О каких технологиях идёт речь

Kubernetes

Сегодня Kubernetes — де-факто стандарт доставки и развертывания рабочих нагрузок на production-серверах. Оно и понятно: удобный и легко расширяемый API, логика контроллеров и reconcile'а, а также новомодные DevOps-практики помогают разрабатывать приложения максимально быстро и эффективно. Kubernetes закрывает кучу проблем в области наблюдаемости (observability), обнаружения сервисов, унификации и контроля за безопасностью приложения. Не удивительно, что Kubernetes взяли в оборот и крупные вендоры, и небольшие предприятия. Он сильно упростил проектирование и управление приложениями, а также повысил стабильность их работы.

Cilium

Для сетевого взаимодействия мы решили полностью положиться на Cilium. Это мощная SDN (Software Defined Network), которая базируется на стеке eBPF — ультрабыстрой технологии в ядре Linux. Cilium может работать как распределенный сетевой балансировщик, распределенный файрвол; обеспечивает хорошую наблюдаемость (observability) и предлагает множество других полезных функций.

Наша виртуализация переиспользует возможности Cilium в полной мере. Их поддержка потребовала небольших правок в коде проекта. Жёстко завязавшись на Cilium, мы можем гарантировать исправную и стабильную работу сети и для Pod’ов, и для виртуальных машин.

У нас Cilium работает во многих кластерах; самый крупный насчитывает более 180+ узлов, 12000+ подов и 6000+ сервисов. Опыт эксплуатации, накопленный «Флантом», говорит о надежности этого решения. Cilium прекрасно справляется с ответственными задачами в production.

LINSTOR

LINSTOR — блочное SDS (Software Defined Storage). Базируется на проверенных временем технологиях и позволяет организовать надёжное хранилище для дисков виртуальных машин. Для создания томов используется менеджер логических томов LVM или ZFS, а технология DRBD обеспечивает их репликацию между физическими серверами. Модуль DRBD уже 10 лет в составе «ванильного» Linux; он зарекомендовал себя как самое быстрое отказоустойчивое решение, работающее на уровне ядра.

Хотя LINSTOR — необязательный компонент для запуска виртуальных машин, модуль виртуализации требовал надёжного и быстрого хранилища, которое бы шло в комплекте с платформой. Мы протестировали разные виды хранилищ и поняли, что LINSTOR лучше всего подходит для нужд виртуализации. На его основе мы сделали отдельный модуль Deckhouse, который можно использовать как для виртуальных машин, так и для классических контейнеров.

У меня есть опыт развертывания больших кластеров на LINSTOR на предыдущей работе. Например, в одном из проектов было 600+ серверов (часть из них — diskless), 450 NVME и 2500+ виртуальных дисков (persistent volumes).

Libvirt/QEMU

Libvirt с QEMU/KVM — стандартный стек для запуска виртуальных машин в Linux. Эту связку можно использовать как самостоятельное решение, так и в составе различных систем виртуализации.

«Флант» управляет 189 гипервизорами; на них запущено 975 виртуальных машин у 26 клиентов. Всё это работает на классическом стеке QEMU (KVM) + Libvirtd. В некоторых ситуациях используется Proxmox как управляющий слой поверх QEMU. Мы отлично разбираемся в этом стеке.

KubeVirt

KubeVirt — безусловно, самая успешная попытка принести виртуальные машины в Kubernetes. Как и «ванильный» Kubernetes, технология KubeVirt открыта для всех желающих. Это позволило нескольким крупным вендорам объединиться для решения общих задач по организации системы виртуализации на основе Kubernetes. Теперь и мы входим в их число . Совместная работа позволяет не тратить силы на разработку общей логики по запуску виртуальных машин в Kubernetes, а сконцентрироваться на фичах, уникальных для каждой платформы.

Встречайте Deckhouse Virtualization

На базе перечисленных выше технологий мы создали систему виртуализации, которая реализует наше видение гиперконвергентной инфраструктуры. При этом мы не просто скомбинировали их вместе, а постарались «выжать» максимум из каждой.

Мы также хотели сохранить интерфейс взаимодействия максимально простым для конечного пользователя. Для этого пришлось внести несколько существенных изменений. В первую очередь было решено отказаться от API «ванильного» KubeVirt из-за его чрезмерной сложности и непонятности.

Подчеркну, основная идея платформы Deckhouse — дружелюбность к пользователю. Пользователь, оперируя высокоуровневыми абстракциями, имеет доступ к ограниченной функциональности, но зато эти возможности тщательно протестированы и гарантировано работают в пределах платформы. При работе с примитивами Deckhouse пользователю не нужно задумываться о том, как они функционируют внутри. Платформа делает это за него.

Обратите внимание: наша система виртуализации — это не очередная попытка переиспользовать KubeVirt. Учитывая идеологию и более широкий стек технологий, мы позиционируем её как совершенно новый продукт на рынке виртуализации.

Почему не подошёл «ванильный» KubeVirt

Как и в случае «ванильного» Kubernetes, разработка KubeVirt ведётся без оглядки на конечных пользователей. Вендоры просто объединились для решения глобальных задач и создания общей кодовой базы, которая переиспользуется в их проектах. Примеры: OpenShift, Harvester , и теперь Deckhouse. Примитивы KubeVirt стали очень громоздкими и сложными из-за необходимости удовлетворить потребности каждого вендора.

Кроме того, KubeVirt — это довольно серьёзный проект. Чтобы принести новые функции и исправления, расширяющие логику общепринятых компонентов, нужно серьёзное обоснование и поддержка со стороны крупных игроков вроде RedHat. Текущий курс проекта — миграция на механизм CNI chaining. Это сложная задача, реализация которой займет немалое время. Поэтому некоторые из наших предложений до сих пор не попали в основную ветку проекта.

Именно несогласие с концепцией организации сети в KubeVirt и собственное видение удобного API заставили нас отделиться от основной ветки проекта и принести три важных изменения в форк.

Пытаясь «выжать» максимальную производительность из сети и при этом задействовать все возможности CNI, мы реализовали поддержку MacVTap для сети Pod'ов. Это не требует дополнительных CNI-плагинов, подключаемых через Multus. Другими словами, нам удалось достичь практически нативной производительности сети Pod'ов, но использовать её для запуска виртуальных машин. Виртуальные машины работают в той же сети, что и стандартные Pod'ы, позволяя использовать все её возможности, а именно: сетевые политики, IPAM и стандартные Kubernetes-сервисы. Виртуальная машина задействует сетевой интерфейс Pod'а напрямую, не расходуя ресурсы на маскарадинг или сетевые мосты, что отлично видно в тестах .

Другое важное изменение — live-миграция виртуальных машин с сохранением IP-адреса . KubeVirt пока не умеет мигрировать виртуальные машины, использующие адрес Pod'а на своем сетевом интерфейсе. Эта возможность доступна, только если сеть Pod’ов подключена с использованием маскарадинга. А это накладывает ограничения: сниженная производительность и необходимость в дополнительном NAT. Проблема была решена с помощью дополнительного IPAM (IP Address Management), который выдаёт IP-адреса из диапазона, отведенного для виртуальных машин. Таким образом, к pod network и service network добавилась еще и vm network. Виртуальные машины получают из нее адрес и работают как обычные Pod'ы в кластере. При этом при миграции на другой узел IP-адрес сохраняется. Еще одно изменение коснулось томов, с которыми работают виртуальные машины. Для операций с томами в KubeVirt был введён специальный ресурс DataVolume, который описывает том с конкретными данными. Мы решили заменить его на более понятные и привычные пользователю сущности: Disk и Image. Image представляет собой образ, из которого можно создать виртуальную машину. Disk описывает диск с данными, который можно физически подключить к виртуальной машине. Вся остальная логика скрыта от конечного пользователя.

Полный список сущностей можно посмотреть в документации модуля virtualization платформы Deckhouse.

Что уже готово

Модуль активно разрабатывается и дорос до публичной альфа-версии (PoC). Базовая функциональность уже доступна и ее можно опробовать:

Управление виртуальными машинами: создание, запуск, остановка, удаление.

Механизм резервации IP-адресов.

Управление дисками: копирование, импорт.

Высокая доступность как для виртуальных машин, так и для компонентов платформы.

SDN с мощными сетевыми политиками на базе Cilium.

Гибкий SDS на базе LINSTOR с поддержкой снапшотов, бэкапирования, шифрования и прочего.

Встроенный мониторинг, дашборды и алерты для системных Pod’ов и вышеперечисленных модулей.

Управление доступом на основе ролей и аутентификация на базе различных источников OAuth 2.0.

Автоматическое обновление всех компонентов платформы.

Примеры создания виртуальной машины приведены в документации модуля .

В ближайшем будущем планируется:

Улучшить механизм миграции виртуальных машин между гипервизорами.

Расширить пользовательский опыт: дополнительный CLI, мониторинг событий, документация и пр.

Сделать веб-интерфейс для управления кластером и виртуальными машинами.

Добавить поддержку VPC (virtual private cloud). Можно будет создавать отдельные изолированные VLAN'ы и подключать к ним виртуальные машины.

На всякий случай напомню, что модуль виртуализации решает исключительно задачи запуска виртуальных машин.

Сейчас у вас есть уникальная возможность повлиять на разработку. Нам очень нужны ваши мнения, идеи, советы — ведь мы хотим создать действительно полезный, удобный и жизнеспособный продукт на рынке виртуализации!

P.S.

Читайте также в нашем блоге:"'https://habrastorage.org/getpro/habr/upload_files/627/99f/3c3/62799f3c38613d1aa03a53f022af847d.png'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
7'719444'30 фактов о доменных именах, которые вас могут слегка удивить'Привет! Меня зовут Максим Кульгин, я основатель  xmldatafeed.com  и  clickfraud.ru . Мы занимаемся парсингом сайтов и защитой от скликивания. Сейчас работаем с заказчиками в России, но...'https://habr.com/ru/post/719444/'"Привет! Меня зовут Максим Кульгин, я основатель xmldatafeed.com и clickfraud.ru. Мы занимаемся парсингом сайтов и защитой от скликивания. Сейчас работаем с заказчиками в России, но мечтаем выйти и на глобальный рынок. И для таких мечтателей как мы, подготовил довольно интересные факты по доменным именам...

Какие самые популярные доменные расширения? Какова наиболее распространенная длина доменного имени? Надеюсь, ответы на эти вопросы будут полезны тем, кто думает открыть свой бизнес в Интернете и задумался о домене. Из опыта всем советую рассматривать расширение .com, но не всегда это возможно по причинам, изложенным далее (посмотрите еще зону .dev как альтернативу).

Итак...

1. Зарегистрировано ~220 миллионов доменных имен.

Интернет растет, о чем свидетельствует тот факт, что количество доменных имен увеличилось на 13,2 миллиона или 3,9% по сравнению с прошлым годом.

zonefiles.io - под VPN открывайте

2. Каждый день регистрируется ~33 000 новых доменных имен.

Если вы не хотите заниматься подсчетами в уме, то это примерно один новый домен каждые 2,61 секунды.

3. С 76,6 миллионами доменов самым популярным регистратором доменных имен является GoDaddy.

Следующим по популярности является Namecheap с 16,5 миллионами. Вы только держите в уме, что после начало СВО Namecheap посчитал нас недостаточно достойными, чтобы продолжать работу, но достаточно достойными, чтобы не возвращать уплаченные деньги… было много на этот счет публикаций.

4. Статистика показывает, что средняя длина имени с расширением. com составляет 13,5 символов.

Однако наиболее распространенная длина — 12 символов. Если мы посмотрим на статистику доменных имен в зоне .net, то увидим, что эти сайты в среднем имеют 12,4 символа.

5. Средняя длина доменного имени пяти самых популярных сайтов составляет шесть символов.

Более короткие доменные имена, как правило, приносят больше трафика.

6. Уже существует 1 602 расширений доменных имен (TLDs, расширений или зон другими словами).

Количество TLDs постоянно растет. От первоначальных восьми общих и известных доменных зон (.com, .net, .org и т. д.) их число дошло до 1 602 из-за возросшего спроса на новые домены. Теперь у нас есть такие интересные домены, как .pizza, .ninja и.photography :) (интересные и никому особо не нужные).

7. 43% всех доменов имеют первоначальные расширения (.com, .net, .org, .gov и т.д.)

8. С 37,1% глобальной доли самым популярным расширением домена является .com.

Здесь нет никаких сюрпризов. Для большинства людей это расширение является синонимом самого Интернета.

9. Существует 160,9 миллионов доменов с расширением .com

10. Самым доверяемым доменным расширением является тоже .com

Исследование из 1500 человек, проведенное компанией Growth Badger, показало, что .com по-прежнему является наиболее доверяемым расширением домена, со средним рейтингом доверия 3,5. Второе и третье места заняли .co и .org с показателями 3,4 и 3,3 соответственно.

11. Забыв расширение у домена, люди в 3,8 раза чаще предполагают, что это .com

12. Регистрация доменных имен с новыми расширениями (зонами) обычно дороже — если .com стоит $11,99, то .build — $99,99.

Новые TDLs являются более ""брендовыми"", поскольку содержат ключевые слова, характерные для конкретной отрасли, и это может повлиять на их цену. Например, TDLs для высокоприбыльных и высококонкурентных отраслей, таких как .inc, .protection и .security, могут стоить ~2 000 долларов. Однако это относится не ко всем новым TDLs — доменные имена с такими расширениями, как .club, .online и .site, могут стоить от 10 до 25 долларов.

13. Статистика доменных имен показывает, что. surf является самым злоупотребляемым зонами

Исследование, проведенное Spamhaus, показывает, что 72,3% доменов с расширением .surf являются ""плохими"" — спамными, вредоносными и т.д.

14. 40% всех доменов имеют страновые расширения (.uk,. cn,. de и т.д.)

15. Существует 340 зон для стран (региональные зоны)

Это может звучать странно, т.к. в мире всего 195 стран (193 члена ООН и две страны-наблюдателя). Причина простая - зоны могут быть присвоены даже конкретным территориям внутри стран. Например, Французская Полинезия, Мартиника и Сектор Газа имеют свои расширения.

16. .cn — третье по популярности расширение, занимающее 4,14% от общего числа региональных зон.

17. В США зарегистрировано около 126,9 млн доменов, что составляет 19,77% от общего числа доменов в мире.

Статистика доменных имен показывает, что вторым в списке является Китай (2,84%) , а третье место занимает Канада (2,58%). В России зарегистрировано ~5.5 млн. доменов.

Данные с сайта statdom.ru

18. Доход в индустрии продаж доменных имен в США достигнет 8,6 млрд в 2023 году.

Рост на 6,1% в годовом исчислении, и рынок демонстрирует устойчивый подъем — среднегодовой рост на 3,9% за последние пять лет.

19. На Токелау, крошечной территории Новой Зеландии, проживает всего 1 411 человек, но 4,23% всех глобальных доменов имеют расширение. tk :)

Группа из трех атоллов предлагает бесплатную регистрацию доменов, что сделало ее чрезвычайно популярной среди мошенников. Если вы начинаете свой бизнес в ИТ и ищете способы сэкономить, выбор этого расширения только потому, что оно предлагает бесплатную регистрацию, — плохой из-за репутации.

20. Самым быстрорастущим страновым расширением доменов является габонский .ga

И снова мы имеем небольшую страну (2,28 млн жителей) с быстрорастущей интернет-популяцией, насчитывающей почти 9,5 млн доменов. И причины схожи — бесплатная регистрация и, как следствие, популярность среди мошенников.

21. Symbolics.com, первый в истории домен, был зарегистрирован 15 марта 1985 года.

22. К 1992 году было зарегистрировано всего около 15 000 доменных имен.

23. Средняя цена нового доменного имени составляет ~$10-$12

Цена во многом зависит от выбранного вами расширения домена, компании-регистратора, длительности регистрации и т.д.

24. Самая высокая стоимость, когда-либо заплаченная за доменное имя, составила 30 миллионов долларов.

Домен voice.com был продан в 2019 году за 30 миллионов долларов.

25. Одно из самых длинных доменных имен состоит из 64 символов

llanfairpwllgwyngyllgogerychwyrndrobwllllllantysiliogogogoch.co.uk попал в Книгу рекордов Гиннесса как самое длинное доменное имя. Это домен туристической кампании для деревни в Уэльсе. ""Очаровательное"" название переводится на английский язык как «Церковь Святой Марии в ложбине белого орешника возле стремительного водоворота и церковь Святого Тисилио из красной пещеры».

26. Регистрация домена была бесплатной до 1995 года. Да, до 1995 года вы даже могли получить домен. com бесплатно.

27. Самая частая начальная буква доменов — ""S"". Она же является и самой частой последней буквой.

Если вам интересно, наименее часто встречающаяся начальная буква — ""Q"".

28. Все трехбуквенные домены. com уже зарегистрированы. Последний был куплен в 1997 году.

29. Элон Маск заплатил ~11 миллионов долларов за домен tesla.com в 2016 году.

До 2016 года компания использовала домен teslamotors.com. По словам самого Маска, на сделку ушло более десяти лет переговоров.

30. Домен google.com был случайно продан за 12 долларов в 2015 году.

Компания заплатила порядка $12 000, чтобы выкупить его обратно, а предыдущий владелец отдал деньги на благотворительность.

Больше информации вы можете найти в моем личном Телеграм- канале «Русский ИТ бизнес» — в нем пишу всю «изнанку», с чем сталкиваемся в процессе работы, без приукрашивания. Если что-то упустил — спрашивайте в комментариях, отвечу обязательно."'https://habrastorage.org/getpro/habr/upload_files/d26/770/cbc/d26770cbc7e074f7114a05914f25241c.png'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
8'719424'«Еще умнее — еще проще для пользователя»: CEO Postgres Pro Олег Бартунов о будущем СУБД, open source и астрономии'С вами директор Мегаплана Сергей Козлов. Несмотря на то что гаражная версия нашей CRM была рождена с использованием MySQL, первые пользователи пришли в систему, когда она работала на PostgreSQL....'https://habr.com/ru/post/719424/'"С вами директор Мегаплана Сергей Козлов. Несмотря на то что гаражная версия нашей CRM была рождена с использованием MySQL, первые пользователи пришли в систему, когда она работала на PostgreSQL. Самое ценное, что у нас есть, — это данные, и мы не можем хранить их в чем-то ненадежном, молодежно-хипстерском, с коротким сроком жизни или раздираемом бюрократическими склоками. Мы выбрали PostgreSQL и ни разу ему не изменили. Как и он нам. Мы были очень рады, когда генеральный директор Postgres Professional, ведущий разработчик PostgreSQL Олег Бартунов согласился поговорить с нами об открытом ПО и новых вызовах, которые сейчас стоят перед разработчиками и пользователями, а еще о том, как большие данные помогают науке и в космических одиссеях. Слово Олегу Бартунову.

Олег Бартунов — сооснователь и генеральный директор российской компании-разработчика системы управления базами данных (СУБД) Postgres Professional. Ведущий разработчик (Major Contributor) PostgreSQL. Разработал для PostgreSQL поддержку интернационализации (русского и других языков), систему полнотекстового поиска, средства поддержки слабоструктурированных данных, индексные методы доступа, в том числе к пространственным данным, и многое другое. Профессиональный астроном, научный сотрудник в отделе физики эмиссионных звезд и галактик ГАИШ МГУ. Увлекается горным туризмом и легкой атлетикой, основал корпоративную команду по бегу.

Как устроен Postgres (спойлер: по законам рынка)

Наша компания Postgres Professional работает сразу в двух направлениях. Уже 8 лет мы одновременно развиваем коммерческую СУБД Postgres Pro и open source СУБД PostgreSQL с открытым исходным кодом. Когда-то нас в этом упрекали, но история Postgres доказала, что это единственный правильный способ развивать open source решения.

Вплоть до 1994 года Postgres был академическим проектом, разработанным студентами и выпускниками университета Berkley под руководством Майкла Стоунбрейкера. В 1994 году Стоунбрейкер открыл исходные коды системы. С этого момента вокруг Postgres стало активно формироваться международное сообщество разработчиков. Сначала сообщество было совсем небольшим и состояло из энтузиастов, которые использовали систему для решения собственных задач, чаще всего научных — например, для изучения сверхновых звезд, как я. Если какой-то функциональности не хватало, любой участник сообщества мог добавить ее самостоятельно, как принято в open source культуре. Именно так и развивалось сообщество, при этом участники не получали за эту работу ни копейки.

В 2000-х годах, по мере того как сообщество росло, вокруг Postgres стали появляться postgres-центричные компании, которые начали предлагать свои услуги и продукты на базе этой СУБД. Они были заинтересованы в развитии системы, поэтому начали нанимать контрибьюторов open source. Появление первых крупных заказчиков в 2010-х годах сильно стимулировало этот процесс.

В итоге уже к 2015 году большинство главных разработчиков сообщества работали на крупных коммерческих игроков. С этого момента именно компании стали определять развитие Postgres: они разрабатывают новые патчи, тестируют их, внедряют в свои коммерческие решения, а затем возвращают их в open source. Сообщество, в свою очередь, поддерживает код, оценивает и принимает (или не принимает) предлагаемые компаниями патчи. Благодаря такой трансформации Postgres стал профессиональной СУБД — системой, форки которой используются для решения задач коммерческих клиентов.

Теперь Postgres развивается по законам рынка и за счет большого экспертного open source сообщества является одной из самых популярных и эффективных СУБД в мире. Что ждет Postgres дальше? Это большая интересная тема для отдельного разговора.

Не все так просто с open source

Многие считают, что open source — панацея от любых проблем, однако на деле это не так. Такое ПО действительно имеет ряд серьезных плюсов. Например, отлично подходит для образовательных целей: позволяет людям заглянуть под капот больших систем. Open source также хорош, чтобы запустить проект, протестировать его и показать миру, на что ты способен. Однако с использованием в коммерческом секторе не все так просто. Как показывает практика, open source решения опасно использовать без наличия поддержки на уровне ядра в критических системах. Серьезный энтерпрайз требует серьезного подхода: обеспечения повышенной безопасности, сертификации продукта, дополнительных фич, доработки в области производительности. Именно за это крупные коммерческие заказчики выбирают enterprise-версии.

Демократичность сообщества — тоже палка о двух концах. С одной стороны, каждый пользователь может предложить любую доработку, получить обратную связь, подискутировать и даже прийти после обсуждений к новым интересным идеям. С другой стороны, каждый коммит требует согласия членов сообщества, а сообщество консервативно и не всегда охотно принимает новые фичи. Часто, чтобы отстоять свою позицию, требуется потратить большое количество сил и, главное, времени. При этом скорость — критичный показатель для коммерческих компаний, клиентам которых нужен быстрый результат.

Живой пример — востребованный у заказчиков Postgres Pro Enterprise патч 64-битных счетчиков транзакций, он нужен компаниям, которые совершают сотни миллионов транзакций в день. Мы успешно внедрили его и используем в enterprise-версии, при этом в open source сообщество мы стараемся его отдать вот уже несколько лет. Все из-за того, что каждый человек может в любой момент поднять руку и сказать: «мне не нравится эта реализация», «не думаю, что эта фича будет востребована», — и запускается новый виток дискуссий. Такие ограничения и мотивируют коммерческие компании активно развивать свои версии.

И все же сотрудничество сообщества с коммерческими компаниями — взаимовыгодный процесс, где каждый отдает и каждый приобретает. Например, сообщество замечает какие-то баги, мы исправляем их, и наши клиенты получают более стабильную версию коммерческого продукта. В то же время сообщество получает ряд объективных улучшений, которые делают работу с продуктом еще быстрее, проще и легче.

Как будет развиваться СУБД

PostgreSQL — это мировой тренд. Как показывают графики, популярность этой СУБД растет гораздо быстрее, чем популярность Oracle, Microsoft или MySQL. Чтобы Postgres продолжил и дальше укреплять свои позиции, важно постоянно его совершенствовать. Есть два базовых направления развития, которые будут актуальны всегда: горизонтальное и вертикальное масштабирование. Горизонтальное — возможность сервера работать при увеличении количества данных. Вертикальное — стабильная работа сервера при все большем количестве запросов.

Наряду с этим очень важно упрощать систему в использовании — делать ее доступней для обывателя. Почему это важно? Информационные технологии давно стали частью жизни любого из нас, при этом количество ИТ-экспертов (настоящих профессионалов, которые могут разобраться в «кишках» решения) снижается, и этот тренд будет все более выражен, в том числе и в СУБД. Сейчас, чтобы работать с базой данных, пользователю нужно знать массу всего. Например, Мегаплан производит продукт, который является интерфейсом между пользователем и информацией. Разработчики системы должны писать заумные многоэтажные SQL-запросы, уметь оптимизировать их, думать о том, как сделать работу системы более устойчивой, как масштабировать сервер с ростом запросов и решать другие задачи.

В свете растущей популярности low code / no code разработки, база данных должна предъявлять минимальные требования к разработчикам приложений. В будущем СУБД должна стать такой же простой, как и телефон: управляться голосом, предугадывать дальнейшие шаги пользователя и давать подсказки.

Другая важная задача для всех СУБД — сочетать производительность и масштабируемость базы c высокой степенью защиты от компрометирования и несанкционированного доступа. Реляционные базы данных уже сейчас могут обеспечить очень высокий уровень безопасности. В частности, Postgres Pro Enterprise включает функции, обеспечивающие максимальную надежность системы и безопасность данных, благодаря чему ее активно используют даже в объектах критической инфраструктуры федеральных информационных систем. Безопасность и надежность СУБД — то, за что нас ценят наши заказчики, и мы стремимся постоянно повышать этот уровень.

Есть и перспективные направления разработки. Ими важно заниматься, чтобы компания видела новые горизонты для развития, мыслила реалиями не только сегодняшнего, но и завтрашнего дня. Для таких направлений у нас в Postgres Pro есть целая лаборатория. Многими из таких разработок мы делимся с сообществом. Например, эффективными способами работы с неструктурированными данными (JSON, JSONB), TOAST, умными методы индексирования (smart индексы) и другими.

Последнее, но не менее важное направление — создание возобновляемого кадрового резерва системных разработчиков. Развитие любой СУБД возможно только при условии достаточного количества квалифицированных специалистов. Чтобы создать такую кадровую базу, мы активно занимаемся отбором и выращиванием студентов: сотрудничаем с вузами, запускаем конкурсы, организуем стажировки, разработали программу роста молодых специалистов внутри компании. Системные разработчики — это особый тип людей, умеющих работать на перспективу и фокусировать внимание на долгосрочных задачах, результат которых может быть виден через месяцы, а то и годы. Найти или вырастить таких — непростая задача. Мы гордимся тем, что справляемся с ней, и планируем активно увеличивать штат и дальше.

Как IT-рынок пережил 2022 год

Один из постулатов open source сообщества — равные возможности для всех участников, независимо от страны проживания, политических взглядов, религии и других факторов. Конечно, определенные дискуссии были, однако PostgreSQL сообщество признает огромный вклад россиян в СУБД, поэтому санкций против нас не ввели. Мы остаемся частью международного сообщества и продолжаем работать вместе на благо open source.

В России уже появилось около десяти российских СУБД на базе, поэтому нас и правда можно назвать «родиной слонов». С одной стороны, такая конкуренция — большой плюс: она полезна для рынка, поскольку помогает развивать качество продукта, а нам как ведущей СУБД на рынке — не бронзоветь. Проблема в том, что в последнее время появились «вендоры», которые создают не новые качественные форки, а лишь модификацию ОСПО с незначительными доработками, клеят на продукт свой шильдик и пытаются продать.

Работа настоящего вендора, напротив, подразумевает серьезные изменения ядра продукта. Вдобавок она выходит далеко за рамки продажи решения. Как минимум нужно тестировать ПО на всех железных и софтверных платформах, под разные процессоры и кучу информационных систем. На нашей ферме, например, тесты запускаются каждые пять минут. Тесты и релизы под разные архитектуры позволяют найти баги. А в нашем деле они могут быть очень серьезными вплоть до утечки данных. Всего же за 2022 год мы выпустили свыше 49 000 пакетов релизов СУБД и расширений. Обладает ли всем этим набором функций новоиспеченный «вендор» — сложный вопрос. В любом случае важно десять раз подумать, прежде чем использовать малоизвестную СУБД в коммерческой компании.

Сейчас не время снимать пенки, плодить клоны и распылять силы на соперничество. Важно объединять усилия, развивать компетенции и продукт, растить качественные полезные проекты, делиться опытом и знаниями. Хорошим решением могла бы стать конференция, где разработчики смогли бы сравнить решения по гамбургскому счету: открыто рассказать про свои «ядерные» патчи, показывать тесты, бенчмарки и другое.

А какие прогнозы?

Мы пережили прошлый год довольно хорошо: с выручкой, прибылью и оборотами все в порядке, мы продолжаем активно расти. Отдельная гордость — расширение штата. За 2022-й мы набрали около 60 человек, к нам пришла группа технических специалистов из Oracle во главе с Марком Ривкиным. Это знак рынку, что наша компания — лидер, которому доверяют. Конечно, не обошлось и без потерь: некоторые сотрудники покинули Россию, но их можно пересчитать по пальцам одной руки.

Сейчас у нас важная миссия — обеспечивать технологическую состоятельность России. Если страна считает себя независимой, то у нее должен быть собственный софт, по крайней мере системное ПО. Последние 7 или 8 лет санкций — особенно недавние события — выдвинули российский Postgres в мировые лидеры по использованию в системах федерального масштаба. Больше ни в одной стране Postgres не применяется так активно, так широко и в таких больших нагрузочных системах. Среди наших клиентов — крупнейшие системы федерального уровня, которые работают 24/7.

Кроме того, сегодня российское сообщество является самым большим сообществом Postgres в мире, а мы — одна из ключевых компаний, развивающих его. Каждый год Postgres Professional отправляет в PostgreSQL больше 100 патчей — например, в выпуске PostgreSQL 15 приняло участие 27 наших сотрудников.

В будущее я смотрю с оптимизмом. Перед нами открылось окно возможностей, которое важно использовать для развития — не просто заместить ушедших конкурентов, а стать лучше. И если не будет серьезных внешних потрясений, мы с этой задачей обязательно справимся.

Как технологии помогают науке

Астрономия — наука данных, и когда их стало много (а это случилось гораздо раньше, чем в промышленности или любой другой отрасли, поскольку звезд на небе больше, чем вообще всего), мы писали свои маленькие программки по обработке и поиску данных. Тогда я обнаружил, что существует целый мир баз данных, который поможет мне в работе.

Раньше я занимался изучением сверхновых — это звезды, которые взрываются в других галактиках. Сейчас несколько раз в неделю я хожу в ГАИШ (Государственный астрономический институт им. П. К. Штернберга при МГУ), общаюсь с коллегами, помогаю, чем могу. Кстати, сотни терабайт данных хранятся у нас именно на Postgres. А некоторые постгресовые индексы небесных тел, над которыми мы работали для эффективного поиска астрономических данных, используются в астрономических проектах по всему миру.

Иногда с грустью вспоминаю, как ночами сидел с телескопом, вставлял в него огромные фотопластины, наводил вручную, делал снимки, а затем проявлял изображения. Это была романтика. Привычка смотреть на небо у меня осталась и сейчас, но в телескоп я уже давно просто так не смотрю, разве что детей удивить. Я, например, перед Новым годом внукам и детям показывал звезду на шпиле университета. Дети кричали: «Вау, какая она, оказывается, ледяная и заснеженная» — и тут же фотографировали на телефон, чтобы рассказать об этом в каком-нибудь блоге.

Астрономы все еще ездят в обсерватории, но многие наблюдения происходят удаленно. Например, у ГАИШ по всему миру развернута сеть телескопов-роботов «Мастер». Она автоматически сканирует небо для обнаружения новых объектов. Все это происходит прямо в базе данных в Postgres. Эдакая машина по открытию новых объектов.

Для работы астрономы пользуются Linux и Postgres. Еще нужны сервисы по обработке изображений, их сегодня разрабатывает много любителей. А научные статьи пишут в LaTeX — это популярная во всем научном мире программа, там удобно строить графики и писать формулы.

Какими бывают большие данные

Если раньше мы писали формулы и теории, а потом при помощи их объясняли открытия, то теперь наоборот: мы ищем закономерности в больших данных, идем от информации. Поэтому серьезные научные открытия сегодня происходят на стыке наук. Например, открытие тех же самых гравитационных волн было сделано при помощи больших данных.

Большие данные — вещь относительная. Никакой конкретной цифры не существует. В целом под ними можно понимать любые данные, систематизировать и обработать которые вы не можете с помощью обычных инструментов. Посмотрите на любого блогера: он генерирует кучу данных, в его телефоне десятки, а то и сотни гигабайтов изображений и видео. Если он не может обработать их с помощью подручных средств, их вполне можно считать большими данными.

Известное высказывание о больших данных принадлежит Дэну Ариели — американскому экономисту израильского происхождения

Опять же все относительно. Например, оцифрованная Библиотека конгресса в США совсем маленькая, хранить ее у себя дома может любой. Телескопы, на которых работают в Америке, могут производить несколько десятков терабайт за одну ночь. А радиотелескоп, размер которого квадратный километр, будет производить петабайты.

О космическом настоящем и будущем

На мой взгляд, одно из важнейших недавних открытий — то, что Вселенная расширяется с ускорением, этот факт имеет большое значение для судьбы Вселенной. Возможно, люди еще недопоняли значимость этого открытия, но оно действительно колоссальное.

Многие открытия ученые давно предсказывали и писали формулы на кончике пера, но совершить их удалось только сейчас. Это, например, награжденное Нобелевской премией открытие гравитационных волн и полученное учеными изображение тени черной дыры. Еще хотелось бы отметить прогресс в поиске экзопланет, то есть планет, находящихся вне Солнечной системы. Раньше мы и мечтать не могли о том, что увидим планеты у других звезд. А теперь это реальность.

Мечты о космосе и внеземные цивилизации

Когда я вижу, что очередной миллионер полетел в космос, я за него радуюсь. Ведь он заработал столько денег, чтобы исполнить свою детскую мечту. Я бы и сам туда хотел попасть, чтобы посмотреть на Землю со стороны. Мне кажется, такое желание есть у каждого человека. Очень хочется взглянуть на черный космос своими глазами, потому красивые снимки — во многом результат обработки искусственным интеллектом. Из науки мы знаем, что там очень темно и блистают звезды. Когда я хожу в горы, ощущаю схожий эффект: если поднимаешься выше и выше, небо становится все темнее.

А еще человечеству всегда хочется быть уверенным в том, что мы не одиноки во Вселенной. В детстве я мечтал увидеть кого-то, познакомиться, получить какие-то халявные знания. Сейчас астрономы бьются в поисках экзопланет, которые по размеру, массе и близости к своей звезде похожи на Землю. Мы интуитивно ищем на других планетах внеземную жизнь в виде нас, похожих на нас. Нам кажется, что в таких же условиях появятся такие же люди, как мы. Хотя кто его знает.

Думаю, что мы еще не доросли до того уровня, чтобы нас вообще замечали. Какой смысл какой-то внеземной цивилизации, которая прошла все эти «болезни роста», с нами контактировать? Даже если они дадут нам какое-то важное знание, то мы не поймем, как его применить. Или, может, они будут нас учить, как надо жить? Но ведь мы не верим даже самим себе. Так что мы сами должны пройти тот путь развития, чтобы с нами стали общаться «по-человечески»."'https://habrastorage.org/getpro/habr/upload_files/50f/d1e/cf3/50fd1ecf3aa9a0869dd5b9ac1aac4e29.jpg'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
9'718540'Тестирование конвейера релизов с помощью Fastlane'Пару недель назад я выступил с докладом о том, как обрести уверенность в процессе релиза, на Mobile Devops Summit , дистанционном мероприятии, организованном Bitrise ....'https://habr.com/ru/post/718540/'"Пару недель назад я выступил с докладом о том, как обрести уверенность в процессе релиза, на Mobile Devops Summit, дистанционном мероприятии, организованном Bitrise. В конце концов, я подумал, что было бы неплохо написать статью с описанием специфики выступления и мотивов, стоящих за ним.

Если вы пропустили выступление и хотели бы его посмотреть, я выложил запись на моём канале Youtube.

Мотивация

Для разработчика iOS есть определённые конвейеры CI (continuous integration — непрерывная интеграция), которые имеют решающее значение для доставки приложения, но из‑за своей природы они не запускаются часто. Отличным примером этого является конвейер релиза, который автоматизирует архивирование приложения, его подписание и отправку в App Store Connect и запускается только тогда, когда приложение готово к релизу.

Когда конвейер запускается нечасто, любые проблемы с ним останутся незамеченными и возникнут только тогда, когда конвейер понадобится в следующий раз. Хотя некоторые из этих проблем легко исправить. Вам необходимо, чтобы такие процессы проходили как можно более гладко, и, в случае конвейера релиза, получить уверенность в том, что приложение будет доставлено пользователям быстро, а не тратить время на исправление ошибок.

Давайте рассмотрим в следующих разделах две разные ошибки, которые могут произойти в день релиза и, безусловно, могут быть сложными для отладки.

Ошибки архивации

Ошибки сборки легко обнаружить, так как приложение обычно создается на CI много раз каждый день. С другой стороны, есть некоторые ошибки, характерные для архивирования приложения, процесса, который обычно происходит только тогда, когда нам требуется сгенерировать артефакт, который затем необходимо распространить.

Давайте рассмотрим модульное приложение для iOS, которое определяет iOS 15 как минимальную версию для развёртывания. Мы хотим представить новую функцию, полностью созданную с помощью SwiftUI, поэтому мы создаём новый модуль Schedule (как Swift package):

Package.swift

// swift-tools-version: 5.6 import PackageDescription let package = Package( name: ""Schedule"", products: [ .library( name: ""Schedule"", targets: [""Schedule""] ) ], dependencies: [], targets: [ .target( name: ""Schedule"", dependencies: [] ), .testTarget( name: ""ScheduleTests"", dependencies: [""Schedule""] ) ] )

Затем новый модуль импортируется целевым приложением и отображается при необходимости. Приложение можно собрать, тесты проходят нормально, новое view (представление, вью, вьюшка) выглядит великолепно, теперь приложение использует SwiftUI!

Время идет, и наступает следующий день релиза, когда пользователи с большим воодушевлением получают отзывы об этом новом view. Но как только запускается конвейер релиза, возникает ошибка, связанная с архивацией приложения:

Смотрим на журнал сборки выше: похоже, что приложение архивируется для armv7. Проблема здесь в том, что SwiftUI недоступен в SDK armv7, из‑за чего компилятор не может найти символы SwiftUI. Посмотрев на некоторые связанные ветки форума разработчиков Apple, пришёл к выводу, что если приложение имеет минимальную версию развертывания iOS 11 или выше, его не следует создавать для этой архитектуры.

Так что же происходит? Что ж, после многократных попыток исправить ошибку выясняется, что даже несмотря на то, что новый пакет импортируется target с минимальной версией развертывания iOS 15, минимальная версия iOS должна быть установлена под platforms (платформами) в Package.swift для того, чтобы ошибка исчезла:

Package.swift

// swift-tools-version: 5.6 import PackageDescription let package = Package( name: ""Schedule"", platforms: [ .iOS(.v15) ], products: [ .library( name: ""Schedule"", targets: [""Schedule""] ) ], dependencies: [], targets: [ .target( name: ""Schedule"", dependencies: [] ), .testTarget( name: ""ScheduleTests"", dependencies: [""Schedule""] ) ] )

Обратите внимание, что эта ошибка характерна для Xcode 13 и не является проблемой для Xcode 14.

Ошибки загрузки

Теперь, когда мы увидели ошибку архивирования, давайте рассмотрим пример ошибки загрузки. Давайте теперь рассмотрим, что новый модуль SwiftUI вместо этого является фреймворком (в проекте Xcode) и используется разными target. Каждый из них встраивает и подписывает фреймворк.

Приложение собирается, запускается и архивируется без проблем, но как только оно загружается в App Store Connect, возникает ошибка:

Встраивая и подписывая несколько раз, мы создаём дубликаты одного и того же пакета, что вызывает ошибку загрузки. Это связано с тем, что не может быть более одного пакета с одним и тем же идентификатором. Исправление простое, но иногда его трудно обнаружить, если вы новичок в модульных кодовых базах. Чтобы обойти эту проблему, инфраструктура должна быть встроена и подписана только один раз на уровне target приложения, а затем любой другой target, который её использует, должен отказаться от её внедрения.

Раннее обнаружение этих ошибок

Несмотря на то, что описанные выше проблемы не требовали значительных изменений кода, их диагностика и расследование, безусловно, требовали времени. И это время, на которое вы откладываете свой релиз. Это может не иметь большого значения, если ваш релиз включает только новые функции и улучшения. Но подумайте о ситуации, когда вы делаете выпуск патча, который исправляет серьёзный сбой. Вы, безусловно, хотите, чтобы ваше приложение стало доступно пользователям как можно быстрее.

Важно отметить, что эта статья не показывает, как предотвратить возникновение этих проблем, а скорее помогает обнаружить их на ранней стадии, чтобы у вас было время исправить их до следующего релиза. Проблема с тестированием конвейеров такого типа заключается в том, что они могут быть довольно громоздкими и длительными, а использование большого количества ресурсов и времени CI в рабочее время команды может привести к сбоям. Вот где запланированные запуски CI очень кстати.

Идея, стоящая за ними, заключается в том, что вы можете запланировать повторный запуск вашего конвейера в определенную дату и время, используя cron expressions. В следующих разделах я создам Github Action, которое заархивирует приложение, подпишет его для App Store, а затем проверит двоичный файл с помощью App Store Connect с помощью fastlane.

Реализация nightly Github Action

Создание nightly lane

Давайте начнём с просмотра того, как выглядит lane релиза в Fastfile:

Fastfile

lane :release do # Let's make some magic happen 🪄 gym( project: ""./NutriFit.xcodeproj"", clean: true, derived_data_path: ""./derived-data"", output_directory: ""./build"", output_name: ""NutriFit.ipa"", scheme: ""NutriFit"", export_options: { provisioningProfiles: { ""dev.polpiella.NutriFit"" => ""NutriFit App Store"", } } ) deliver( ipa: ""build/Nutrifit.ipa"" ) end

Глядя на ошибки, обнаруженные выше, новая nightly lane должна убедиться, что приложение может быть правильно заархивировано и что созданный двоичный файл может быть загружен в App Store Connect. Проблема в том, что если мы дословно продублируем код релиза, он отправит сборку в TestFlight, а это не то, что нам необходимо. Вместо этого мы должны использовать флаг доставки verify_only, чтобы сборка никогда не отправлялась, а только проверялась:

Fastfile

lane :release do # Let's make some magic happen 🪄 gym( project: ""./NutriFit.xcodeproj"", clean: true, derived_data_path: ""./derived-data"", output_directory: ""./build"", output_name: ""NutriFit.ipa"", scheme: ""NutriFit"", export_options: { provisioningProfiles: { ""dev.polpiella.NutriFit"" => ""NutriFit App Store"", } } ) deliver( ipa: ""build/Nutrifit.ipa"", verify_only: true ) end

Если вы хотите узнать больше о том, как работает флаг verify_only, вы можете взглянуть на оригинальный pull request. Я работал над внесением этого изменения в код, поэтому, если у вас есть дополнительные вопросы, не стесняйтесь, напишите мне сообщение в Twitter.

Создание nightly workflow

Теперь, когда nightly lane реализована, её необходимо запускать в определённое время каждый день. Для этого в каталоге .github/workflows создаётся новый файл Github Actions workflow с именем nightly.yml, который работает в системе с macos‑latest в качестве операционной системы и просто вызывает nightly lane в репозитории. Кроме того, в приведённом ниже действии используется тег schedule с chron expression, чтобы сообщить Github, что это действие должно выполняться каждый день в полночь:

nightly.yml

name: Nightly on: schedule: - cron: '0 0 * * *' jobs: nightly: runs-on: macos-latest steps: - uses: actions/checkout@v2 - name: Run nightly lane run: bundle exec fastlane nightly

Есть некоторые дополнительные настройки, такие как аутентификация с помощью App Store Connect, которые для простоты проигнорированы в этой статье. Если вам интересно узнать немного больше о том, как обрабатывать аутентификацию с помощью App Store Connect и fastlane, следите за этим блогом, так как я скоро напишу статью на эту тему.

Когда запланированные рабочие процессы сияют

Запланированные рабочие процессы очень удобны, когда вы хотите получить уверенность в процессах, которые очень важны, но не запускаются очень часто (например, конвейер релиза).

Они также отлично подходят для выполнения задач, требующих много времени и ресурсов (таких как сквозные тесты) с минимальными перерывами и затратами. Например, вместо того, чтобы запускать E2E‑тесты при каждой отправке на main, их можно запускать один раз вечером, проверяя все изменения, внесённые за день.

И последнее, но не менее важное: еще один отличный вариант использования запланированных запусков CI — это автоматизация повторяющихся процессов. Например, на работе у нас есть сертификат, который необходимо выпускать каждый месяц, поэтому мы создали Github Action, которое запускается в начале каждого месяца и заменяет текущий сертификат новым."'https://habr.com/share/publication/718540/48fafaa1e737cbb9df48d9bc3b1679d7/'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
10'719426'Как выбрать для своего конвейера данных максимально эффективную архитектуру'Привет! Меня зовут Михаил Благов, я руководитель департамента «Чаптер инженеров данных и разработчиков» в beeline tech. В этом посте я хочу поделиться способом, с помощью которого можно выбрать...'https://habr.com/ru/post/719426/'"Привет! Меня зовут Михаил Благов, я руководитель департамента «Чаптер инженеров данных и разработчиков» в beeline tech. В этом посте я хочу поделиться способом, с помощью которого можно выбрать подходящую архитектуру для конвейера данных в зависимости от требований к нему. В частности, обсудим паттерн CDC (change data capture, aka «захват изменений»), основная идея которого — быстрая репликация какого-то источника в аналитическое хранилище.

Под катом мы:

познакомимся с вариантами архитектуры конвейеров данных: из каких компонентов и как его можно собирать,

рассмотрим и сравним четыре разные архитектуры конвейеров.

Disclaimer: серебряной пули не будет, в этой статье я поделюсь опытом выбора архитектуры для решения конкретной задачи. Аналогичный выбор для других случаев потребует дополнительных исследований и замеров производительности.

Начнем с матчасти

Помните главные отличия OLAP и OLTP ?

OLTP — Online Transaction Processing тип нагрузки на базу данных, при котором требуется быстро обрабатывать insert’ы, update’ы, delete’ы, но точечно, по одной записи. Для работы с таким типом нагрузки предназначено большинство реляционных баз данных, таких как PostgreSQL, Oracle, MsSQL и др.

OLAP — Online Analytical Processing, аналитический тип нагрузки, характеризующийся чтением значительной доли данных в таблице для формирования метрик. Это запросы вида «Я хочу посчитать количество с группировкой по чему-нибудь», «Я хочу посчитать среднее значение числовой колонки» и прочие. С такой нагрузкой плохо справляются обычные реляционные СУБД, и их обычно заменяют на колоночные СУБД, например, Clickhouse, или специальные распределённые системы хранения данных, такие как Hadoop с его специальными форматами хранения данных.

У систем хранения данных, оптимизированных под OLAP-нагрузку, есть специфика — обновления и удаления либо не работают вообще, либо работают очень медленно.

Теперь представьте себе ситуацию, когда у компании есть хорошо работающий продукт, использующий классическую OLTP базу данных. В какой-то момент руководителю компании потребуется принимать решения о его дальнейшем развитии и позиционировании. Мудрый руководитель принимает решения, основываясь на данных, и поэтому перед внедрением глобальных изменений нанимает дата-аналитика и просит проанализировать работу продукта. Возникает необходимость делать одновременно и быструю обработку транзакций, и существенную аналитику по ним (OLAP-запросы).

Что произойдёт с продуктивной базой, если впустить туда дата-аналитиков? Она будет работать медленно для обоих типов нагрузки.

Что же делать, если на проекте требуется делать одновременно и быструю обработку транзакций, и существенную аналитику по ним? А если ещё и во времени, близком к реальному? Ответ обычно следует из принципа разделения обязанностей. Пусть продуктивная база отвечает за продуктивную нагрузку, а её копия – за аналитическую. А если ещё эту копию сделать на OLAP-системе… В этот момент возникает необходимость содержать оба типа СУБД и строить конвейеры данных, эффективно перемещающие информацию из одной в другую.

Выглядит это просто:

В чем же здесь проблема? В том, как реализовать блок, отвечающий за перемещение данных, или, по-другому, репликацию. Обычно начинают с простых решений. Например, можно копировать все данные каждый день и говорить: «Окей, у нас время доставки T-1 день». Или каждый час. Тогда «свежесть» данных для аналитики уже существенно повышается. Для многих типов отчетности этого достаточно (например, для построения ежемесячных или ежеквартальных отчетов, сверок счетов и т. п.). Это вполне себе рабочий подход, если данных не очень много, а нужны они не срочно.

Но есть и недостатки. Если данных достаточно много или они должны быть достаточно «свежими», то вся эта схема перестает работать.

CDC спешит на помощь

Решить задачу можно, применяя широко известный паттерн Change Data Capture, или Захват Изменений Данных. Его смысл заключается в том, чтобы перемещать только те данные, которые изменились с момента предыдущего копирования. Способов реализации достаточно много.

Например, в исходные данные можно добавить какую-нибудь колонку типа timestamp, в котором исходная система будет сохранять дату последней модификации записи. Тогда каждый раз, копируя данные, конвейер может сохранять последнюю скопированную временную метку, а в следующий запуск оперировать только с данными младше этого времени. Это базовая реализация CDC. Она тоже подразумевает пакетную обработку раз в какой-то промежуток времени, но даже такой подход позволяет существенно сократить объём копируемых данных.

Другой способ реализации паттерна — применение изменений. Такой подход даёт возможность построить репликацию во времени, близком к реальному. Основа решения — подписка на информацию об изменениях в источнике. Далее она применяется к целевой системе. Здесь важно иметь в виду, что изменения всегда берутся с какой-то временной точки, поэтому важно написать пакетный конвейер данных, очень похожий на нативное решение по репликации, чтобы синхронизировать начальное состояние продуктивного аналитического хранилищ.

Хватит теории! Практику давай!

Рассмотрим построение аналитической системы, где в качестве продуктивной БД выступает MongoDB, а в качестве аналитической — Clickhouse.

При построении репликации требуется обеспечить семантику доставки данных “at-least-once”, при этом требуется максимизировать пропускную способность конвейера.

Захват изменений будет реализован через чтение лога операций — стандартный механизм получения оповещений об изменениях в MongoDB.

Маппинг коллекций MongoDB на таблицы Clickhouse известен и не меняется.

Дополнительно известно, что лог операций в MongoDB достаточно жёстко ограничен по объёму, что требует дополнительной буферизации изменений в промежуточном хранилище — Apache Kafka.

Выбор компонентов обусловлен уже существующим стеком проекта, поэтому примем его как данность.

Обзор возможностей компонентов

MongoDB — документо-ориентированная база, данные доступны в формате JSON, запросы к ней пишутся также в JSON. У этой системы хранения данных есть бесплатная общественная версия, а также широкая поддержка коммерческой функциональности, такой как безопасность, высокая доступность и масштабируемость.

Для репликации используется Oplog — коллекция, в которую попадают операции, произошедшие в Mongo с указанием типа изменения, например, i - insert, u - update, d - delete. Каждое сообщение в этой коллекции содержит временную метку, что делает их пригодными к потреблению паттерном «Захват изменений».

Apache Kafka — это распределённый брокер сообщений. Обладает открытым кодом, хорошо масштабируется и держит большие нагрузки.

Clickhouse — колоночная база данных с SQL-интерфейсом, в которой даже работают update’ы.

Архитектура решения

Каким образом можно реализовать конвейер данных с описанными требованиями на этих компонентах?

Первый вариант — вставка напрямую

В зависимости от типа операции в Clickhouse выполняется соответствующий запрос. i = insert, u = update, d = delete. Одной записи в Oplog соответствует один запрос, схлопывание однотипных запросов в батч не выполняется.

Одной коллекции в MongoDB соответствует одна таблицу в Clickhouse. Для репликации в этом случае можно использовать простое Java-приложение или какой-нибудь фреймворк, например, Apache Spark.

Второй вариант — Slowly Changing Dimensions (SCD) Type 2. Все операции, неважно, insert, update или delete, выполняются как insert на целевом хранилище. Каждой новой версии записи по соответствующему идентификатору присваиваем порядковый номер или timestamp обновления. Эту дополнительную колонку впоследствии можно использовать для того, чтобы выбрать последнюю версию записи или сформировать слепок на определённый момент времени.

Третий вариант — использование промежуточного кеша, поддерживающего обновления. Идея проста: не стоит обновлять данные в хранилище, которое не поддерживает операции обновления, вместо этого достаточно применить эти операции к какому-нибудь in-memory-хранилищу. Insert, update, delete работают быстро, однако раз в какое-то время будет требоваться полная перезапись в Clickhouse. Это архитектура табличного обновления.

И четвёртый подход. Если данные предполагают естественное разбиение на части, например, по времени появления в системе, то их можно регионировать, или партицировать. В таком случае при регулярном обновлении из кеша в целевое хранилище не обязательно перезаписывать всю таблицу, достаточно заменить только те партиции, которые поменялись.

В остальном, идея ровно такая же, как с табличным обновлением.

Какая архитектура выиграет? Ответ оказывается неоднозначным.

Время замерять результат

О тестовом стенде. MongoDB, Kafka и Clickhouse можно развёрнуть на виртуальных машинах в публичном облаке. Для построения графиков, приведённых в этом посте, использовались виртуальные машины с 2 CPU, 4 Gb RAM, HDD, гигабитной сетью и остальными настройками по умолчанию. Операционная система: Ubuntu 20.04.

Далее потребуется генератор данных, который позволяет совершать операции всех видов в MongoDB.

Будем записывать в MongoDB N штук изменений, где N — достаточно большое. Замерять будем общее время обработки этого количества записей, включая инициализацию и завершение, усредненную скорость (record per second, rps) и максимальную задержку появления данных в аналитической системе (t минус что-то).

Для статистической достоверности результатов запустим приложение десять раз, отбросим 2 наиболее отличающихся результата, потом посчитаем среднее значение и стандартное отклонение.

Тестовый стенд

Настройка компонентов инфраструктуры. В MongoDB придется настроить реплика-сет, состоящий из одного узла, генератор данных будем запускать в единственном экземпляре. Рассмотрение оптимизации с точки зрения параллелизма, кластерности, улучшения машин, на которых всё запускается, не входит в нашу задачу. В частности, в зависимости от всех этих параметров могут получиться совершенно иные результаты, и конкретный подход лучше выбирать на железе, аналогичном предполагаемому к использованию в продуктивной среде. В данном случае при строительстве стенда мы априорно стремимся к тому, чтобы узким местом в системе была производительность выполнения операций в Clickhouse.

Для такого теста также важно, какие данные будут проходить через систему.

Будем использовать два профиля: первый — исключительно insert’ы. На этом профиле мы не будем использовать «тяжелых» операций при записи в Clickhouse, и все архитектуры должны показать себя одинаково хорошо.

Второй профиль — 40% вставки, 40% обновлений и 20% удалений.

В реальной жизни профили зависят от того, что происходит в продуктивной базе, от специфики нагрузки, но даже базовая оценка распределения операций по типам достаточна для проведения теста.

Ось X — количество записей в батче, выполненном в MongoDB, ось Y — количество обработанных записей в секунду (rps)

Как видно из диаграммы, rps растут в зависимости от количества записей, это означает, что все реализации обладают достаточно большим overhead’ом на инициализацию. Есть способы избавиться от его влияния на результаты. Например, можно «прогреть» систему или делать замеры на постоянном потоке обновлений в MongoDB.

На первом профиле данных простая вставка в любом случае проигрывает. Проигрывает она по одной простой причине: вставка батчами всегда быстрее, чем она же по одной записи. Вставка в Clickhouse — все равно что вставка в колоночный формат, достаточно тяжелая операция.

SCD2 — просто insert’ы, они делались в данном случае батчами, batch size был достаточно большим (записи в Kafka, пришедшие за секунду), поэтому можно даже сравнить, насколько подобная оптимизация ускоряет работу пайплайна.

При табличном обновлении запись в кэш происходит быстро, но запись непосредственно в Clickhouse достаточно медленная, потому что приходится перезаписывать все данные каждый раз на каждый батч (также записи в Kafka, пришедшие за секунду). Если мы сначала все сохраним в кэш, а потом все сразу запишем в целевое хранилище, высота столбика должна получиться примерно такой же, как в SCD2.

Важно! В данном сравнительном анализе не учитывается время, которое будет затрачено на выборку конечного результата в Clickhouse. Запросы, требующие создания слепка данных в модели SCD2, конечно, будут работать медленнее, чем в других вариантах архитектур.

На втором профиле результаты другие. Столбик с простым применением существенно просел за счет того, что операции обновления и удаления существенно дольше выполняются. Остальные столбики, в принципе, остались примерно такими же, что говорит о том, что вне зависимости от профиля данных SCD2 будет работать примерно одинаково. Это даёт некую надежду на универсальность и отсутствие необходимости считать этот профиль каждый раз для каждой нагрузки.

Что в итоге

В сравнительной таблице приведены ещё несколько факторов, которые будут достаточно важными для принятия решения об использовании той или иной архитектуры:

сложность разработки,

производительность на вставку,

производительность обновления,

скорость запросов,

толерантность к горячей секции,

задержка доставки данных до источника.

У каждой архитектуры есть свой недостаток.

Выбор надо делать, исходя из того, что именно требуется максимизировать: если важна скорость доставки, то, конечно, выбор за SCD2, но для выборки актуальной версии данных потребуются запросы с оконными функциями или self-join’ы, или надо будет сделать еще один батчовый шаг по обновлению слепка данных на определённое время.

Если же важна сложность разработки, требуется быстро внедрить пайплайн для проверки какой-нибудь гипотезы, то почему бы не воспользоваться стандартным API, это достаточно быстро.

С кэшем получается и дорого, и больно, но зато сразу получается слепок, к которому можно писать запросы.

Финал

Конечно же, однозначного ответа не получилось. Серебряной пули опять не существует, а каждому гвоздю требуется свой молоток. Оказалось, что даже в сильных ограничениях на технологии, которые были введены в этом посте, есть вариативность при выборе архитектуры решения, что удалось наглядно показать, используя данные."'https://habrastorage.org/getpro/habr/upload_files/e33/456/d80/e33456d809e597624ea17edc52a2991f.png'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
11'719430'Солнечный парк Дубая'Возобновляемые источники энергии многие люди считают одним из способов уменьшения последствий изменения климата. Одним из крупнейших проектов в данной области, реализуемым в южной пустыне Дубая,...'https://habr.com/ru/post/719430/'"Возобновляемые источники энергии многие люди считают одним из способов уменьшения последствий изменения климата. Одним из крупнейших проектов в данной области, реализуемым в южной пустыне Дубая, является Солнечная электростанция Мохаммеда бин Рашида Аль Мактума.

Парк солнечных батарей, уходящих за горизонт

Солнечный парк Дубая: общая информация

Парк солнечных батарей является уникальным проектом, который реализуется на площади в 44 квадратных километра. Он оснащен миллионами фотоэлектрических панелей, преобразующих солнечный свет в электроэнергию мощностью 1000 МВт в час и обеспечивающих питание более 320 000 домов.

Решение о строительстве солнечного парка было объявлено Его Высочеством Мохаммедом ибн Рашидом Аль Мактумом в 2012 году. Реализацию данного проекта осуществляет Управление по электричеству и воде Дубая DEWA с привлечением частного капитала размером примерно 40 миллиардов дирхам (правовая база Дубая позволяет участие частного сектора в подобных проектах)

Этапы строительства

Первая очередь парка была введена в эксплуатацию 22 октября 2013 года, ее мощность составила 13 МВт.

Строительство второй очереди парка солнечных батарей длилось до марта 2017 года. В результате запуска 2,3 миллионов солнечных панелей стало вырабатываться 200 МВт энергии.

Реализация третьей фазы проекта мощностью 800 МВт началась в 2015 году.

Строительство четвертого этапа электростанции завершилось в 2022 году. Солнечный парк в 2019 году обеспечивал 3% от общего энергоснабжения в эмирате (на данный момент - 11,4%). До запуска электростанции основным источником энергии выступал природный газ.

В ближайшие пару лет парк солнечных батарей должен завершить пятую фазу. По прогнозам специалистов, она позволить снизить выбросы углерода на 6,5 миллионов в год. В рамках данного проекта будет построена крупнейшая в мире башня концентрированной солнечной энергии. Ее высота составит 260 метров, для получения энергии будут использоваться 70 000 гелиостатов. Такая конструкция обеспечит преобразование энергии солнечного света в тепловую, а также ее хранение в течение 15 часов.

Башня будет вырабатывать 700 МВт энергии, что позволит обеспечить чистой энергией более 270 000 домов и сократить объем выделяемого углекислого газа на 1,4 млн тонн в год. Ожидается, что к концу 2023 года мощность солнечного парка составит 5000 МВт.

Зачем все это

В октябре 2022 года в ОАЭ была принята стратегическая инициатива по достижению к 2050 году нулевых углеродных выбросов, что обеспечит эмират экологически чистой энергией на 100%.

Специалисты DEWA отмечают, что для достижения данной цели потребуется производить более 42 000 МВт возобновляемой энергии.

Кроме того DEWA уже 5 лет подряд получает самые низкие цены в мире на солнечную энергию (Levelized Cost of Energy или LCOE). К сожалению, наиболее свежие данные нашел только за 2020 год - 13,5 у.е./МВт

Посещение парка

Где еще можно посетить электростанцию Будущего? Конечно в Дубае!

Парк солнечной энергетики в Дубае открыт для посещения, на его территории работает Центр исследований и разработок, а также Инновационный центр, одной из задач которого является повышение осведомленности населения и который можно посетить всей семьей.

Площадь здания составляет 4 355 кв. метров выставочного пространства, на котором представлено:

выставочная зона, посвященная истории развития водоснабжения и электрификации в Дубае, инновационным изобретениям в данной области

30 интерактивных экспонатов, демонстрирующих разработки в сфере возобновляемых источников энергии. ( в том числе установки для опреснения воды)

выставка компонентов фотоэлектрической солнечной энергии. Связанные с ней технологии используются в спутниках и космических кораблях, ветряных турбинах, электромобилях и зданиях, о принципах их действия рассказывают гостям центра.

Инновационный парк солнечных батарей открывает свои двери для посетителей с воскресенье по четверг, он работает с 08:30 до 14:30 часов. Забронировать посещение центра инноваций можно на официальном сайте.

Если Вам понравилась информация, интересна жизнь в Дубае, инновации и инициативы этого города - буду благодарен за подписку на мой ТГ-канал Домохозяин в Дубае . Размещаю там статьи, которые не подходят по формату на Хабр (но вписываются в VC и Дзен)"'https://habrastorage.org/getpro/habr/upload_files/ee6/690/8a7/ee66908a77e46ad3e3adb0014c03e7d0.jpg'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
12'719420'Instagram* сможет работать без VPN?'Авторы приложения тестируют модуль обхода блокировок в странах-цензорах Популярная социальная сеть была запрещена в России в 2022 году. Для многих поклонников приложения это стало настоящим ударом, а...'https://habr.com/ru/post/719420/'"Авторы приложения тестируют модуль обхода блокировок в странах-цензорах

Популярная социальная сеть была запрещена в России в 2022 году. Для многих поклонников приложения это стало настоящим ударом, а трафик Instagram* понес огромные потери: по данным Brand Analytics на октябрь 2022 года, количество авторов (блогеров) сократилось с 38 млн до 17 млн за год, а количество отправленных сообщений упало со 135 млн до 40 млн за тот же период. Теперь, вероятно, владельцы соцсети ищут новые способы вернуть свою аудиторию. Одним из них может стать работа Instagram* с уже встроенным модулем обхода блокировок в странах-цензорах.

Что использует Instagram*

Во время тестирования обновленной версии приложения Instagram* одним из сотрудников компании i2crm было установлено, что приложение работает в обычном режиме без использования VPN-сервиса. Для выяснения причины компания обратилась к стороннему специалисту по реверс-инжинирингу. В результате реверса мобильного приложения удалось обнаружить, что в Android-версии Instagram* 260.0.0.23.115 arm64 появился модуль Psiphon .

Что такое реверс-инжиниринг Реверс-инжиниринг (обратная разработка) — это исследование некоторого готового устройства или программы, а также документации на него, с целью понять принцип его работы.

Реверс-инжиниринг приложения: как именно был обнаружен модуль Psiphon

Сервис Psiphon имеет открытый код, который опубликован на веб-хостинге для IT-проектов GitHub. Для обнаружения модуля, прежде всего, необходимо было ознакомиться с документацией по внедрению модуля в Android-приложение:

Было установлено, что для работы модуля Psiphon на смартфоне требуется несколько условий, а именно:

Разрешения для работы с сетью в AndroidManifest.xml .

Java код.

Нативная библиотека .

Вызов java-кода Psiphon модуля из java-кода Instagram*.

Первый этап

С помощью архиватора 7-zip был открыт apk-файл Instagram*, в котором были обнаружены файлы.

Среди этих данных были интересны:

AndroidManifest.xml — он предоставляет подробную информацию о приложении;

файлы classes.dex — classes9.dex — это скомпилированный java-код;

папка lib — нативные библиотеки.

Файл AndroidManifest.xml содержит много информации о приложении, но в данной ситуации специалистов интересовали разрешения на доступ в сеть. Так как приложение Instagram* активно использует интернет-соединение, то проверку разрешений можно пропустить, сделав вывод, что условие по доступу в сеть выполняется.

Второй этап: Java-код

Далее требовалась распаковка apk-файла в декомпиляторе Bytecode-viewer . В нем был обнаружен класс модуля Psiphon .

На этом этапе Java-часть в apk-файле Instagram* была обнаружена, что подтвердило второе условие для поддержки модуля Psiphon.

Данное расширение указывало на то, что файл является скомпилированным (преобразованным) java-кодом. Чтобы понять, что внутри java-кода, специалистам потребовалось преобразовать его в исходный вид, т.е. декомпилировать. В изначальном java-коде и был обнаружен модуль для обхода блокировок Psiphon.

Третий этап: работа с нативной библиотекой

«Заглянуть» внутрь java-кода и обнаружить класс модуля Psiphon удалось с помощью Bytecode-viewer. Реверс apk-файла позволил найти dex-файлы, а при их последующей декомпиляции обнаружить класс модуля Psiphon .

Далее, чтобы понять, как обеспечивается работа модуля на Android, необходимо было найти java-метод, который загружает нативную библиотеку. Когда этот метод был найден, специалисты занялись поиском нативной библиотеки. С ее помощью нужно было установить, какая часть кода отвечает за загрузку этой библиотеки на смартфон.

Нативная библиотека для 64-разрядных arm-процессоров в репозитории располагается также в открытом доступе на GitHub здесь и имеет имя «libtun2socks.so».

Для подтверждения использования модуля специалисты исследовали java-код и обнаружили метод «startRouting()», который отвечает за загрузку нативной части модуля.

В методе «startRouting()» был обнаружен интерфейс, в который передается имя нативной библиотеки. Сам интерфейс использует системный Android api-метод « loadLibrary() ». Этот метод является кодом самого Android и отвечает за загрузку нативной библиотеки в память устройства и делает ее экспортированные функции доступными для java-кода. В свою очередь это дает возможность взаимодействия со скомпилированным С/С++ кодом из java.

Вот так выглядит та же функция в декомпилированном java-коде:

При распаковке приложения расположение библиотек в каталоге обычно выглядит так: lib\<архитектура процессора>.

Однако по данному пути libtun2socks.so обнаружить не удалось. Поэтому пришлось заглянуть assets\lib, где приложение Instagram* также может хранить нативные библиотеки.

В папке находились два файла:

libs.spo -— архив с библиотеками;

metadata.txt — перечень библиотек с указанием sha-256 хэша и размера каждого файла.

Но и в metadata.txt нативная библиотека снова не была обнаружена. Все, что было известно изначально — Instagram* при первом запуске приложения автоматически распаковывает архив libs.spo в защищенную часть памяти устройства /data/data/com.instagram.android/lib-compressed/.

Таким образом, третье условие было не выполнено (наличие нативной библиотеки libtun2socks.so ). Из первых трех условий можно сделать вывод, что использование модуля невозможно из-за отсутствия ключевой библиотеки.

Специалисты решили проверить, добавили ли разработчики только код модуля или уже начали его активное внедрение.

Вызов java-кода Psiphon-модуля из java-кода Instagram* на примере установки в Android-приложение

Чтобы понять, как именно устанавливается модуль Psiphon в Android-приложение, можно рассмотреть пример из открытых источников

Создание модуля происходит с помощью метода newPsiphonTunnel(), его код выглядит так:

Метод newPsiphonTunnelImpl() выглядит так:

При установке модуля в Android встречается еще одна нативная библиотека gojni. При реверс-инжиниринге она не была замечена. При повторном изучении репозитория был обнаружен maven aar - модуль для интеграции Psiphon в проекты Android Studio.

Далее при открытии aar-файла архиватором 7-Zip специалисты нашли искомую библиотеку и ресурсы.

На основании этого можно сделать такой вывод: для работы Psiphon модуля требуется libtun2socks.so и libgojni.so.

После проведенных установок специалисты снова вернулись к Instagram* и зафиксировали пути, где хранятся библиотеки:

/data/data/com.instagram.android/lib-compressed/

<apk>/lib/<архитектура процессора> Библиотека вновь не была обнаружена. Тогда была сделана попытка найти Instagram*- код, который ссылается на метод newPsiphonTunnel().

При этой операции был найден вызов из кода Instagram* искомого Psiphon модуля. Данное исследование с установкой модуля Psiphon в Android показало, что в целом модуль не используется полноценно, а, как и предполагалось, находится на этапе внедрения. Вероятно, этот сервис компания Meta* может использовать в дальнейшем для того, чтобы избежать блокировок Instagram* со стороны стран-цензоров.

Что представляет собой сервис Psiphon?

VPN-сервис Psiphon разработан в 2006 году в Университете Торонто. Он предназначен для обхода цензуры со стороны госрегуляторов в таких странах, как Китай и Иран. Подробно о принципах работы VPN-сервисов можно прочитать в этой статье .

Psiphon имеет сложный механизм, и его трафик почти невозможно поймать, например, через системы фильтрации DPI. Он предоставляет доступ в интернет через прокси-сервер в другой стране, а если сервер становится недоступным, то меняет его автоматически. Теперь, по-видимому, Instagram* решил «зашить» модуль обхода блокировок непосредственно в приложение, чтобы избавить пользователей от необходимости искать варианты зайти в него.

Опасен ли модуль Psiphon с точки зрения передачи данных между пользователями Instagram*? Его создатели могут видеть домены, к которым происходит доступ, но не могут видеть пользовательские данные. Это объясняется тем, что модуль — это локальный прокси-сервер, на который перенаправляется зашифрованный Instagram*-трафик. Однако для его чтения недостаточно перехвата, требуется еще расшифровка. Иными словами, модуль может получать данные в обобщенном виде и использовать, например, для настройки рекламного трафика, но не может получать историю браузера и файлов cookies.

Почему Instagram* не использует методы Telegram

Трафик Instagram* блокируется с 14 марта 2022 года интернет-провайдерами России по требованию Генпрокуратуры РФ. Приложение не может самостоятельно обходить блокировки, как это делает Telegram, используя разные IP-адреса.

Telegram для обхода блокировок использует моментальное изменение IPv4-адресов на хостингах Amazon, Google, DigitalOcean. Если заблокировать эти адреса принудительно, то неизбежно произойдет сбой в работе других сайтов и приложений, базирующихся на данных хостинга. Этот способ не используется в Китае, где перечисленные сервера заблокированы госрегулятором.

Также Telegram использует IPv6-адреса, которые регулирующие органы пока не умеют массово выявлять и блокировать. Еще одним способом защиты от возможных блокировок является возможность proxy-подключений через протоколы SOCKS5 и MTProto и ботов автоматической настройки от провайдеров услуг proxy и VPN.

Передача сообщений между пользователями Telegram осуществляется напрямую по протоколу P2P с использованием встроенного Proxy, подобного Tor. Заблокировать такой протокол возможно лишь по конечным IP-адресам пользователей, то есть фактически отключив от сети всех.

Заключение

Исследование работы модуля Psiphon в Android-версии Instagram* 260.0.0.23.115 arm64 было проведено двумя способами: с помощью реверс-инжиниринга приложения и методом вызова java-кода Instagram* на примере установки в Android-приложение. Изучение было проведено с помощью информации, полученной из открытых источников и ресурсов.

Специалисты установили, что в настоящее время модуль не используется полноценно. Скорее всего, он тестируется и в дальнейшем будет встроен в приложение для того, чтобы избежать блокировок Instagram* со стороны регуляторов в странах-цензорах.

*Meta Platforms Inc. (Facebook, Instagram) — признана экстремистской, ее деятельность запрещена на территории России."'https://habr.com/share/publication/719420/cadcf983c0786cbc54fd5147a47d4452/'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
13'719416'1C (и не только) c PostgreSQL'Предисловие Уже несколько лет назад я столкнулся с проблемой производительности 1С на PostgreSQL в некоторых запросах, которые на MS SQL выполнялись относительно быстро. Тогда же выяснилось, что в...'https://habr.com/ru/post/719416/'"Предисловие

Уже несколько лет назад я столкнулся с проблемой производительности 1С на PostgreSQL в некоторых запросах, которые на MS SQL выполнялись относительно быстро. Тогда же выяснилось, что в 99% случаев такие запросы можно оптимизировать так, что они начинают выполняться даже быстрее, чем на MS SQL, всего навсего добавлением нужных индексов во временные таблицы.

Решение

Тогда же было ясно, что править типовую конфигурацию совсем не хочется. Ладно еще индексы постоянных таблиц, но для добавления индексов во временные таблицы средствами 1С потребуется править код. Поэтому решено было не править конфигурацию вообще, а индексировать нужные временные таблицы на лету средствами самого PostgreSQL. Для этой цели в нем уже давно имеется такая интересная команда, как CREATE EVENT TRIGGER. В нашем случае, интересен вызов событийного триггера сразу же после создания таблицы, то есть по событию ddl_command_end.

Разберем решение в упрощенном виде. Пусть у нас создается временная таблица tmp_tmp состоящая из уникального id, и еще каких-то полей. Необходимо создать уникальный индекc по id. При этом не следует забывать, что создаваться эта временная таблица может тремя путями:

CREATE TEMP TABLE ...

CREATE TEMP TABLE AS ...

SELECT ... INTO TEMP TABLE ...

Учитывая это создаем такую функцию для создания индекса:

CREATE OR REPLACE FUNCTION build_index_on_tmp_tmp() RETURNS event_trigger LANGUAGE plpgsql AS $$ BEGIN IF EXISTS ( SELECT 1 FROM pg_event_trigger_ddl_commands() E WHERE E.object_identity='pg_temp.tmp_tmp' AND tg_tag IN ('CREATE TABLE', 'CREATE TABLE AS', 'SELECT INTO')) THEN CREATE UNIQUE INDEX IF NOT EXISTS tmp_tmp_idx ON tmp_tmp(Id); END IF; END; $$;

А вызываться эта функция будет уже из событийного триггера:

CREATE EVENT TRIGGER build_index_on_tmp_tmp_tr ON ddl_command_end EXECUTE FUNCTION build_index_on_tmp_tmp();

Теперь при создании временной таблицы tmp_tmp любым из трех перечисленных путей, таблица окажется сразу же индексирована:

DROP TABLE IF EXISTS tmp_tmp; CREATE TEMP TABLE tmp_tmp (Id int, some_text text NULL); INSERT INTO tmp_tmp(Id) SELECT generate_series(1,1000000); DROP TABLE IF EXISTS tmp_tmp; CREATE TEMP TABLE tmp_tmp AS SELECT generate_series(1,1000000) AS Id, NULL::text AS some_text; DROP TABLE IF EXISTS tmp_tmp; SELECT generate_series(1,1000000) AS Id, NULL::text AS some_text INTO TEMP TABLE tmp_tmp;

Для сравнения посмотрим на разницу без триггера и с триггером на простейшем запросе

SELECT * FROM tmp_tmp WHERE Id=500000;

С индексом получаем

Index Scan using tmp_tmp_idx on tmp_tmp (cost=0.42..2.64 rows=1 width=36) (actual time=0.030..0.031 rows=1 loops=1) Index Cond: (id = 500000) Planning Time: 0.169 ms Execution Time: 0.043 ms

Без него

Seq Scan on tmp_tmp (cost=0.00..11449.69 rows=2810 width=36) (actual time=39.425..78.025 rows=1 loops=1) Filter: (id = 500000) Rows Removed by Filter: 999999 Planning Time: 0.112 ms Execution Time: 78.045 ms

Итоги

Данный лайф-хак применим далеко не только к 1C, но и к любой другой системе, в код которой нет желания или возможности залезть. Небольшим довеском непосредственно в PostgreSQL можно решить проблемы производительности многих запросов, вынудив планировщик отправиться по индексу. Иногда это еще потребует управления статистиками, но этот вопрос уже выходит за рамки текущей статьи."'https://habrastorage.org/getpro/habr/upload_files/804/2ee/117/8042ee1176d06befa6e4ffcbc83234e5.png'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
14'712844'GSM NetMonitor для гика и преподавателя'В статье я рассмотрю, как недорого в лабораторных условиях собрать и на практике использовать GSM NetMonitor на основе открытого программного продукта Osmocom, более известного в IT-среде по проекту...'https://habr.com/ru/post/712844/'"в лабораторных условиях

OsmocomBB

▍ 1. Введение

и кому

▍ 2. Tutorial для гика

софтфона

~/osmocombb/src/host/osmocon/osmocon -p /dev/ttyUSB0 -m c123xor -c ~/osmocombb/src/target/firmware/board/compal_e88/layer1.highram.bin -p /dev/ttyUSB0 – интерфейс подключения телефона -m c123xor – режим работы протокола, загружаемого в телефон -c ~/osmocombb/src/target/firmware/board/compal_e88/layer1.highram.bin - прошивка

~/osmocombb/src/host/layer23/src/mobile/mobile -i 127.0.0.1

telnet 127.0.0.1 4247

show running-config Current configuration: ! ! line vty настройки консоли no login доступ без авторизации ! gps device /dev/ttyACM0 настройки GPS gps baudrate default no gps enable ! no hide-default настройки отображения конфигурации ! ms 1 описание mobile station 1 layer2-socket /tmp/osmocom_l2 sap-socket /tmp/osmocom_sap sim reader network-selection-mode auto режим выбора сети imei 000000000000000 0 imei imei-fixed no emergency-imsi no sms-service-center номер SMS-центра no call-waiting настройки вызова no auto-answer no force-rekey no clip no clir tx-power auto управление мощностью no simulated-delay no stick location-updating управление работой с сотовой сетью neighbour-measurement codec full-speed prefer настройки вокодеров codec half-speed no abbrev support поддерживаемые режимы sms a5/1 a5/2 p-gsm e-gsm r-gsm no gsm-850 dcs no pcs class-900 4 class-850 4 class-dcs 1 class-pcs 1 channel-capability sdcch+tchf+tchh поддержка логических каналов full-speech-v1 full-speech-v2 half-speech-v1 min-rxlev -106 минимальный уровень приёма dsc-max 90 no skip-max-per-band exit test-sim настройки SIM-модуля imsi 001010000000000 (это целое отдельное устройство внутри телефона) no barred-access no rplmn hplmn-search foreign-country exit no shutdown exit ! end



nano /home/Mike/.osmocom/bb/mobile.cfg

enable show ms show cell 1 showsubscriber 1

Команды cli help вызов справки Mobile list вывод перечня поддерживаемых команд writeterminal запись назначенных параметров в память софтфона writefile запись назначенных параметров в файл writememory запись назначенных параметров в оперативную память show running-config вывод текущей конфигурации Mobile exit выход из текущей сессии telnet и запуск сессии с параметрами по умолчанию disable отключить командный режим configureterminal изменить конфигурацию софтфона copyrunning-configstartup-config использовать текущую конфигурацию софтфона в качестве конфигурации по умолчанию showstartup-config показать конфигурацию по умолчанию showversion показать текущую версию Osmocom showonline-help показать справку онлайн terminallength<0-512> назначение количества выводимых строк terminalnolength вывод неограниченного количества строк showhistory история вводимых команд terminalmonitor перевод софтфона в режим мониторинга terminalnomonitor отключение мониторинга софтфона сети связи showms [MS_NAME] вывод характеристик сети связи showsubscriber [MS_NAME] вывод характеристик, записанных в SIM-карту софтфона showsupport [MS_NAME] вывод поддерживаемых сетью связи технологий showcell MS_NAME вывод характеристик базовой станции showcell MS_NAME <0-1023> [pcs] сканирование каналов базовых станций и вывод их характеристик showneighbour-cell MS_NAME вывод списка соседей для текущей базовой станции showba MS_NAME [MCC] [MNC] вывод списка частот, используемых текущей сетью связи show forbidden location-area MS_NAME вывод текущей зоны местоположения showforbiddenplmn MS_NAME вывод значений MCC и MNC, на которых настроен софтфон monitornetwork MS_NAME перевод софтфона в режим мониторинга заданной сети nomonitornetwork MS_NAME отключение мониторинга софтфона заданной сети off отключение софтфона simtestcard MS_NAME MCC MNC LAC TMSI attached передача параметров зоны местоположения и временного номера софтфону simreader MS_NAME присоединение SIM-карты софтфона к устройству SIM Reader simremove MS_NAME отсоединение SIM-карты софтфона от устройства SIM Reader sim pin MS_NAME PIN установка PIN-кода sim disable-pin MS_NAME PIN отключение PIN-кода sim enable-pin MS_NAME PIN включение PIN-кода sim change-pin MS_NAME OLD NEW изменение PIN-кода sim unblock-pin MS_NAME PUC NEW разблокировка PIN-кода simlai MS_NAME MCC MNC LAC присвоение софтфону зоны местоположения network search MS_NAME поиск сети связи networkshow MS_NAME отображение параметров сети связи network select MS_NAME MCC MNC [force] выбор сети связи call MS_NAME (NUMBER|emergency|answer|hangup|hold) осуществление вызова call MS_NAME retrieve [NUMBER] осуществление повторного вызова call MS_NAME dtmf DIGITS осуществление вызова по технологии DTMF sms MS_NAME NUMBER .LINE отправка SMS-сообщения service MS_NAME (*#06#|*#21#|*#67#|*#61#|*#62#|*#002#|*#004#|*xx*number#|*xx#|#xx#|##xx#|STRING|hangup) отправка USSD-запроса deleteforbiddenplmn NAME MCC MNC удаление параметров зоны местоположения



show ms % (MS 1) % Trying to registering with network... 1 MS '1' is up, service is limited (pending) IMEI: 000000000000000 IMEISV: 0000000000000000 IMEI generation: fixed automatic network selection state: A1 trying RPLMN MCC=XXX MNC=XXX cell selection state: C3 camped normally ARFCN=715(DCS) MCC=XXX MNC=XX LAC=0xXXXX CELLID=0xXXXX radio ressource layer state: idle mobility management layer state: MM idle, attempting to update



Таблица ARFCN для GSM-900 и 1800



show subscriber 1 Mobile Subscriber of MS '1': IMSI: XXXXXXX ICCID: XXXXXXXXX Service Provider Name: XXXXXXX Status: U1_UPDATED IMSI detached TMSI 0xXXXXXX LAI: MCC XXX MNC XX LAC 0xXXXX Key: sequence 0 8f 30 d7 21 bc 1a 24 6c Registered PLMN: MCC XXX MNC XX Access barred cells: no Access classes: C3 List of preferred PLMNs: MCC |MNC -------+------- XXX |XX



Mobile Subscriber of MS '1': No SIM present.

show cell 1 76 ARFCN = 76 channels 512+ refer to DCS (1800) Available SYSTEM INFORMATIONS = 2 3 SI2 (neigh.) BA=0: 53,57,62,67,73,113 0 .....................................................n...n....n. 63 64 ...n.....n.......................................n........... 127 128 191 192 255 256 319 320 383 384 447 448 511 512 ................................................................ 575 576 ................................................................ 639 640 ................................................................ 703 704 ................................................................ 767 768 ................................................................ 831 832 ...................................................... 895 896 ..... 959 960 ................................................................ 1023 'S' = serv. cell 'n' = SI2 (neigh.) 'r' = SI5 (rep.) 'b' = SI2+SI5 Serving Cell: BSIC = 0,5 MCC = XXX MNC = XX LAC = XXXX Cell ID = XXXX Country = XXXXXXXX Network Name = XXXXX MAX_RETRANS = 4 TX_INTEGER = 32 re-establish = allowed Cell barred = no barred classes = CBQ = 0 CRO = 0 TEMP_OFFSET = 0 PENALTY_TIME = 0 NCC Permitted BCCH = 0 1 2 3 4 5 6 7 Neighbor Cell: MAX_RETRANS = 4 TX_INTEGER = 32 re-establish = allowed Cell barred = no barred classes = MX_TXPWR_MAX_CCCH = 5 CRH = 6 RXLEV_MIN = -102 NECI = 1 ACS = 0 BCCH link timeout = 52 DTX = 1 PWRC = 1 SACCH link timeout = 0 DTX = 0 PWRC = 0 CCCH Config = 1 CCCH BS-PA-MFMS = 2 Attachment = allowed BS-AG_BLKS_RES = 2 T3212 = 21600 sec. chan_nr = 0x00 TSC = 0 ARFCN = 0



show neighbour-cells 1 Serving cell: ARFCN=619(DCS) RLA_C=-59 C1=43 C2=43 LAC=XXXXX Neighbour cells: # |ARFCN |RLA_C |C1 |C2 |CRH |prio |LAC |cell ID|usable |state --------------------------------------------------------------------------------------- 1 | 553 | -75 | 20 | 20 | 0 |normal |0xXXXX |0xXXXX |yes |SYSINFO 2 | 53 | -77 | 25 | 25 | 0 |normal |0xXXXX |0xXXXX |yes |SYSINFO 3 | 520 | -77 | 25 | 25 | 0 |normal |0xXXXX |0xXXXX |yes |SYSINFO 4 | 113 | -78 | 24 | 24 | 0 |normal |0xXXXX |0xXXXX |yes |SYSINFO 5 | 76 | -81 | 21 | 21 | 0 |normal |0xXXXX |0xXXXX |yes |SYSINFO 6 | 529 | -83 | 12 | 12 | 0 |normal |0xXXXX |0xXXXX |yes |SYSINFO --- unmonitored cells: --- 7 | 74 | -85 | 17 | 17 | 0 |normal |0xXXXX |0xXXXX |yes |SYSINFO 8 | 631 | -85 | 17 | 17 | 0 |normal |0xXXXX |0XXXXX |yes |SYSINFO 9 | 512 | -101 |- |- |- |- |- |- |no |RLA_C 10 | 515 | -98 |- |- |- |- |- |- |no |RLA_C 11 | 517 | -91 |- |- |- |- |- |- |no |RLA_C 12 | 521 | -87 |- |- |- |- |- |- |no |RLA_C 13 | 616 | -92 |- |- |- |- |- |- |no |RLA_C 14 | 623 | -101 |- |- |- |- |- |- |no |RLA_C



show ba 1 Band Allocation of network: MCC XXX MNC XX 53 74 76 113 512(DCS) 515(DCS) 517(DCS) 520(DCS) 521(DCS) 529(DCS) 553(DCS) 616(DCS) 619(DCS) 623(DCS) 624(DCS) 628(DCS) 631(DCS) Band Allocation of network: MCC XXX MNC XX 77 82 85 88 89 91 94 95 97 99 100 102 104 680(DCS) 682(DCS) 764(DCS) 765(DCS) 767(DCS) 770(DCS) 776(DCS) 777(DCS) 778(DCS) 779(DCS) 782(DCS) 790(DCS) 793(DCS) 802(DCS) 807(DCS) 810(DCS) Band Allocation of network: MCC XXX MNC XX 26 28 30 31 37 38 40 45 46 48 51 640(DCS) 641(DCS) 649(DCS) 656(DCS) 711(DCS) 715(DCS) 717(DCS) 719(DCS) 721(DCS) 723(DCS) 724(DCS) 729(DCS) 735(DCS) 736(DCS) 740(DCS) 741(DCS) 742(DCS) 752(DCS) 753(DCS)



osmo-bts.cfg phy 0 instance 0 osmotrx ms-power-loop -65 osmotrx legacy-setbsic bts 0 band 1800 ipa unit-id 1801 0 oml remote-ip 127.0.0.1 trx 0 phy 0 instance 0



openbsc.cfg e1_input e1_line 0 driver ipa network network country code ХХХ mobile network code ХХ short name ХХХ long name ХХХ auth policy accept-all location updating reject cause 13 encryption a5 0 neci 1 rrlp mode none mm info 1 handover 0 handover window rxlev averaging 10 handover window rxqual averaging 1 handover window rxlev neighbor averaging 10 handover power budget interval 6 handover power budget hysteresis 3 handover maximum distance 9999 bts 0 type sysmobts band DCS1800 cell_identity XXXX location_area_code XXXXX training_sequence_code 7 base_station_id_code XX ms max power 15 cell reselection hysteresis 4 rxlev access min 0 channel allocator ascending rach tx integer 9 rach max transmission 7 ip.access unit_id 1801 0 oml ip.access stream_id 255 line 0 gprs mode none trx 0 rf_locked 0 arfcn 514 nominal power 23 max_power_red 30 rsl e1 tei 0 timeslot 0 phys_chan_config CCCH+SDCCH4 hopping enabled 0 timeslot 1 phys_chan_config SDCCH8 hopping enabled 0 timeslot 2 phys_chan_config TCH/F hopping enabled 0 timeslot 3 phys_chan_config TCH/F hopping enabled 0 timeslot 4 phys_chan_config TCH/F hopping enabled 0 timeslot 5 phys_chan_config TCH/F hopping enabled 0 timeslot 6 phys_chan_config TCH/F hopping enabled 0 timeslot 7 phys_chan_config TCH/F hopping enabled 0



хаотичного жима клавиш клавиатуры

testcard MS_NAME MCC MNC LAC TMSI attached

туда-сюда

show cell 1 ARFCN |MCC |MNC |LAC |cell ID|forb.LA|prio |min-db |max-pwr|rx-lev -------+-------+-------+-------+-------+-------+-------+-------+-------+------- 27 |XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 5 |-73 28 |XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 5 |-78 30 |XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 5 |-83 31 |XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 5 |-80 32 |XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 5 |-81 36 |XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 5 |-79 38 |XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 5 |-83 46 |XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 5 |-67 51 |XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 5 |-82 53 |XXX |BB |0xXXXX |0xXXXX |no |normal |-102 | 5 |-83 61 |XXX |BB |0xXXXX |0xXXXX |no |normal |-102 | 5 |-80 76 |XXX |BB |0xXXXX |0xXXXX |n/a |n/a |-102 | 5 |-98 97 |XXX |CC |0xXXXX |0xXXXX |no |normal |-104 | 5 |-82 100 |XXX |CC |0xXXXX |0xXXXX |no |normal |-104 | 5 |-73 113 |XXX |AA |0xXXXX |0xXXXX |n/a |n/a |-102 | 5 |-94 520DCS|XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 0 |-78 529DCS|XXX |AA |0xXXXX |0xXXXX |n/a |n/a | -95 | 0 |-86 553DCS|XXX |AA |0xXXXX |0xXXXX |no |normal | -95 | 0 |-75 554DCS|XXX |AA |0xXXXX |0xXXXX |no |normal |-102 | 0 |-83 616DCS|XXX |BB |0xXXXX |0xXXXX |n/a |n/a | -95 | 0 |-89 631DCS|XXX |BB |0xXXXX |0xXXXX |no |normal |-102 | 0 |-86 641DCS|XXX |BB |0xXXXX |0xXXXX |no |normal |-102 | 0 |-86 715DCS|XXX |CC |0xXXXX |0xXXXX |no |normal |-102 | 0 |-77 736DCS|XXX |CC |0xXXXX |0xXXXX |no |normal |-102 | 0 |-86 741DCS|XXX |CC |0xXXXX |0xXXXX |no |normal |-102 | 0 |-84 764DCS|XXX |CC |0xXXXX |0xXXXX |no |normal |-100 | 0 |-86



~/osmocombb/src/host/layer23/src/misc/cell_log

~/osmocombb/src/host/layer23/src/misc/ccch_scan -a 741 -i 127.0.0.1

~/osmocombb/src/host/layer23/src/misc/bcch_scan -i 127.0.0.1

~/osmocombb/src/host/layer23/src/misc/cbch_sniff -a 741 -i 127.0.0.1

▍ 3. Tutorial для преподавателя

специалистом

▍ 4. Заключение

В статье я рассмотрю, как недорогособрать и на практике использовать GSM NetMonitor на основе открытого программного продукта Osmocom, более известного в IT-среде по проекту OpenBTS, позволяющему создавать персональные базовые станции. Так, входящая в его состав программапомогает узнать большое количество различных технических характеристик, задействованных в стеке GSM-протоколов для удовлетворения личного исследовательского интереса. В образовательной среде она поможет понять и на практике изучить работу рассматриваемых телекоммуникационных сетей, на которых в той или иной степени базируются определённые 3G, 4G и 5G-решения. Чтобы минимизировать заимствования из схожих публикаций, материал носит практический характер (за редким исключением). Дополнительно я раскрою явным образом недокументированную, но полезную возможность рассматриваемого программного обеспечения по одновременному NetMonitor сигналов от различных операторов.Интерес к устройству сетей сотовой связи, внешние элементы которых знакомы каждому, давно прямо или косвенно привёл к появлению общедоступных баз данных , содержащих технические характеристики базовых станций различных сетей. На основе информации из этих источников наши мобильные устройства могут осуществлять геолокацию без необходимости вычисления GPS-координат, а в условиях плотной городской застройки, когда вычисленные GPS-координаты сильно отличаются от действительных, выступают в качестве источника дополнительной информации для повышения достоверности местоопределения. Наполнение полезной информацией осуществляется с помощью людей, намеренно или непреднамеренно передающих геолокационную информацию куданужно. Доступ пользователей к подобным данным обычно называется NetMonitor и может быть реализован с помощью внешнего программного обеспечения для Android или встроенного и глубоко интегрированного в iOS нативного приложения ().Инженерно-технический персонал операторов сотовой связи в своей профессиональной деятельности использует куда более прокаченные девайсы с ошеломляющей обычного человека стоимостью и соответствующим этой стоимости функционалом. Однако вернёмся к открытому программному обеспечению. Проект OpenBTS неоднократно и достаточно подробно разбирался на Хабре, например (из классики), публикация 1 публикация 3 . При этом до сих пор эта тема вызывает определённый интерес в сообществе, что видно из обсуждений статьи , опубликованной в начале года.Кроме всего того, что уже разобрано, OsmocomBB позволяет недорого и увлекательно покопаться в технических аспектах работы сетей сотовой связи 2-го поколения стандарта GSM, реализуя ряд протоколов управления и передачи соответствующих команд на совместимые с ним модели телефонов Motorola (, приобрести их можно в подземных переходах, на eBay или Авито). Для подключения к компьютеру можно применять платы сопряжения интерфейсов UART и USB, например, модель P2102. Для этого традиционно кабель подключения к телефону Motorola собирается на коленках. Программную часть можно установить самостоятельно (всё-таки свободный софт), или поискать готовые образы для Raspberry.Для понимания возможностей OsmocomBB представим его в качестве виртуального сотового телефона (), в котором реализованы канальный, сетевой и прикладной уровни абонентского оборудования. В составе имеется прога Mobile, отвечающая за управление софтфоном посредством telnet. При этом сам телефон непосредственно реализует физический уровень. Загрузка в Motorola L1 прошивки осуществляется следующей командой:L2 и L3 активируются так:Далее управление осуществляется посредством CLI:По умолчанию конфиг для мобилы выглядит следующим образом:При желании его можно отредактировать:Далее активируется командный режим, и после возможно выполнение предустановленных команд:В прошлом проект Osmocom активно развивался, поэтому изменялись команды, передаваемые на софтфон, а некоторые сегодня имеют дублирующие функции:Чтобы посмотреть состояние софтфона, определить MCC (код страны —) и MNC (условный код, закреплённый за оператором), к которому выполнено подключение, а также ARFCN (номер частотного / физического канала), LAC (номер района, объединяющего несколько базовых станций) и CELLID текущей базовой станции (цифровой код сектора), выполняем следующее:DCS означает, что сотовый подключён к базовой станции, работающей в диапазоне 1800 МГц. Это также понятно из значения ARFCN. Кстати, написанные вместе MCC + MNC + LAC = LAI (международный идентификатор зоны местоположения). Ниже приведу соответствие значений ARFCN его физическим величинам (МГц):Увидеть значения IMSI (15-значный десятичный номер, закреплённый оператором за своим пользователем), временного номера TMSI (16-ричный номер, который меняется от LAI к LAI для сохранения приватности), сеансового ключа шифрования (симметричный ключ шифрования):1 – это порядковый номер mobile station. Тот же вывод, если в Motorola не вставлена SIM-карта, будет выглядеть следующим образом:Как раз приведённое выше значение ключа шифрования () может быть использовано для расшифровки собственного трафика в среде разработки GNU Radio при применении флоуграфа gr-gsm . На иллюстрации ниже я отправил SMS с текстом, записал радиосигнал с помощью SDR-приёмника и указанного флоуграфа, декодировал и дешифровал первоначальный текст:Можно получить подробную информацию о работе конкретной соты и увидеть псевдографическое представление частотной сетки (76 – это номер рабочей частоты соты). Легенда для схемы прилагается:Странные аббревиатурыи т. п. являются не чем иным, как сокращением от имени служебных сообщений system information type , применяемых в системе связи. Получить подробную информацию о соседних с сотой базовых станциях, так называемый, можно следующим образом:RLA_C — это уровень принимаемого сигнала, С1 и С2 — это вычисляемые качественные показатели , на основании которых мобила выполняет переключение между сотами. Отличная возможность разобраться на практике с хендовером. Ещё одна команда про то же самое — показатьКакого-то практического применения этой информации я не вижу. Позволю себе немного отклониться от темы и без излишней детализации показать, что может настраиваться непосредственно на базовой станции, а что на контроллере, управляющем их группой. Многие параметры уже знакомы по результатам NetMonitor. Ниже представлен конфигурационный файл для проекта OsmoBTS, в котором видно, что на базе особо нечего задать:А это пример конфигурации OpenBSC (контроллера), где как раз есть чем заняться. В нашем распоряжении: MCC, MNC, высвечиваемое на сотовом телефоне имя сети (), параметры шифрования () и много чего ещё. Каждая базовая станция номеруется как. Коротко напомню о структуре основных логических каналов управления в стандарте GSM: BCCH TCH + TCH… Количество временных слотов временное разделение всё-таки) равно 8. Числа 4 и 8 для SDCCH означают «количественную ёмкость» логического канала. Больше значение — больше количество одновременно обслуживаемых сотовых телефонов.в TCH канале означает использование полноскоростного кодирования для голоса. Когда все временные слоты использованы (сконфигурированы), тогда базе могут быть добавлены дополнительные физические каналы.В результатенаучных изысканий найдена интересная недокументированная возможность, позволяющая переводить телефон Motorola в режим сканирования всех операторов сотовой связи, а не только того, чья SIM-карта установлена внутри:Подставляем в неё правдоподобные значения (шаблон можно подсмотреть из результатов выполнения команд выше) и получаем устройство для выполнения NetMonitor одновременно всех операторов сотовой связи. Это очень удобно, так как не надо переставлятьSIM-карту. В консоль выводятся значения MCC, MNC, LAC, CID, ARFCN, уровень сигнала базовых станций. Это является достаточным для определения радиочастотного покрытия GSM:Как раз всё, что нам нужно, для работы с соответствующими агрегаторами Другой документированной возможностью OsmocomBB является определение удалённости базовых станций от точки измерения по параметру Time Advance ). В этом случае Motorola сканирует физические каналы работы базовых станций и определяет значения: ARFCN, MCC, MNC и TA (однако отсутствует вывод информации о CID и LAC). Значение TA, равное 1, означает, что базовая станция находится на удалении от 550 до 1100 метров, значение TA, равное 2, означает расстояние от 1100 до 1650 метров и т. д. Имеется возможность подключения внешнего GPS через TTY для автоматической привязки результатов измерений к геоинформации. Работа возможна как от аккумуляторных батарей, так и от зарядного устройства:Здесь стоит упомянуть, что кроме программы Mobile имеются другие, позволяющие обрабатывать нешифрованную информацию, постоянно передающуюся на радиоинтерфейсе. Так, чтобы декодировать канал CCCН (для 741 ARFCN), работаем с этой программой:Для перебора каналов BCCH и декодирования соответствующих пакетов с возможностью последующей работы в Wireshark:Получение служебной информации из cell broadcast channel (как раз там, где передаются SMS-сообщения):Упомянутый выше флоуграф также позволяет всё это обрабатывать.Описанный технический инструментарий может быть применим в учебном процессе профильных высших учебных заведений. Достаточно легко нарастить его необходимым интерактивом для повышения интереса и внимательности аудитории. Теоретическая часть подлежит рассмотрению в формате лекции. После практических занятий или лабораторных работ знания начнут занимать своё место в голове. Закрепление их в формате самостоятельной работы, например, подготовка курсовых проектов по радиообследованию кампуса университета и прилегающей к нему территории, разнесённый замер технических характеристик систем связи, сличение с имеющейся информацией из общедоступных ресурсов, визуализация полученных результатов – всё это будет в разы лучше, чем сотрясание воздуха лектория или изучение скучных и пыльных учебников. Наконец, обсуждение в формате семинаров применённых технических решений, их слабых и сильных сторон (например, простоты), миграции в современные стандарты связи, общих черт и отличий работы 3G, 4G и 5G-сетей, вопросов информационной безопасности и т. д. позволит не только углубиться в тему, но и почувствовать себяинженером, а сам учебный процесс будет хотя бы немного походить на участие в современной IT-конференции При прослушивании в лектории радиотехнического университета этих малопонятных терминов, да ещё на английском языке (на русском они порой выглядят ещё страшнее), в голове складывается кашеобразная картина, мало отражающая реальную работу сетей. Подобные открытые проекты позволяют самым волшебным образом прикоснуться ко многим техническим аспектам их работы, что исключительно полезно для удовлетворения собственного интереса или в образовательной среде: в работе преподавателя или тянущегося к качественным знаниям студента. Финансовые вложения при этом минимальные. Хотелось бы, чтобы отечественное образование оставалось конкурентноспособным и соответствующим требованиям современного технологичного мира не только на бумаге, в планах и концепциях."'https://habrastorage.org/webt/9p/lb/y_/9plby_jyajgs5qc6ib_tmbigzgy.jpeg'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
15'719198'17 вопросов по Kubernetes, которые может услышать разработчик на собеседовании'Kubernetes прочно вошел в технологический стек разработки cloud-native-приложений, став мейнстримовой технологией. Разработчику, конечно же, не нужно быть экспертом по Kubernetes, чтобы запустить в...'https://habr.com/ru/post/719198/'"Вопрос 1. Что такое контейнеры? Чем они отличаются от виртуальных машин?

Вопрос 2. В чем разница stateful и stateless?

Вопрос 3. Docker-контейнер и runtime — это одно и то же?

Вопрос 4. Что такое Kubernetes и зачем он нужен?

запускать приложение в контейнере на нескольких серверах/площадках. Если ваши приложения работают на 2–3 серверах, то можно обойтись и без Kubernetes, но если их десятки и сотни, то дальнейшее масштабирование, управление и апдейт будет сложнее без дополнительного инструмента оркестрации. Как раз таким и является Kubernetes;

автоматически развертывать, апдейтить, откатывать назад обновления, управлять состоянием контейнеров;

управлять нагрузкой и оперативно масштабироваться в большую или меньшую сторону.

Вопрос 5. Как Kubernetes соотносится с Docker?

Вопрос 6. Назовите главные компоненты архитектуры Kubernetes

kube-apiserver — это точка входа в панель управления master-ноды. Он отвечает за взаимодействие между master- и worker-нодами, отслеживает состояние worker-узлов и оповещает master о важных изменениях;

— это точка входа в панель управления master-ноды. Он отвечает за взаимодействие между master- и worker-нодами, отслеживает состояние worker-узлов и оповещает master о важных изменениях; kube-scheduler отвечает за распределение нагрузки на рабочие узлы, постоянно отслеживает, сколько ресурсов сейчас доступно и сколько из них задействовано под нагрузку на каждом узле. Он решает, на каком узле запускать новый Pod;

отвечает за распределение нагрузки на рабочие узлы, постоянно отслеживает, сколько ресурсов сейчас доступно и сколько из них задействовано под нагрузку на каждом узле. Он решает, на каком узле запускать новый Pod; Controller Manager отвечает за работу контроллеров: Deployment, ReplicaSet, StatefulSets, DaemonSet, Jobs, CronJob;

отвечает за работу контроллеров: Deployment, ReplicaSet, StatefulSets, DaemonSet, Jobs, CronJob; ETCD хранит информацию о настройках и состоянии кластера, его метаданные. Представляет собой распределенную базу данных в формате ключ-значение.

kubelet — процесс, который запускает, удаляет, обновляет поды с контейнерами;

— процесс, который запускает, удаляет, обновляет поды с контейнерами; kube-proxy — конфигурирует правила сети на рабочих узлах.

Вопрос 7. Что такое под (pod)?

Вопрос 8. Что такое пространство имен (namespaces)? Почему не стоит использовать одно namespace для всех приложений?

Вопрос 9. Какую функцию выполняет ReplicaSet?

Вопрос 10. Что такое Deployment?

Вопрос 11. За что отвечает StatefulSet?

Вопрос 12. Какая роль у контроллера DaemonSet?

Вопрос 13. Как в Kubernetes устроена работа с хранилищами?

Вопрос 14. Как в Kubernetes сделать приложение доступным извне по сети интернет?

Вопрос 15. Что такое ingress и зачем он нужен?

Вопрос 16. Расскажите, как вы будете запускать приложение в Kubernetes, если из инструментов у вас только kubectl?

Для запуска в Kubernetes приложение должно быть упаковано в контейнер, поэтому первым шагом будет поместить приложение в контейнер. Затем нужно запустить контейнер в виде набора реплик (подов). Для этого используем Deployment. Для того чтобы приложение было доступно в интернете и к нему можно было подключиться, нужно настроить сервис LoadBalancer, который позволит присвоить публичный IP-адрес и подключиться к кластеру из внешней сети. Чтобы маршрутизировать пришедший через балансировщик трафик до приложения, в кластере должен быть создан Ingress, описывающий правила маршрутизации, и запущен Ingress-контроллер.

Вопрос 17. Приложение перестало работать — как понять, что случилось?

под отсутствует;

под не запускается (статус Pending);

под запускается, но падает с ошибкой (статус CrashLoopBackOff);

под работает (статус Runnung), но недоступен по сети.

Для начала нужно убедиться, что манифест выполнился и под действительно зарегистрирован в кластере. Если подов и деплоймента не находится, проверьте манифесты. Если поды находятся в статусе Pending, значит Scheduler не может найти подходящую ноду для запуска пода. На это тоже может быть много причин: недостаточно ресурсов в кластере, несовпадение taints/tolerances, невозможность скачать образ и многое другое. Найти причину помогут события, связанные с подом, однако некоторые проблемы (например, отказ Scheduler) не попадут в этот список. Также проверьте статус нод в кластере и селекторы, указанные в манифесте. Если под был назначен ноде, но при запуске произошла ошибка, под будет иметь статус CrashLoopBackOff и кластер будет предпринимать попытки запустить его повторно. Обычно это происходит в случае ошибки в самом приложении внутри контейнера, а найти причину обычно помогают логи (если приложение их пишет, конечно). Следующая ситуация — поды работают (статус Running), однако не доступны по сети из других подов. Для начала нужно проверить, создан ли Service с соответствующим селектором. Также необходимо проверить, что они находятся в одном namespace.

Kubernetes прочно вошел в технологический стек разработки cloud-native-приложений, став мейнстримовой технологией.Разработчику, конечно же, не нужно быть экспертом по Kubernetes, чтобы запустить в нем свое приложение. Но понимание азов даст лучшее представление о том, как приложение живет и работает в Kubernetes.Мы собрали список вопросов про Kubernetes, с которыми может столкнуться разработчик на собеседовании, подготовили короткие ответы и ссылки на более подробную информацию в документации и не только.Если есть свободные 20 минут, приглашаем устроить внеплановую ревизию своих знаний.Контейнеры — это сущность, которая содержит в себе все зависимости (системные библиотеки, сторонние пакеты кода и прочее), необходимые для запуска приложения. Контейнеры позволяют быстро запускать приложения без оглядки на окружающую среду.И контейнеры, и виртуальные машины — это технологии виртуализации ресурсов.Основное различие контейнеров и виртуальных машин заключается в том, что виртуальные машины виртуализируют весь компьютер/сервер вплоть до аппаратного уровня. На виртуальную машину можно установить любую гостевую ОС, и она может быть отличной от ОС компьютера/сервера.Контейнеры же виртуализируют только то, что выше уровня операционной системы. То есть контейнеры делят друг с другом ядро операционной системы, которая установлена на сервере. Благодаря этому контейнеры занимают меньше ресурсов и быстрее запускаются. В то же время контейнеры не так изолированы друг от друга, как виртуальные машины.Контейнеры — это сущность, которая содержит в себе все зависимости (системные библиотеки, сторонние пакеты кода и прочее), необходимые для запуска приложения. Контейнеры позволяют быстро запускать приложения без оглядки на окружающую среду.И контейнеры, и виртуальные машины — это технологии виртуализации ресурсов.Основное различие контейнеров и виртуальных машин заключается в том, что виртуальные машины виртуализируют весь компьютер/сервер вплоть до аппаратного уровня. На виртуальную машину можно установить любую гостевую ОС, и она может быть отличной от ОС компьютера/сервера.Контейнеры же виртуализируют только то, что выше уровня операционной системы. То есть контейнеры делят друг с другом ядро операционной системы, которая установлена на сервере. Благодаря этому контейнеры занимают меньше ресурсов и быстрее запускаются. В то же время контейнеры не так изолированы друг от друга, как виртуальные машины.Если говорить применительно к приложениям, то Stateful-приложение — это то, которое сохраняет данные при работе как состояние внутри себя. Примером могут быть сессии пользователей, которые хранятся на сервере. Ответ на запрос пользователя зависит от состояния сессии.Такие приложения сложнее масштабировать горизонтально: чтобы развернуть несколько экземпляров, нужно переносить состояния на новые машины и синхронизировать их.Stateless — любой запрос к приложению уникален, а его ответ не зависит от какого-либо состояния приложения. Stateless-приложения легко масштабируются горизонтально, упрощают автоматизированное тестирование, так как нет состояния, которое нужно воспроизводить.Есть Docker как стандарт, по которому описываются контейнеры, а есть Docker-движок, он же runtime, — это то, что запускает контейнер.В Kubernetes благодаря Container Runtime Interface (CRI) API в контейнерах можно запускать разные runtime, например CRI-O, Containerd.Так как Docker-движок старше, чем Kubernetes, он не отвечает стандартам CRI, поэтому уже некоторое время Docker runtime не поддерживается в Kubernetes Но это не означает , что сами Docker-контейнеры нельзя использовать в Kubernetes.За словом Docker действительно скрывается много всего, что вызывает путаницу. Об этом даже говорил сам Джо Беда, один из создателей Kubernetes. Так что вы точно не одиноки :)Подробнее о том, как соотносятся контейнеры, Container Runtime, CRI и о судьбе Docker runtime в Kubernetes, можно почитать тут Kubernetes — это open-source-платформа для автоматизированного запуска, масштабирования и управления контейнеризированными приложениями.С помощью Kubernetes можно:Если хотите блеснуть эрудицией, можно сказать, что Kubernetes — это детище Google, в k8s 8 означает 8 букв в слове kubernetes, а само название переводится с греческого как «кормчий, рулевой».Docker — это один из общепринятых стандартов контейнеризации. С его помощью мы упаковываем приложения в контейнеры, автоматизируем их запуск и развертывание, управление их жизненным циклом. Docker позволяет запускать один контейнер на одном хосте. А что если нужно запустить несколько контейнеров на разных хостах и как-то ими управлять?Вот здесь приходит на помощь Kubernetes, который помогает настраивать сетевую связность Docker-контейнеров, запущенных на разных хостах, и оркестровать их.То есть Docker — контейнер, Kubernetes — платформа для управления контейнерами, или оркестратор контейнеров.координируют все активности кластера: распределяют и резервируют ресурсы, управляют состоянием контейнеров, масштабируют, раскатывают обновления. Мастер-ноды состоят из следующих компонентов:— рабочие узлы в кластере. На них запускаются поды с контейнерами.На каждой worker-ноде Kubernetes работают:Под — это самая маленькая сущность в Kubernetes, в которой запускаются контейнеры. Контейнеров внутри пода может быть несколько.Помимо контейнеров, у каждого пода есть:— уникальный IP-адрес, который позволяет подам общаться друг с другом;— хранилище PV (по необходимости);— данные по конфигурации, которые определяют, как контейнер должен запускаться.Пространства имен позволяют разделять кластер на виртуальные кластеры, в которых можно объединять приложения в группы по нужному принципу. При этом эти группы будут изолированы друг от друга. Благодаря этому можно, например, создать приложение с одинаковым именем в двух разных пространствах.Если использовать только одно пространство имен, которое было по умолчанию при запуске кластера, то со временем будет сложно ориентироваться во всех запущенных там приложениях. Группировка приложений в разных пространствах имен упростит работу: например, можно в одном пространстве разместить приложение мониторинга, в другом — приложения, связанные с ИБ.Другой сценарий, когда пригодится нескольких пространств имен, — это работа нескольких команд с одним кластером.Задача ReplicaSet (RS) — поддерживать работу определенного количества экземпляров подов в кластере Kubernetes. Это базовый строительный блок Kubernetes, который используется для запуска Stateless-приложения. RS часто используется для обеспечения доступности приложения. Если какие-то из подов покрашатся, то Kubernetes с помощью RS автоматически запускает новые экземпляры подов, чтобы заменить вышедшие из строя. Без RS пришлось бы их запускать вручную. Тем самым RS помогает сохранить приложение доступным для пользователей.Deployment, по сравнению с ReplicaSet, — это абстракция более высокого уровня. Если ReplicaSet отвечает за то, чтобы поды были запущены и доступны, то Deployment помогает делать декларативные апдейты подов, используя ReplicaSet.Когда для группы контейнеров нужно обновить версии или откатиться к предыдущей, мы используем Deployment.Другие сценарии применения Deployment можно найти здесь StatefulSet управляет развертыванием и масштабированием группы подов, но при этом он дает возможность сохранять состояние и характеристики подов.Например, если нужно, чтобы поды запускались в определенном порядке, на тех же нодах, чтобы при каждом запуске у каждого было хранилище (PVC) или какие-то специальные сетевые идентификаторы, используют StatefulSet.Обычно он используется для запуска подов с очередями сообщений, брокеров и БД. DaemonSet используется в Kubernetes, когда нужно запустить один или несколько подов на всех рабочих узлах кластера. То есть при запуске новых нод вам не потребуется вручную запускать поды, которые должны там быть для каких-то служебных задач. Например, с помощью него можно запустить поды с Prometheus Node Exporter для мониторинга, collectd или поды с fluentd or logstash для логирования узлов.Примечание: это не полный список контроллеров, есть еще Jobs У Kubernetes есть volumes , например, нативный emtyDir . Часть из них stateless, то есть они живут, пока жив под. Судьба у данных, которые туда попадают, аналогичная.Для statefull-приложений используются постоянные хранилища, Persistent Volumes (PV). Persistent Volumes (PV) — это единицы хранения, которые были выделены кластеру Kubernetes его администратором. Это могут быть локальные диски, СХД, внешние дисковые полки. Они никак не зависят от жизненного цикла подов.Persistent Volume Claim (PVC) — это запрос на выделение PV определенных характеристик: типа хранилища, объема, типа доступа (чтение и/или запись). Для описания подробных характеристик доступных PV используются Storage Classes В динамике это все выглядит следующим образом: под отправляет PVC, а PVC уже обращается к PV и передает ее поду.Для этого нужно будет настроить сервисы (Services).— сущность, которая позволяет маршрутизировать запросы к подам на статичный IP-адрес. Благодаря ClusterIP у нас будет неизменная точка входа, даже если сами поды будут крашиться и восстанавливаться снова.делает сервис доступным извне через статический порт на каждом узле кластера. Любой трафик, отправленный на этот порт, будет перенаправлен на сервис. При этом ClusterIP создается автоматически.публикует сервис вовне и заводит трафик от балансировщика облачного провайдера внутрь кластера.сопоставляет сервис с DNS-именем (например, example.com). Он создает CNAME-запись, которая соединяет DNS-имя с определенным именем внутри кластера. Выступает как прокси, которое позволяет пользователю перенаправлять запросы сервису, находящемуся внутри или за пределами кластера.Ingress позволяет настраивать правила маршрутизации для трафика от внешних источников до сервисов внутри кластера.В Ingress описываются сами правила маршрутизации к сетевым сервисам, аконтроллер Ingress отвечает за их выполнение. Контроллер не поставляется в Kubernetes, но можно использовать одно из сторонних решений , предварительно изучив их возможности и особенности.В общем виде последовательность действий выглядит следующим образом:Проделать все это можно через kubectl, командную строку по сути. Это императивный и самый простой способ, когда мы как бы говорим Kubernetes «сделай это и это».Второй способ, который применяется уже в промышленной эксплуатации, — это управление через декларативные манифесты, в которых мы описываем желаемое состояние, а Kubernetes уже сам решает, какие действия для этого нужно сделать. Затем эти манифесты отправляем в Kubernetes c помощью команды kubectl apply.Подробную инструкцию по запуску приложения в Kubernetes c примерами yaml-файлов читайте здесь Причин, по которым приложение не работает в кластере Kubernetes, много.Вот самые распространенные:Ниже кратко рассмотрим алгоритмы, позволяющие понять, что же все-таки случилось.Если сервисы существуют, но доступа нет, причина может быть в правилах NetworkPolicy, ограничивающих доступ сервисов друг к другу. Проверьте эти ограничения.Если сервис должен быть доступен извне кластера (из интернета или приватной сети), необходимо проверить наличие Ingress-правила, описывающего маршрутизацию L7-трафика на выбранный сервис. Также стоит проверить состояние Ingress Controller: если он не работает, правила не будут исполняться.Кроме того, для прохождения запроса внутрь кластера должна существовать точка входа, через которую запрос попадает на Ingress Controller. Такой точкой служит Service NodePort для кластеров on-premise инфраструктуры или LoadBalancer для кластеров в облаке.Каждый из этих шагов можно выполнить через набор команд kubectl или через графический клиент, например, Lens.Подробнее можно почитать тут Это была наша версия вопросов по Kubernetes для разработчика.Напишите в комментариях, что еще, на ваш взгляд, важно понимать про Kubernetes или, наоборот, что в нашем списке вам показалось избыточным."'https://habrastorage.org/webt/lr/sg/en/lrsgenc4hl-alevizhpey9xkmzq.png'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
16'719412'Как работает Docker Desktop Networking'Современные приложения активно используют сети. Обычное дело, когда во время сборки apt-get/dnf/yum/apk install устанавливает пакет из репозитория пакетов дистрибутива Linux. При выполнении команды...'https://habr.com/ru/post/719412/'"Современные приложения активно используют сети. Обычное дело, когда во время сборки apt-get/dnf/yum/apk install устанавливает пакет из репозитория пакетов дистрибутива Linux. При выполнении команды приложение может захотеть подключиться к внутренней базе данных postgres или mysql , чтобы сохранить определённое состояние при вызове listen() и accept() . При этом разработчик должен иметь возможность работать отовсюду — из дома или офиса, с мобильного устройства или через VPN. Docker Desktop помогает сделать так, чтобы сеть «просто работала» в каждом из сценариев. В статье разбираем инструменты и методы, которые обеспечивают это, начиная с всеми любимого набора протоколов: TCP/IP.

TCP/IP

TCP/IP — набор протоколов, который задаёт стандарты связи между компьютерами и содержит подробные соглашения о маршрутизации и межсетевом взаимодействии. Когда контейнер хочет подключиться к внешнему миру, он используют TCP/IP. Поскольку для Linux-контейнеров требуется ядро Linux, Docker Desktop включает вспомогательную виртуальную машину Linux. В результате трафик из контейнеров идёт от виртуальной машины Linux, а не от хоста, что вызывает серьёзную проблему.

Многие IT-отделы создают политики VPN, где говорится что-то вроде «перенаправлять через VPN только трафик, исходящий от хоста». Смысл в том, чтобы предотвратить случайное действие хоста в качестве маршрутизатора, перенаправляющего небезопасный трафик из интернета в защищенные корпоративные сети. Если программа VPN увидит трафик с виртуальной машины Linux, он не будет маршрутизироваться через VPN, что не позволит контейнерам получить доступ к внутренним ресурсам.

Docker Desktop помогает избежать этой проблемы, перенаправляя весь трафик на уровне пользователя через vpnkit и стек TCP/IP, написанный на OCaml поверх библиотек сетевых протоколов проекта MirageOS . На диаграмме показан поток пакетов от вспомогательной виртуальной машины через vpnkit и в Интернет:

При загрузке виртуальная машина запрашивает адрес с помощью DHCP. Ethernet-фрейм, содержащий запрос, передаётся от виртуальной машины к хосту через общую память, либо через virtio на Mac, либо через AF_VSOCK на Windows. Vpnkit содержит виртуальный коммутатор ethernet ( mirage-vnetif ), который перенаправляет запрос на сервер DHCP ( mirage/charrua ).

Как только виртуальная машина получает ответ DHCP, содержащий IP-адрес виртуальной машины и IP-адрес шлюза, она отправляет запрос ARP для определения адреса сетевого шлюза ( mirage/arp ). После получения ответа ARP он сможет отправить пакет в Интернет.

Когда vpnkit видит исходящий пакет с новым IP-адресом, он создаёт виртуальный стек TCP/IP для удалённой машины ( mirage/mirage-tcpip ). Этот стек действует как одноранговый стек в Linux — принимает и обменивается пакетами. Когда контейнер вызывает connect() для установления TCP-соединения, Linux отправляет TCP-пакет с установленным флагом SYNchronize. Vpnkit наблюдает за флагом SYNchronize и сам вызывает connect() с хоста. Если connect() завершается успешно, vpnkit отвечает Linux пакетом TCP SYNchronize. В Linux connect() выполняется успешно, и данные проксируются в обоих направлениях ( mirage/mirage-flow ). Если connect() отклоняется, vpnkit отвечает пакетом TCP RST (reset), который заставляет connect() внутри Linux возвращать ошибку. UDP и ICMP обрабатываются аналогичным образом.

Помимо низкоуровневого TCP/IP, vpnkit имеет ряд встроенных высокоуровневых сетевых служб, например, DNS-сервер ( mirage/ocaml-dns ) и HTTP-прокси ( mirage/cohttp ). К этим службам можно обращаться напрямую — через виртуальный IP-адрес или DNS-имя, и косвенно — путем сопоставления исходящего трафика и динамического перенаправления в зависимости от конфигурации.

«RabbitMQ для админов и разработчиков»

С адресами TCP/IP трудно работать напрямую. В следующем разделе разберём, как Docker Desktop использует DNS для присвоения удобочитаемых имён сетевым службам.

DNS

Внутри Docker Desktop есть несколько DNS-серверов:

DNS-запросы от контейнеров сначала обрабатываются сервером внутри dockerd , который распознаёт имена других контейнеров в той же внутренней сети. Это позволяет контейнерам легко взаимодействовать друг с другом даже без знания внутренних IP-адресов. Каждый раз, когда приложение запускается, внутренние IP-адреса могут быть разными, но контейнеры по-прежнему будут легко подключаться друг к другу по удобочитаемому имени благодаря внутреннему DNS-серверу внутри dockerd .

Остальные поисковые запросы отправляются в CoreDNS (из CNCF ). Затем в зависимости от доменного имени запросы перенаправляются на один из двух DNS-серверов на хосте. Домен docker.internal считается особенным и включает в себя DNS-имя host.docker.internal , которое преобразуется в IP-адрес для текущего хоста. Хотя предпочтительнее, когда всё контейнеризировано, иногда имеет смысл запускать часть приложения как обычный сервис хостинга. Имя host.docker.internal позволяет контейнерам связываться с этими хост-сервисами и не беспокоиться о хардкодинге IP-адресов.

Второй DNS-сервер на хосте обрабатывает остальные запросы с помощью стандартных системных библиотек ОС. Это гарантирует, что, если имя правильно разрешится в веб-браузере разработчика, оно также будет правильно разрешаться в контейнерах. Это особенно важно при сложных настройках, например, когда одни запросы отправляются через корпоративный VPN ( internal.registry.mycompany ), в то время как другие — через обычный интернет (docker.com).

HTTP(S)-прокси

Некоторые организации блокируют прямой доступ в интернет и требуют, чтобы весь трафик направлялся через HTTP-прокси для фильтрации и логирования. Это влияет на извлечение образов во время сборки, а также на исходящий сетевой трафик, генерируемый контейнерами.

Самый простой способ использования HTTP-прокси — указать движку Docker на прокси-сервер c помощью переменных среды. Единственный недостаток: при необходимости изменения прокси-сервера придётся перезапустить Docker для обновления переменных, что приведёт к сбою. Docker Desktop позволяет избежать этого. Он запускает собственный HTTP-прокси внутри vpnkit, который перенаправляет на восходящий прокси-сервер. При изменении восходящего прокси-сервера внутренний прокси-сервер динамически перенастраивается, что позволяет избежать перезапуска.

На Mac Docker Desktop отслеживает параметры прокси-сервера, сохраненные в системных настройках. Когда компьютер переключает сеть (например, между сетями Wi-Fi или на сотовую связь), Docker Desktop автоматически обновляет внутренний HTTP-прокси, поэтому всё продолжает работать без каких-либо действий со стороны разработчика.

Port forwarding

Порты позволяют сетевым и подключенным к интернету устройствам взаимодействовать через указанные каналы. Хотя серверы с назначенными IP-адресами могут подключаться к интернету напрямую и делать порты публично доступными, система, находящаяся за пределами локальной сети, может оказаться недоступной из интернета. Port Forwarding — технология проброса портов, которая позволяет преодолеть это ограничение и сделать устройства публично доступными. Доступ предоставляется с помощью перенаправления трафика определённых портов с внешнего адреса маршрутизатора на адрес выбранного компьютера в локальной сети.

Поскольку Docker Desktop запускает Linux-контейнеры внутри виртуальной машины Linux, возникает разрыв: порты на виртуальной машине открыты, но инструменты работают на хосте. Нам нужно что-то для перенаправления соединений с хоста на виртуальную машину.

Рассмотрим отладку веб-приложения: разработчик вводит docker run -p 80:80 , чтобы порт 80 контейнера был открыт на порту 80 хоста (и чтобы сделать его доступным через http://localhost ). Вызов Docker API записывается в /var/run/docker.sock на хосте, как обычно. Когда Docker Desktop запускает Linux-контейнеры, движок Docker представляет собой программу Linux, работающую внутри вспомогательной виртуальной машины Linux, а не на хосте. Поэтому Docker Desktop включает в себя прокси-сервер Docker API, который пересылает запросы с хоста на виртуальную машину. В целях безопасности запросы не пересылаются напрямую по протоколу TCP по сети. Вместо этого Docker Desktop перенаправляет соединения с доменными сокетами Unix по защищенному низкоуровневому пути через процессы, обозначенные на схеме выше как vpnkit-bridge .

Прокси Docker API может делать больше, чем просто пересылать запросы туда и обратно. Он также может декодировать и преобразовывать запросы и ответы, чтобы улучшить работу разработчика. Когда разработчик предоставляет порт с помощью docker run -p 80:80 , прокси Docker API декодирует запрос и использует внутренний API для переадресации порта через процесс com.docker.backend . Если что-то на хосте уже прослушивает этот порт, разработчику возвращается удобочитаемое сообщение об ошибке. Если порт свободен, процесс com.docker.backend начинает принимать соединения и перенаправлять их в контейнер через vpnkit-forwarder , запущенный поверх vpnkit-bridge .

Docker Desktop не запускается с «root» или «Administrator» на хосте. Разработчик может использовать docker run –privileged , чтобы получить права root внутри вспомогательной виртуальной машины, но гипервизор гарантирует, что хост всегда будет защищён. Это хорошо с точки зрения безопасности, но вызывает проблему удобства использования в macOS — как разработчик может открыть порт 80 ( docker run -p 80:80 ), когда он считается «привилегированным портом» в Unix, то есть номер порта < 1024? Решение состоит в том, что Docker Desktop включает в себя вспомогательную привилегированную службу, которая запускается от имени root из launchd и которая говорит API «пожалуйста, привяжите этот порт». В связи с этим возникает вопрос: безопасно ли разрешать пользователю без полномочий root привязывать привилегированные порты?

Привилегированные порты изначально были функцией безопасности. Они появились во времена, когда порты использовались для аутентификации сервисов: можно было с уверенностью предположить, что вы разговариваете с HTTP-демоном хоста, потому что он привязан к порту 80, для которого требуется root. Современный способ аутентификации — с помощью сертификатов TLS и отпечатков пальцев SSH. Поэтому пока системные службы связывают свои порты до запуска Docker Desktop, macOS связывает порты при загрузке через launchd , благодаря чему не может быть путаницы или отказа в обслуживании. Соответственно, современная macOS сделала привязку привилегированных портов ко всем IP-адресам ( 0.0.0.0 или INADDR_ANY ) непривилегированной операцией. Есть только один случай, когда Docker Desktop все ещё нуждается в использовании привилегированного помощника для привязки портов: когда запрашивается определенный IP (например, docker run -p 127.0.0.1:80:80 ), для которого требуется root в macOS.

Коротко о главном

Извлечение образов Docker, установка пакетов Linux, взаимодействие с серверными частями базы данных — всё это ежедневные задачи, для выполнения которых приложениям нужны надёжные сетевые подключения. Docker Desktop работает в самых разных средах: в офисе, дома и даже в поездках с нестабильным Wi-Fi. Однако на каких-то компьютерах могут быть установлены ограничительные политики брандмауэра, на каких-то — сложные конфигурации VPN. В таких случаях Docker Desktop стремится «просто работать», чтобы разработчик мог сосредоточиться на создании и тестировании своего приложения (а не на отладке Docker).

«RabbitMQ для админов и разработчиков»"'https://habrastorage.org/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
17'715624'Оптимизация зубчатых передач в КОМПАС-3D с помощью приложений «Валы и механические передачи 3D» и «Оптимизация IOSO-К»'Валерий Голованёв, Юрий Бабий Требования к повышенной прочности, долговечности, износостойкости и плавности работы зубчатых передач были, есть и будут приоритетными при их проектировании. Примерно...'https://habr.com/ru/post/715624/'"Валерий Голованёв, Юрий Бабий



Требования к повышенной прочности, долговечности, износостойкости и плавности работы зубчатых передач были, есть и будут приоритетными при их проектировании. Примерно 80% от общего числа зубчатых передач в мировом машиностроении приходится на эвольвентные цилиндрические передачи.

В настоящее время существует несколько стандартов на исходные контуры. Каждый из них хорош по-своему, однако получить передачу, оптимальную для заданных условий эксплуатации, при использовании стандартных подходов и методов не всегда возможно. А ведь наверняка любопытному и грамотному конструктору захочется выйти за границы стандартов, отойти от стандартного исходного контура и посмотреть — а что там? Вдруг в неведомом пока многомерном поле переменных, которыми являются исходные геометрические данные передачи, и окажется то самое решение, которое позволит в тех же габаритах создать передачу лучше и надежнее?!

Но реальность такова, что без применения современных методов оптимизации и построения корректной математической модели, описывающей работу передачи, быстро получить результат невозможно.

Для достижения цели «сделать лучше и надежнее» в программном комплексе, состоящем из расчетного модуля «Валы и механические передачи 3D» и приложения «Оптимизация IOSO-K», реализованы IOSO-алгоритмы оптимизации, в которых стратегия решения задач оптимизации принципиально отличается от известных подходов нелинейного программирования и базируется на новой эволюционной технологии построения поверхности отклика. Как следствие, данная технология обладает большей эффективностью, обеспечивает большие возможности.

Заложенная стратегия поиска позволяет существенно сократить количество прямых обращений к математической модели, что приводит к значимому сокращению времени, необходимого для поиска значений экстремумов.

Проведенные широкомасштабные исследования позволяют утверждать, что алгоритмы технологии оптимизации IOSO инвариантны к различным классам задач оптимизации и могут использоваться при решении проблем условной и безусловной нелинейной оптимизации в однокритериальной и многокритериальной постановках с целевыми функциями различных типов: гладкие, недифференцируемые, стохастические, с наличием областей невычисляемости, многоэкстремальные. Алгоритмы имеют высокую скорость сходимости, обладают хорошими глобальными свойствами и позволяют найти глобальный экстремум с большой степенью вероятности. В то же время алгоритмы чрезвычайно просты в использовании при постановке и решении сложных практических проблем нелинейной оптимизации и не требуют от пользователя знаний теории и методов оптимизации.

Что же в данном случае представляет собой математическая модель зубчатой передачи? По сути, это геометрический расчет, выполненный по ГОСТ 16532-70, и расчеты на прочность и долговечность, выполненные по ГОСТ 21354-87, с целевыми функциями, выстраиваемыми по одному или двум критериям, и системой ограничений, которая гарантирует качественные показатели зацепления. Варьируемыми параметрами в заданных диапазонах мы приняли:

Параметры исходного контура: угол профиля;

коэффициент высоты головки зуба;

коэффициент радиального зазора;

коэффициент радиуса кривизны переходной кривой в граничной точке профиля зуба. Коэффициенты смещения исходного контура; Угол наклона зубьев на делительном цилиндре (при расчете передачи с заданным межосевым расстоянием). Он может быть как фиксированным, так и варьируемым; Модуль передачи (так же может быть как фиксированным, так и вычисляемым).

Рис. 1. Варьируемые параметры

Основой системы ограничений является динамический блокирующий контур, «перестраиваемый» приложением в зависимости от варьируемых параметров передачи. Наглядным способом отображения зависимости геометрических параметров и качественных показателей передачи от коэффициентов смещения являются кривые, построенные для каждого сочетания чисел зубьев передачи z 1 и z 2 в плоской системе координат x 1 и x 2 . Эта система координат была предложена М. Б. Громаном [1] еще в 1955 году, а в дальнейшем получила развитие в работах В. А. Гавриленко и коллектива, возглавляемого И. А. Болотовским. Именно В. А. Гавриленко предложил термин «блокирующий контур зубчатой передачи» — БК.

Суть блокирующего контура (рис. 1) [2] состоит в том, чтобы на плоскости координат x 1 , x 2 в виде набора линий показать основные ограничения, в пределах которых будет обеспечена кинематически правильная работа зубчатой передачи.

Таковыми ограничениями (изолиниями) являются:

Предельно допустимое минимальное значение коэффициента торцового перекрытия ε α = 1 (при ε α < 1 будет нарушена непрерывность зацепления зубьев в передаче). По сути, данный коэффициент можно считать критерием плавности работы;

Интерференция в рабочем зацеплении (ситуация, когда в процессе работы передачи вершина зуба одного колеса внедряется в зуб другого колеса, т. е. происходит заклинивание зацепления);

Границы допустимого подрезания;

Предельно допустимое минимальное значение нормальной толщины зуба на поверхности вершин зубьев s na = 0;

Срезание зуба зубчатого колеса зуборезным долбяком при обработке колеса данным инструментом.

Увеличить

Рис. 2. Блокирующий контур передачи внешнего зацепления, составленной из колес, нарезанных реечным инструментом

Внутри блокирующего контура (БК) могут быть проведены линии условных границ, за которые переходить не рекомендуется: ε α = 1,2, s na = 0,4m n , и линии x 1 = x min 1 , x 2 = x min 2 , ограничивающие начало подрезания, а также линия x 1 + x 2 = 0 (при расчете передачи по коэффициентам смещения) или линия x 1 + x 2 = x Σ (при расчете передачи с фиксированным межосевым расстоянием).

Кроме того, представляет интерес линия выравнивания удельных скольжений в нижних точках активных профилей зубьев θ p 1 = θ p 2 (ЛВУС). По сути, эта линия является критерием износостойкости передачи. Применение ЛВУС в БК было сделано И. А. Болотовским [3] на основании работ Я. И. Дикера [4].

Более подробно тема использования блокирующих контуров в приложении «Валы и механические передачи» освещена в статьях [5,6,7].

В качестве критериев оптимизации могут быть использованы один или два параметра:

Увеличить

Рис. 3. Критерии оптимизации

Рассмотрим реальный пример. Имеем шевронную передачу редуктора колёсной пары электровоза 2ЭС5К. Цель оптимизации — повысить износостойкость передачи без изменения угла наклона зубьев и габаритных размеров.

Увеличить

Рис. 4. Исходная передача

Увеличить

В качестве критериев оптимизации выберем износостойкость и плавность работы.

Увеличить

Рис. 5. Диалог приложения перед стартом оптимизации

Запускаем расчет и через некоторое время получаем его результаты в IOSO.

Увеличить

Рис. 6. Результаты расчетов в IOSO

В ходе решения задачи оптимизации получено множество Парето-оптимальных решений (зеленые ромбы на графике), особенностью которых является то, что ни один критерий не может быть улучшен без ухудшения какого-либо другого.

На графике по оси Y показан критерий «износ», который необходимо минимизировать, а по оси X — критерий «плавность работы», который необходимо максимизировать. Желтый квадрат на графике соответствует значениям этих критериев для исходной передачи. Анализ полученного Парето-множества показал, что в результате решения оптимизационной задачи найдены решения, позволяющие значительно сократить износ передачи и повысить ее плавность хода по сравнению с исходным вариантом.

Мы выбрали один из вариантов. Критерием выбора в данном случае было желание выбрать нечто среднее из Парето-множества результатов.

Увеличить

Увеличить

Рис. 7. Оптимизированная передача

Что мы видим... Удельное скольжение ниже, контактные напряжения ниже, ресурс передачи выше. Изгибные напряжения в данном случае нас никак не ограничивали.

Исследования можно продолжить и дальше, например, разрешить варьирование угла наклона и (или) изменить набор критериев. Но преимущества оптимизированной передачи уже очевидны.

Таким образом, применение расчетного комплекса «Валы и механические передачи 3D» в сочетании с приложением «Оптимизация IOSO-К» в среде КОМПАС-3D открывает новые возможности в проектировании высокоэффективных зубчатых передач, обладающих наилучшими характеристиками прочности, долговечности, износостойкости и плавности.



Список ссылочной литературы"'https://habrastorage.org/getpro/habr/upload_files/26e/f50/424/26ef50424635c1ccaf2cbaa64d947d60.png'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
18'718084'Полное понимание асинхронности в браузере'Про асинхронность JavaScript написано много статей, документации и книг. Но вся информация сильно распределена по интернету, поэтому сложно быстро и полностью разобраться, что к чему, и составить...'https://habr.com/ru/post/718084/'"Цикл событий

У цикла событий всегда есть работа, даже когда сайт написан без JavaScript

Задачи, тики и Web API

const button = document.createElement('button') document.body.appendChild(button) button.textContent = 'OK'

fetch('/url') .then((response) => { // выполнится когда-то в будущем })

Очередь задач

setTimeout(() => { // поставить задачу в очередь через 1000 мс }, 1000)

document.body.addEventListener('click', () => { // поставить задачу в очередь, когда наступит событие })

16,6 миллисекунды на задачу

Обработка больших задач

function longTask () { toDoSomethingFirst() setTimeout(() => { toDoSomethingLater() }, 0) }

const worker = new Worker('worker.js') worker.addEventListener('message', () => { // получить данные }) // отправить данные worker.postMessage('any data')

Микрозадачи

Promise.resolve.then(() => { // микрозадача }) async function () { // микрозадача } queueMicrotask(() => { // микрозадача }) new MutationObserver(() => { // микрозадача }).observe(document.body, { childList: true, subtree: true })

Смотреть код const div = document.createElement('div') document.body.appendChild(div) let height = 0 function changeDOM () { height += 1 div.style.height = `${height}px` requestAnimationFrame(changeDOM) } requestAnimationFrame(changeDOM) setTimeout(() => { const promise = Promise.resolve() .then(() => { console.log(div.style.height) }) .then(() => { console.log(div.style.height) }) promise .then(() => { console.log(div.style.height) }) }, 1000) // все console.log выведут одинаковое значение

requestAnimationFrame

Вверху без rAF, внизу через rAF

requestAnimationFrame

requestAnimationFrame(() => { console.log('one') }) requestAnimationFrame(() => { console.log('two') }) requestAnimationFrame(() => { console.log('three') }) // one two three

let requestId function animate () { requestId = requestAnimationFrame(animate) } requestId = requestAnimationFrame(animate) setTimeout(() => { // отменить анимации через какое-то время cancelAnimationFrame(requestId) }, 3000)

requestIdleCallback

function sendAnalytics () { // отправить данные для аналитики } requestIdleCallback(sendAnalytics, { timeout: 2000 })

requestIdleCallback

Сравнение очередей

задачи — таймеры, события (включая обработку postMessage);

микрозадачи — обещания, асинхронные функции, Observer API, queueMicrotask;

requestAnimationFrame, requestIdleCallback — соответствующие вызовы API.

Цикл событий в Node.js

Функции обратного вызова

Ад обратных вызовов

fetchToken(url, (token) => { fetchUser(token, (user) => { fetchRole(user, (role) => { fetchAccess(role, (access) => { fetchReport(access, (report) => { fetchContent(report, (content) => { // Welcome to Callback Hell }) }) }) }) }) })

Не выпускайте Залго

syncOrAsync(() => { // как именно выполняется код? }) // синхронная реализация function syncOrAsync (callback) { callback() } // асинхронная реализация function syncOrAsync (callback) { queueMicrotask(callback) }

Жёсткая сцепленность

firstStep((error, data) => { if (error) { // отменить этап №1 } secondStep((error, data) => { if (error) { // отменить этап №2, а затем №1 } }) }))

Проблема доверия

import { thirdPartyCode } from 'third-party-package' thirdPartyCode(() => { // инверсия управления })

Обещания

// выставить обещание на выполнение const resolvedPromise = new Promise((resolve, reject) => { setTimeout(() => { resolve('^_^') }, 1000) }) // выставить обещание на отказ const rejectedPromise = new Promise((resolve, reject) => { setTimeout(() => { reject('O_o') }, 1000) })

resolvedPromise.then((value) => { console.log(value) // ^_^ })

rejectedPromise.then( (value) => { // ... проигнорировано }, (error) => { console.log(error) // O_o } ) rejectedPromise.catch((error) => { console.log(error) // O_o })

const promise = new Promise((resolve, reject) => { resolve('^_^') reject('O_o') // уже никак не повлияет на состояние Promise }) promise.then((value) => { console.log(value) // ^_^ }) promise.then((value) => { console.log(value) // ^_^ })

Promise.resolve('^_^').then((value) => { console.log(value) // ^_^ }) Promise.reject('O_o').catch((error) => { console.log(error) // O_o })

Promise.resolve('^_^').finally(() => { // какая-то работа }).then((value) => { console.log(value) // ^_^ }) Promise.reject('O_o').finally(() => { // какая-то работа }).catch((error) => { console.log(error) // O_o })

Цепочки обещаний и проброс отказа

Promise.resolve('^') .then((value) => { return value + '_' }) .then((value) => { return value + '^' }) .then((value) => { console.log(value) // ^_^ })

Promise.resolve() .then(() => { return Promise.reject('O_o') }) .then(() => { // все обработчики на выполнение будут пропущены }) .catch((error) => { console.log(error) // O_o }) .then(() => { // продолжаем выполнять цепочку в штатном режиме })

Promise.reject('O_o') .catch((error) => { console.log(error) // O_o return '^_^' }) .then((value) => { console.log(value) // ^_^ })

window.addEventListener('unhandledrejection', (event) => { console.log('Необработанная ошибка Promise. Позор вам!') console.log(event) // PromiseRejectionEvent console.log(event.reason) // O_o }) // Promise.reject('O_o') // UnhandledPromiseRejection

Promise.resolve() .then(() => { Promise.reject('O_o') }) .catch(() => { // будет пропущено, потому что не указан return // будет выброшено UnhandledPromiseRejection })

Неявное поведение

// можно и так: const one = Promise.resolve('^') const two = one.then((value) => { return value + '_' }) const three = two.then((value) => { return value + '^' }) three.then((value) => { console.log(value) // ^_^ }) // но так гораздо лучше: Promise.resolve('^') .then((value) => { return value + '_' }) .then((value) => { return value + '^' }) .then((value) => { console.log(value) // ^_^ })

Promise.resolve() .then(() => { return Promise.resolve('^_^') }) .then((value) => { console.log(value) // ^_^ })

// можно и так: Promise.resolve('^') .then((value) => { return Promise.resolve(value + '_') .then((value) => { return Promise.resolve(value + '^') .then((value) => { console.log(value) // ^_^ }) }) }) // но так гораздо лучше: Promise.resolve('^') .then((value) => { return Promise.resolve(value + '_') }) .then((value) => { return Promise.resolve(value + '^') }) .then((value) => { console.log(value) // ^_^ })

Promise.resolve() .then(() => { undefined.toString() }) .catch((error) => { console.log(error) // TypeError: Cannot read property 'toString' of undefined })

Promise.resolve() .then(() => { try { undefined.toString() } catch (error) { return Promise.reject(error) } }) .catch((error) => { console.log(error) // TypeError: Cannot read property 'toString' of undefined })

Thenable-объекты

then

const thenable = { then (fulfill) { fulfill('@_@') } }

Promise.resolve(thenable) .then((value) => { console.log(value) // @_@ }) new Promise((resolve) => { resolve(thenable) }).then((value) => { console.log(value) // @_@ }) Promise.resolve() .then(() => { return thenable }) .then((value) => { console.log(value) // @_@ })

const awesomeES6Promise = Promise.resolve(thenable) awesomeES6Promise.then((value) => { console.log(value) // @_@ })

const thenable = { then (fulfill) { fulfill('@_@') } } const promise = Promise.resolve('@_@') const resolvedThenable = Promise.resolve(thenable) const resolvedPromise = Promise.resolve(promise) console.log(thenable === resolvedThenable) // false console.log(promise === resolvedPromise) // true

const promise = Promise.resolve('@_@') Promise.reject(promise) .catch((value) => { console.log(value) // Promise {<fulfilled>: ""@_@""} })

Статические методы

const setPromise = (value, ms, isRejected = false) => new Promise((resolve, reject) => setTimeout(() => isRejected ? reject(value) : resolve(value), ms))

Promise.all([ setPromise('^_^', 400), setPromise('^_^', 200), ]).then((result) => { console.log(result) // [ ""^_^"", ""^_^"" ] })

Promise.all([ setPromise('^_^', 400), setPromise('O_o', 200, true), ]).catch((error) => { console.log(error) // O_o })

Promise.all([]) .then((result) => { console.log(result) // [] })

Promise.race([ setPromise('^_^', 100), setPromise('O_o', 200, true), ]).then((result) => { console.log(result) // ^_^ })

Promise.race([ setPromise('^_^', 400), setPromise('O_o', 200, true), ]).catch((error) => { console.log(error) // O_o })

Promise.race([]) .then(() => { console.log('resolve не выполнится никогда') }).catch(() => { console.log('reject тоже') })

Promise.any([ setPromise('^_^', 400), setPromise('O_o', 200, true), ]).then((result) => { console.log(result) // ^_^ })

Promise.any([ setPromise('O_o', 400, true), setPromise('O_o', 200, true), ]).catch((result) => { console.log(result.message) // All promises were rejected console.log(result.errors) // [ ""O_o"", ""O_o"" ] })

Promise.any([]) .catch((error) => { console.log(error.message) // All promises were rejected })

Promise.allSettled([ setPromise('^_^', 400), setPromise('O_o', 200, true), ]).then(([resolved, rejected]) => { console.log(resolved) // { status: ""fulfilled"", value: ""^_^"" } console.log(rejected) // { status: ""rejected"", reason: ""O_o"" } })

Promise.allSettled([]) .then((result) => { console.log(result) // [] })

Промисификация

function promisify (fn) { return function (...args) { return new Promise((resolve, reject) => { function callback(error, result) { return error ? reject(error) : resolve(result) } fn(...args, callback) }) } } function asyncApi (url, callback) { // ... выполнить асинхронную операцию callback(null, '^_^') } promisify(asyncApi)('/url') .then((result) => { console.log(result) // ^_^ })

Обещания или функции обратного вызова?

Promise.race([ fetchLongRequest(), new Promise((_, reject) => setTimeout(reject, 3000)), ]).then((result) => { // получили данные }).catch((error) => { // или отказ по таймеру })

Корутины

function async (generator) { const iterator = generator() function handle({ done, value }) { return done ? value : Promise.resolve(value) .then((x) => handle(iterator.next(x))) .catch((e) => handle(iterator.throw(e))) } return handle(iterator.next()) }

async(function* () { const response = yield fetch('example.com') const json = yield response.json() // обработать json })

Async/await

async function asyncFunction () { return '^_^' }

function asyncFunction () { return Promise.resovle('^_^') }

asyncFunction().then((value) => { console.log(value) // ^_^ }) (async () => { const value = await asyncFunction() console.log(value) // ^_^ })()

Верхнеуровневый await и асинхронные модули

const connection = await dbConnector() const jQuery = await import('http://cdn.com/jquery')

// module.mjs const value = await Promise.resolve('^_^') export { value } // main.mjs import { value } from './module.mjs' console.log(value) // ^_^

// module.mjs export let value export const promise = (async () => { value = await Promise.resolve('^_^') })() export { value, promise } // main.mjs import { value, promise } from './module.mjs' (async () => { await promise console.log(value) // ^_^ })()

Обработка ошибок

async function asyncFunction () { await Promise.reject('O_o') } asyncFunction() .then((value) => { // вдруг ошибка? }) .catch((error) => { // тогда ошибку поймает catch })

async function asyncFunction () { try { await Promise.reject('O_o') } catch (error) { // перехватить ошибку } } asyncFunction().then((value) => { // мы в безопасности })

Не все await одинаково полезны

const articles = await fetchArticles() const pictures = await fetchPictures() // ... какие-то действия с articles и pictures

const [articles, pictures] = await Promise.all([ fetchArticles(), fetchPictures(), ])

Заключение

Про асинхронность JavaScript написано много статей, документации и книг. Но вся информация сильно распределена по интернету, поэтому сложно быстро и полностью разобраться, что к чему, и составить цельную картину в голове. Не хватает одного исчерпывающего гайда. Именно эту потребность я и хочу закрыть своей статьёй.Для работы сайта браузер выделяет один единственный поток, который должен успевать одновременно делать две важные задачи: выполнять код и обновлять интерфейс. Но один поток в один момент времени может совершать только одно действие. Поэтому поток выполняет эти задачи по очереди, чтобы создать иллюзию параллельного выполнения. Это и есть цикл событий (event loop).Выполнение кода происходит в стеке вызовов. Если функция внутри себя вызывает другую функцию, то вызов её самой приостанавливается до тех пор, пока выполняется другая функция, — таким образом получается эдакий стек вызовов. Как только все операции будут выполнены и стек опустеет, цикл событий может поместить в стек ещё какой-нибудь код для выполнения или обновить интерфейс пользователя.Обновление интерфейса пользователя выполняет движок браузера. Этот этап, как правило, состоит из четырёх шагов: style, layout (reflow), paint, composite. На этапе style браузер пересчитывает изменение стилей, вызванное операциями JavaScript, и рассчитывает медиа-выражения. Layout выполняет перерасчёт геометрии страницы, где происходит вычисление слоёв, расчёт взаимного расположения элементов и их влияния друг на друга. Во время шага paint движок отрисовывает элементы и применяет к ним стили, которые влияют только на внешний вид, например, на цвет, фон и т. п. Composite применяет оставшиеся специфические стили. Как правило, это трансформации, которые происходят в отдельном слое.Браузер может пропускать некоторые операции, если они не нужны. Понимать, когда браузер выполняет или пропускает тот или иной шаг, может быть полезным для оптимизации веб-страницы. Более подробно о каждом этапе и его связи с производительностью можно прочитать во второй части хабрастатьи «Оптимизация производительности фронтенда».Первой операцией в цикле событий может быть как обновление интерфейса, так и выполнение кода. Если сайт использует синхронный тег script, то с большой вероятностью движок выполнит его перед тем, как отрисовать первый кадр интерфейса пользователя. Если же мы грузим скрипты асинхронно через async или defer, то велика вероятность, что до загрузки JavaScript браузер успеет отрисовать интерфейс пользователя.Вариант с асинхронной загрузкой скриптов более предпочтительный, потому что начальный бандл, как правило, достаточно объёмный. Пока он полностью не выполнится, пользователь будет видеть белый экран, потому что цикл событий не сможет отрисовать интерфейс пользователя. При этом даже при асинхронной загрузке рекомендуется разбивать JavaScript-код на отдельные бандлы и сначала грузить только самое необходимое, потому что цикл событий очень последовательный: он полностью выполняет весь код в стеке вызовов и только потом переходит к обновлению интерфейса. Если в стеке вызовов будет слишком много кода, интерфейс будет обновляться с большой задержкой. У пользователя создастся впечатление, что сайт лагает. Если написать бесконечный цикл, то браузер так и будет выполнять код снова и снова, а обновление интерфейса не наступит никогда, поэтому страница просто зависнет и перестанет реагировать на действия пользователя.Внутри стека вызовов будет выполняться как код, написанный разработчиком, так и код, встроенный по умолчанию и отвечающий за взаимодействие со страницей. Благодаря встроенному коду работают прокрутка, выделение, анимации и другие штуки, для которых, казалось бы, JavaScript не нужен. Стек вызовов будет выполнять встроенные скрипты даже тогда, когда мы запретим в браузере JavaScript. Для примера можно открыть пустую страницу about:blank без JavaScript, выполнить несколько кликов и увидеть, что стек вызовов выполнил код, отвечающий за обработку событий.Задача — это JavaScript-код, который выполняется в стеке вызовов. Тик — выполнение задачи в стеке вызовов. Web API — свойства и методы в глобальном объекте Window.Методы Web API работают либо синхронно, либо асинхронно: первые выполнятся в текущем тике, а вторые в одном из следующих тиков.Хороший пример синхронных вызовов — это работа DOM:Создание элемента, вставка в DOM и выставление свойств — это синхронные операции, которые выполняются в текущем тике. Поэтому совершенно нет разницы, когда мы выставим текст для кнопки — до вставки в DOM или после неё. Браузер обновит интерфейс только после полного завершения синхронных операций, так что пользователь увидит сразу актуальное состояние интерфейса.Когда мы пишем асинхронный код, то гарантируем, что задача будет выполняться в следующем тике. При этом он может начаться как до обновления интерфейса, так и после. Например, когда циклу событий требуется выполнить очередную задачу, он может либо выполнить её сразу после предыдущей, либо сначала обновить интерфейс, а только потом выполнить следующую задачу. Для разработчиков это не играет особой роли. Важно просто понимать, что асинхронная задача выполнится когда-то в будущем.Хороший пример асинхронного вызова — это запрос данных с сервера. Через функцию обратного вызова описывается задача, которая будет выполнена когда-то в будущем после получения данных:Подсистема браузера, которая отвечает за работу с сетью, выполнит запрос в отдельном потоке, который будет работать независимо. Пока запрос будет выполняться фоном, цикл событий может спокойно обновлять интерфейс и выполнять код. После того как данные успешно загрузятся, задание, которое мы описали через функцию обратного вызова, станет готовым для выполнения в одном из следующих тиков нашего основного цикла заданий.Задач, готовых к выполнению после асинхронных вызовов, может быть несколько. Поэтому для передачи их в стек вызовов на выполнение существует специальная очередь.Задачи попадают в очередь через асинхронное браузерное API. Сперва где-то в отдельном потоке выполняется асинхронная операция, а после её завершения в очередь добавляется задача, готовая к выполнению в стеке вызовов.Понимая эту концепцию, можно разобрать одну особенность таймеров в JavaScript, которые тоже являются асинхронным API.Когда мы запускаем таймер, движок начинает вести обратный отсчёт в отдельном потоке и по готовности задача добавляется в очередь. Можно было бы подумать, что таймер выполнится через одну секунду, но на самом деле это не так. В лучшем случае через одну секунду он добавится в очередь заданий, а код будет выполнен только после того, как до него дойдёт очередь.Точно такая же история с обработчиками событий. Каждый раз, когда мы регистрируем обработчик событий, мы привязываем к нему задачу, которая будет добавлена в очередь после наступления события:Чтобы сайты были быстрыми и «отзывчивыми», браузеру надо создать иллюзию, что он одновременно выполняет код пользователя и обновляет интерфейс. Но поскольку цикл событий работает строго последовательно, браузеру приходится быстро переключаться между задачами, чтобы пользователь ни о чём не догадался.Как правило, мониторы обновляют картинку с частотой 60 кадров в секунду, поэтому цикл событий старается с такой же скоростью выполнять код и обновлять интерфейс, то есть на выполнение задачи уходит 16,6 миллисекунды. Если наш код будет выполняться быстрее, то браузер будет просто часто обновлять дисплей. Но если код будет выполняться медленно, то частота кадров начнёт снижаться, и у пользователя появится ощущение, что сайт лагает.Для большинства сценариев 16,6 миллисекунды вполне достаточно. Но иногда на клиентской стороне требуется выполнять тяжёлые вычисления, которые могут потребовать гораздо больше времени. Для этого есть специальные методики.Оптимизировать большие задачи можно двумя путями: либо через разбиение их на подзадачи и выполнение последних в разных тиках, либо через вынесение вычисления в отдельный поток.Выполнить что-то в следующем тике можно, например, через setTimeout с минимальной задержкой Кроме того есть экспериментальная функция postTask , которая является частью Scheduling API и в данный момент доступна только в Chrome . Через неё можно не только выполнять задачи асинхронно для разгрузки основного потока, но и устанавливать для них приоритет. Более подробно об этом можно почитать в статье Джереми Вагнера «Optimize long tasks» Для запуска отдельного потока подойдёт Web Worker API Для веб-воркера создаётся отдельный поток, где будут происходить вычисления независимо от основного цикла событий. Как только вычисления закончатся, воркер через postMessage сможет отправить данные в основной цикл событий и задача, связанная с их обработкой, будет добавлена в очередь и выполнена в одном из следующих тиков. Но у веб-воркера есть ограничения. Например, внутри нельзя работать с DOM, однако вычислительные задачи будут работать.Если данные вычислений нужны внутри других вкладок в рамках одного источника (same origin), то вместо обычного воркера можно использовать SharedWorker. Кроме того, для некоторых задач может быть полезен ServiceWorker, но это уже другая история. Подробнее про воркеры можно прочитать, например, вот тут Кроме веб-воркеров есть другой, менее очевидный способ создать отдельный поток — открыть окно или фрейм на другом домене, чтобы нарушить политику same origin. Тогда у окна или фрейма будет свой собственный независимый цикл событий, который сможет выполнять какую-то работу и взаимодействовать с основным окном так же, как и веб-воркер через механизм postMessage. Это достаточно специфическое поведение, которое может по-разному выглядеть в разных браузерах, его можно проверить, например, через демку со Stack Overflow Микрозадачи — это те задачи, которые хранятся в специальной отдельной очереди.Задачи попадают в эту очередь при использовании обещаний, асинхронных функций, встроенном вызове queueMicrotask или для Observer API.Очередь микрозадач более приоритетная, задачи из неё выполняются раньше обычных. Кроме того, у неё есть важная особенность — цикл событий будет выполнять микрозадачи до тех пор, пока очередь не опустеет. Благодаря этому, движок гарантирует, что все задачи из очереди имеют доступ к одинаковому состоянию DOM.Это поведение можно наглядно увидеть на примере с обещаниями, где каждый последующий обработчик получает доступ к одному и тому же состоянию DOM (на момент установки обещания):Есть замечательный наглядный сайт JavaScript Visualizer 9000 , где можно более подробно изучить, как работают очереди задач и микрозадач. Ещё советую хорошую хабрастатью , где разбираются обещания.requestAnimationFrame (или сокращённо rAF) позволяет выполнить JavaScript-код прямо перед обновлением интерфейса. Каким-то другим способом, например через таймеры, эмулировать такое поведение практически невозможно.Основная задача requestAnimationFrame — это плавное выполнение JavaScript-анимаций, но используют его нечасто, так как анимации проще и эффективнее задать средствами CSS. Тем не менее он занимает своё полноценное место в цикле событий.Задач, которые нужно выполнить перед обновлением следующего кадра, может быть несколько, поэтому у requestAnimationFrame есть своя отдельная очередь.Задачи из очереди выполняются один раз перед обновлением интерфейса в порядке их добавления:Написать повторяющуюся задачу, которая будет выполняться снова и снова, можно через рекурсивную функцию. Причём, если по какой-то причине потребуется отменить выполнение, это можно сделать через cancelAnimationFrame. Но надо убедиться, что в него передаётся актуальный идентификатор, потому что каждый вызов rAF создаёт новый requestId.Небольшая, но дельная статья по теме requestAnimationFrame есть в блоге Флавио Коупса requestIdleCallback (или сокращённо rIC) добавляет задачи в ещё одну (четвёртую) очередь, которая будет выполняться в период простоя браузера, когда нет более приоритетных задач из других очередей.В качестве второго аргумента можно указать timeout и, если задача не будет выполнена в течение указанного числа миллисекунд, то она добавится в обычную очередь, после чего выполнится в порядке общей очереди.По аналогии с requestAnimationFrame, чтобы регулярно добавлять задачу в очередь, потребуется написать рекурсивную функцию, а для остановки — передать актуальный идентификатор в cancelIdleCallback.В отличие от других очередей, рассмотренных ранее, requestIdleCallback — это всё ещё отчасти экспериментальное API, поддержка которого отсутствует в Safari . Кроме того, эта функция имеет ряд ограничений, из-за которых её удобно использовать только для небольших неприоритетных задач без взаимодействия с DOM, например для отправки аналитических данных. Более подробно о requestIdleCallback можно почитать в материале «Using requestIdleCallback» Пола Льюиса.— это самая приоритетная очередь, с неё начинается выполнение кода. Работа браузера с этой очередью продолжается до тех пор, пока в ней есть задачи, сколько бы времени это ни заняло.Издвижок выполняет, как правило, одно или несколько заданий, стараясь уложиться в 16,6 миллисекунды. Как только пройдёт отведённое время, движок пойдёт обновлять интерфейс, даже если в очереди остались задачи. К ним он вернётся на следующем витке цикла событий.выполнит все задачи из своей очереди, потому что он гарантирует выполнение кода перед обновлением интерфейса. Но если в ходе выполнения кто-то добавит новые задания в очередь, то они выполнятся уже на следующем витке.Когда наступит время простоя и в других очередях не будет более приоритетных задач, выполнится одно или несколько заданий requestIdleCallback. Таким образом, эта очередь чем-то похожа на очередь задач, но с более низким приоритетом.Взаимодействие с очередями происходит через:В Node.js цикл событий работает схожим образом: сначала выполняется задание, затем нужно заглянуть в очередь за следующим. Но набор очередей отличается, а также отсутствуют этапы, связанные с обновлением интерфейса, потому что код работает на сервере. Подробнее о циклах событий в Node.js можно почитать в серии статей , которые написал Дипал Джаясекара (Deepal Jayasekara). Для быстрого понимания setImmediate и process.nextTick есть хорошее объяснение на Stack Overflow.Это удобный и простой способ взаимодействовать с асинхронным API, но если быть с ним неаккуратным, возникает много проблем.Ад обратных вызовов (callback hell) — самая частая проблема, которую вспоминают, когда говорят про недостатки функций обратного вызова.Последовательность асинхронных вызовов через функции обратного вызова становится похожа на пирамиду судьбы (pyramid of doom).Можно подумать, что это самый главный недостаток функций обратного вызова, но на этом проблемы с ними только начинаются.Дело в том, что сходу нельзя определить, как именно будет вызвана функция обратного вызова — синхронно или асинхронно, а ведь от этого может сильно зависеть логика нашего кода. Чтобы разобраться наверняка, придётся прочитать реализацию функции. А это требует дополнительных действий и усложняет отладку.В узких кругах эта проблема широко известна как проблема монстра Залго , которого лучше не выпускать на свободу.Жёсткая сцепленность — это проблема зависимости одной части кода от другой при обработке последовательных асинхронных операций:Если ошибка наступит на этапе №1, надо будет обработать только её. Но если ошибка произойдёт уже на этапе №2, то придётся отменить этап №2, а затем и этап №1 тоже. И чем больше этапов, тем больше проблем при обработке ошибок.Инверсия управления — это передача нашего кода в библиотеку, которую писали другие разработчики:Мы полагаемся на то, что наша задача будет вызвана так, как надо, но всё может быть далеко не так. Другая библиотека может вызвать функцию слишком рано или слишком поздно, делать это слишком часто или редко, поглотить ошибки и исключения, передать неправильные аргументы или вовсе не вызвать нашу функцию.Исходя из сказанного, можно подумать, что работа с асинхронностью через функции обратного вызова — это сплошные сложности. Отчасти так и есть, но, к счастью, со всеми этими проблемами помогают справиться обещания.Обещания напоминают талончики с номером заказа в кафе. Когда мы делаем заказ, вместо еды мы получаем талончик с номером. Дальше возможны два сценария. Первый: заказ успешно приготовят и через некоторое время выдадут на стойке получения заказов. Второй: что-то может пойти не так, например, закончатся нужные ингредиенты, тогда сотрудник кафе сообщит нам, что не может приготовить наш заказ, и предложит вернуть деньги или заказать что-то другое.Обещания создаются через конструктор Promise, который обязательно вызывается через new. Конструктор принимает только один аргумент — функцию обратного вызова с двумя параметрами: resolve и reject. Внутри обещания вызывается асинхронная операция с функцией обратного вызова. В свою очередь внутри этой функции вызывается либо resolve, либо reject, которые устанавливают обещание либо на выполнение, либо на отказ соответственно.Вот так вот можно выставить обещание либо на выполнение, либо на отказ:После того как обещание установлено, результат можно получить через метод then:Обработать отказ можно либо через второй параметр в then, либо через catch:Значение обещания устанавливается один раз, после чего его уже не изменить:Для удобства можно использовать статические методы — функции-конструкторы Promise.resolve и Promise.reject, которые создают сразу установленное обещание:У обещаний ещё есть метод finally, который что-то сделает независимо от успеха или неудачи. Это чем-то похоже на приготовление блюда в духовке: неважно, пригорело наше блюдо или нет — духовку всё равно надо будет выключить.Самая главная польза обещаний в том, что мы можем выстраивать из них цепочки асинхронных операций:Если где-то произойдёт ошибка, то отказ пропустит обработчики на выполнение и долетит до ближайшего обработчика отказа, после чего цепочка продолжит работать в штатном режиме:Возвращать значение можно и внутри catch, оно будет точно так же обработано в цепочке:Если цепочка завершится, а ошибка останется необработанной, то сработает событие `unhandleledPromiseRejection`, на которое можно подписаться, чтобы отслеживать необработанные ошибки внутри обещаний:Важно понимать, что обработка ошибок работает только тогда, когда цепочка непрерывна. Если опустить return и создать обещание, установленное на отказ, то последующий catch не сможет его обработать:У обещаний есть две неявные особенности. Во-первых, методы then и catch всегда возвращают новое обещание. Во-вторых, внутри себя они перехватывают любые ошибки и, если что-то пошло не так, возвращают обещание, установленное на отказ, с причиной ошибки.Каждый вызов then или catch создаёт новое обещание, значение которого либо undefined, либо явно выставляется через return.Благодаря этому, вместо создания временных переменных можно сразу сделать удобную цепочку вызовов:При этом, если вернуть обещание, его значение распакуется и всё будет работать точно так же.За счёт этого можно избегать вложенных обещаний и всегда писать код с одним уровнем вложенности:Другая особенность обещаний связана с обработкой ошибок. Функции обратных вызовов, которые передаются в методы обещаний, оборачиваются в `try/catch`. Если что-то пойдёт не так, то try/catch перехватит ошибку и установит её в качестве причины отказа обещания:Это всё равно что самостоятельно написать вот такой код:Таким образом, внутри обещаний можно обойтись без try/catch, потому что обещания сделают это за нас. Главное — потом правильно обработать причину отказа в catch.Это объекты, в которых естьСкорее всего, это полифилы обещаний до ES6. Обещания распакуют такие объекты, а затем завернут их в полноценные ES6-обещания. По такому принципу работают resolve, Promise.resolve, then и catch.Благодаря этому обеспечивается совместимость с кодом, написанным до ES6:Есть одна особенность: если в Promise.resolve передать обычное обещание, то оно не распакуется и вернётся без изменений. При этом resolve, then, catch распакуют значение и создадут новое обещание.Но самое интересное — это поведение reject и Promise.reject, которые работают совершенно иначе. Если туда передать любой объект, в том числе и обещание, они просто вернут его как причину отказа:У обещаний есть шесть полезных статических методов. Два из них мы уже разобрали — это Promise.resolve и Promise.reject. Давайте посмотрим на другие четыре.Для наглядности напишем функцию, которая поможет получать установленное обещание через какое-то время:Все четыре метода, которые мы разберём ниже, принимают массив значений. Но каждый из этих методов работает по своему, и результаты они возвращают разные.Этот вызов возвращает массив значений или первый отказ:Если хотя бы одно обещание завершится неудачей, то вместо массива значений в catch прилетит причина отказа:Для пустого массива сразу вернётся пустой результат:Этот метод возвращает первое значение или первый отказ:Если отказ произойдёт первым, то race установится на отказ:Если передать в Promise.race пустой массив, то обращение зависнет в состоянии выполнения и не будет установлено ни на выполнение, ни на отказ:Вызов возвращает первое значение или массив с причинами отказа, если ни одно обещание не завершилось успешно:Когда все обещания установятся на отказ, то any вернёт объект ошибки, в котором информацию об отказах можно будет достать из поля errors:Для пустого массива вернётся ошибка:Метод дождётся выполнения всех обещаний и вернёт массив специальных объектов:Для пустого массива сразу вернётся пустой результат:Когда требуется перейти от функций обратного вызова к обещаниям, на помощь приходит промисификация — специальная функция-помощник, которая превращает функцию, работающую с callback, в функцию, которая возвращает обещание:Работа промисификации зависит от сигнатуры функций в коде, потому что требуется учитывать порядок аргументов, а также параметры callback. В примере выше предполагается, что функция обратного вызова передаётся последним аргументом, а в качестве параметров сначала принимает ошибку, а затем результат.Обещания устраняют недостатки функций обратного вызова. Они всегда асинхронные и одноразовые, код линейный и не обладает жётской сцепленностью, можно не переживать за ад обратных вызовов.Но как быть, если обещание всё-таки зависло и не устанавливается ни на выполнение, ни на отказ? В этом случае можно использовать Promise.race, чтобы прервать выполнение зависшего или очень длинного запроса по таймауту:В любом случае важно понимать: несмотря на многие преимущества обещаний, всё равно кое-где придётся использовать функции обратного вызова, и это нормально. Через них работают обработчики событий и многие асинхронные методы API, например setTimeout, поэтому в таких случаях нет смысла промисифицировать и удобнее использовать функции обратного вызова. В конце концов, они нам также понадобятся, чтобы создать обещание. Главное запомнить, что, если где-то есть цепочка последовательных вызовов, там обязательно надо использовать обещания.Обещания — это фундамент для работы с асинхронностью, но над этим фундаментом есть очень удобная надстройка async/await, которая реализуется благодаря корутинам.Корутина (coroutine, cooperative concurrently executed routine) — это сопрограмма или, проще говоря, особая функция, которая может приостанавливать свою работу и запоминать состояние, а также имеет несколько точек входа и выхода.В JavaScript в качестве корутин выступают функции-генераторы, которые возвращают итератор. Итератор может приостанавливать свою работу, запоминать текущее состояние и взаимодействовать с внешним кодом через .next и .throw.Благодаря таким возможностям корутин, можно написать специальную функцию следующего вида:И затем через неё последовательно вызывать асинхронные операции:Это оказалось настолько удобно, что позже в JavaScript добавили конструкции async/await.Это синтаксический сахар, реализованный через обещания и корутины, который делает работу с асинхронными операциями более удобной.Модификатор async ставится перед функцией и делает её асинхронной:Результат асинхронной функции — это всегда обещание. Для удобства можно представлять асинхронную функцию как обычную, которая заворачивает свой результат в обещание:Результат асинхронной функции извлекается через then или через await:Await немного удобнее обещаний, но у него есть серьёзное ограничение — его можно вызывать только внутри асинхронной функции. При этом асинхронность становится «прилипчивой» — стоит один раз написать асинхронный вызов, и дороги назад, в синхронный мир, уже нет. Какое-то время с этим ничего нельзя было сделать, но потом появился верхнеуровневый await.Верхнеуровневый await (top level await) позволяет использовать этот оператор за пределами асинхронных функций:Но его можно использовать только либо внутри ES6-модулей, либо в DevTools. Такое ограничение связано с тем, что await — это синтаксический сахар, который работает через модули.Например, модуль с верхнеуровневым await для разработчика выглядит так:Ни внутри модуля, ни внутри основной программы нет асинхронных функций, но при этом они необходимы для работы await. Как же тогда работает этот код?Дело в том, что движок сам возьмёт на себя задачу обернуть await в асинхронную функцию, поэтому где-то «под капотом», без синтаксического сахара, верхнеуровневый await будет выглядеть примерно так:Никакой магии. Просто синтаксический сахар.Есть два способа обработать ошибку внутри асинхронных функций. Первый — поставить catch после вызова функции, второй — обернуть вызов await в конструкцию try/catch.Поскольку асинхронные функции — это обещания, после вызова можно поставить catch и обработать ошибку.Такой способ будет работать, но, скорее всего, try/catch подойдёт лучше, потому что даст возможность обработать исключение сразу в теле функции:Другое важное преимущество: в отличие от catch, конструкция try/catch сможет обработать верхнеуровневый await.Оператор await приостанавливает выполнение задачи до завершения асинхронной операции. Если перед каждой асинхронной операцией бездумно ставить await, это может привести к неоптимальной работе кода из-за последовательной загрузки несвязанных данных.Например, список статей и картинок, которые никак друг с другом не связаны, через await можно было бы загрузить вот так:Тогда данные, которые можно было бы получить параллельно, будут запрашиваться последовательно. До тех пор пока первая часть данных не загрузится полностью, работа со второй частью не начнётся. Из-за этого задача будет выполняться дольше, чем могла бы. Допустим, каждый запрос выполняется за две секунды, тогда на полную загрузку данных уйдёт четыре секунды. Но если данные грузить параллельно, через Promise.all, то вся информация загрузится в два раза быстрее:Вот и всё, что вы, вероятно, хотели знать про асинхронность в браузере. Надеюсь, теперь вы хорошо понимаете, как действует цикл событий, сможете выбраться из ада обратных вызовов, легко работаете с обещаниями и грамотно используете async/await. Если я что-то забыл, напоминайте в комментариях."'https://habr.com/share/publication/718084/59cd5c6156bfd6f0f074385017b19497/'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
19'719202'Графический спектроанализатор с динамической индикацией на жесткой логике'Когда деревья были большими, а я был юным, но в меру упитанным электронщиком, мне доводилось проектировать весьма немаленькие светодиодные штуковины. Естественно, делалось это все на...'https://habr.com/ru/post/719202/'"Под спойлером забавная история на профессиональную тему, которая связана с этим здоровенным графическим спектроанализатором.



В то время на нашем черноморском побережье только начинали открываться модные ночные клубы с электронной музыкой. Владелец одного из таких клубов обратился к нам с целью украсить интерьер своего заведения. Отмечу, что сам владелец позиционировал себя ди-джеем.



Мне здорово пришлось попыхтеть, я первый раз писал цифровой фильтр для AVR микроконтроллера. Благо, обрабатывать сигналы в реальном времени не требовалось, и в интернете уже были примеры проектов. Контроллер накапливал измерения АЦП в пределах ограниченного окна и затем проводил вычисления, на основе которых формировалась светодиодная анимация.



Естественно, заказчик проект не принял. Буквально заявив, что это не музыка, а какая-то… ерунда. Объяснить ему, что это реальная спектрограмма, не представлялось возможным. Да и, как известно, кто платит, того и танцуют. Мне пришлось взять дополнительное время, и как следует подумать. Решение не заставило себя долго ждать.



Тогда набирал популярность медиаплеер Winamp. Он умел рисовать на экране различную анимацию на основе спектра звукового сигнала. Я некоторое время понаблюдал за тем, как плеер это делает. Тупо нарисовал десятка полтора произвольных огибающих в памяти микроконтроллера. Затем оставил в коде только вычисление низких частот. По пикам низких частот случайным порядком выгружалась одна из имеющихся псевдоогибающих и выполнялась анимация, которая гасила столбики.



При следующей встречи восторгу заказчика не было предела. «Я вижу музыку» — воскликнул он. Я не стал его переубеждать. Просто сказал, что перенастроил фильтры, поэтому в этот раз все получилось как надо.



Главный вывод из этой истории я для себя сделал. Не нужно шокировать заказчика своими новаторствами. Дайте заказчику ровно то, к чему он привык.





Конечно, сейчас при обилии китайских светодиодных экранов таким никого не удивишь. Но на тот момент китайские экраны в Россию еще не привозили.

Сейчас кто-то вряд ли сможет узнать в этом юнце с фото грузного бородатого электронщика не первой свежести, прокопченного канифолью и табачным дымом. Но тогда я только начинал постигать азы взаимодействия с заказчиком и набил на этом немало шишек.В то время на нашем черноморском побережье только начинали открываться модные ночные клубы с электронной музыкой. Владелец одного из таких клубов обратился к нам с целью украсить интерьер своего заведения. Отмечу, что сам владелец позиционировал себя ди-джеем.Мне здорово пришлось попыхтеть, я первый раз писал цифровой фильтр для AVR микроконтроллера. Благо, обрабатывать сигналы в реальном времени не требовалось, и в интернете уже были примеры проектов. Контроллер накапливал измерения АЦП в пределах ограниченного окна и затем проводил вычисления, на основе которых формировалась светодиодная анимация.Естественно, заказчик проект не принял. Буквально заявив, что это не музыка, а какая-то… ерунда. Объяснить ему, что это реальная спектрограмма, не представлялось возможным. Да и, как известно, кто платит, того и танцуют. Мне пришлось взять дополнительное время, и как следует подумать. Решение не заставило себя долго ждать.Тогда набирал популярность медиаплеер Winamp. Он умел рисовать на экране различную анимацию на основе спектра звукового сигнала. Я некоторое время понаблюдал за тем, как плеер это делает. Тупо нарисовал десятка полтора произвольных огибающих в памяти микроконтроллера. Затем оставил в коде только вычисление низких частот. По пикам низких частот случайным порядком выгружалась одна из имеющихся псевдоогибающих и выполнялась анимация, которая гасила столбики.При следующей встречи восторгу заказчика не было предела. «Я вижу музыку» — воскликнул он. Я не стал его переубеждать. Просто сказал, что перенастроил фильтры, поэтому в этот раз все получилось как надо.Главный вывод из этой истории я для себя сделал. Не нужно шокировать заказчика своими новаторствами. Дайте заказчику ровно то, к чему он привык.Конечно, сейчас при обилии китайских светодиодных экранов таким никого не удивишь. Но на тот момент китайские экраны в Россию еще не привозили.

❯ Разработка электрической схемы

❯ Сборка макета

Когда деревья были большими, а я был юным, но в меру упитанным электронщиком, мне доводилось проектировать весьма немаленькие светодиодные штуковины. Естественно, делалось это все на микроконтроллерах. Старые фотографии одной из таких штуковин навеяли мне идею собрать схему спектроанализатора, но без использования микроконтроллеров.Я поставил для себя задачу получить схему с функциональностью, аналогичной тому, что показано на видео. Также хотелось сэкономить драгоценные микросхемы, запасы которых у меня истощились. Для этого решено было делать динамическую индикацию. Да, вам не почудилось, динамическая индикация и ни каких микроконтроллеров. К тому же, динамическая индикация с легкостью позволит решить задачу одновременного отображения столбиков и точек. Количество светодиодных столбиков я решил ограничить до четырех, чтобы не раздувать слишком большую схему.Как всегда, под катом вас ждет беспощадная схемотехника на основе только жесткой логики и не менее жестких операционниках. Рассмотрим общий принцип работы спектроанализатора. Схема предназначена для графического отображения соотношения спектра сигнала по четырем полосам: 500Гц, 1кГц, 4кГц, 8кГц. Для отображения уровня сигнала используется светодиодная шкала из четырех столбцов по 20 светодиодов в каждом. Каждый столбик светодиодов отображает спектральную плотность для своей полосы частот: слева — нижние частоты, справа — верхние.Заполнение столбца светодиодов производится снизу вверх пропорционально пиковому значению сигнала в соответствующем диапазоне частот. Полное время убывания столбца составляет примерно 50мс. В каждом столбце отдельной точкой отмечается пик с временем убывания примерно 1с.Предварительный каскад А смешивает стереосигнал в моно. Смесительне имеет емкостной развязки входов. В моем случае это было не нужно. Но, при необходимости, можно поставить последовательно с входными резисторами по конденсатору примерно по 10мкФ. Полосовой фильтрограничивает полосу входного сигнала, это сделано скорее для само успокоения, чем из-за реальной необходимости, все так делают, и я решил не выделяться. А вот повторительнеобходим для согласования полосовых фильтров, его следует оставить, даже если вы решите выкинуть входной смеситель и фильтр, иначе внутреннее сопротивление источника сигнала (в нашем случае это фильтр) будет оказывать влияние на полосу пропускания фильтровРазделение спектра на четыре полосы производится фильтрами. АЧХ фильтров имеет второй порядок, этого вполне достаточно для получения удовлетворительного визуального эффекта, все-таки не измерительный прибор делаю.Усилителипозволяют получить сбалансированное отображение спектра для улучшения визуального эффекта. Регулируя их коэффициенты усиления нужно добиться того, чтобы столбики светодиодов как можно чаще «добивали» до максимума.Пиковые детекторыпредназначены для формирования уровней заполнения светодиодных столбиков для динамической индикации. Время полного убывания сигнала для них составляет примерно 50мс, это снижает мерцание индикации и позволяет формировать отдельно различимые кадры спектра сигнала. Если это время уменьшить, то светодиоды будут слишком навязчиво «мельтешить». Это время тоже можно подстроить на свой вкус в зависимости от размеров светодиодных индикаторов и личных предпочтений. Но для этого придётся менять резисторы.Пиковые детекторывыполняют аналогичные функции и используются для определения уровня индикации точек. Время полного убывания сигнала на них составляет примерно 1с. За счет этого точки на спектроанализаторе спускаются медленнее и более продолжительное время хранят пиковые значения по частотам.В основе схемы используется интегральный индикатор уровняна схеме). Схема индикации построена по динамическому принципу. Генераторопределяет частоту развертки изображения. Счетчикуправляет дешифратороми аналоговым мультиплексором. Схема поочередно выводит уровни с пиковых детекторов на индикатор уровня, а транзисторные ключи подключают соответствующий столбик линейного светодиодного индикатора.Схема динамической индикации и формирования уровней устроены таким образом, что сперва последовательно отображается один кадр с заполнением столбцов, а затем кадр с точками. Для этого пиковые детекторы столбцовподключены к младшей тетраде входов аналогового мультиплексора, а пиковые детекторы точек— к старшей тетраде.Счетчикодновременно формирует двоичный адрес для подключения одного из восьми входов мультиплексора, а также для дешифратора, который выбирает один из столбцов линейного светодиодного индикатора. Для управления мультиплексоромиспользованы три двоичных выхода счетчика, а для дешифратора— только два его младших разряда.Когда входы мультиплексора переключаются от 0-ого до 3-его, выходы дешифратора по очереди подключают столбцы с нулевого по третий. Затем, когда выходы мультиплексора продолжают переключаться от 4-ого по 7-ой, выходы дешифратора повторно подключают столбцы с нулевого по третий.Старший задействованный выходной бит счетчикатакже управляет выбором режима работы индикатора уровня«столбец/точка».За счет высокой скорости переключения столбцов в кадре и кадров со столбцами и точками, создается иллюзия одновременного отображения на индикаторе спектрограммы с быстро перемещающимися столбцами и медленно спускающимися точками.Пиковый детекторформирует опорное напряжение для индикатора уровня. За счет этого не зависимо от громкости звукового сигнала заполнение столбиков светодиодной индикации всегда производится практически на всю их высоту.Компараторотключает индикацию при отсутствии входного сигнала. Иначе пиковый детекторнастроит схему под уровень входной помехи, и светодиодный индикатор будет практически полностью светиться. Минимально различимый уровень входного сигнала можно подстроить опорным делителем напряжения.На питании схемы подробно останавливаться не буду. Отмечу только, что оно двухполярное не более, а лучше. При необходимости можно перейти на однополярное питание, для этого в схеме понадобится искусственная средняя точка, и обязательно нужно будет развязать входы схемы с помощью конденсаторов.После того, как схема была разработана и отлажена, можно приступать к ее изготовлению. Печатная плата была вырезана на ЧПУ. Подробнее о том, как я это делаю, можно посмотреть по ссылке. К моменту сборки у меня возник некоторый дефицит микросхем. В целях экономии решил ставить их через панельки. И при установке микросхемы в панельку одним неловким движением был обломлен драгоценный вывод. Пришлось имплантировать его от другой микросхемы. Сточил край корпуса надфилем, чтобы добраться до основания обломленного вывода, и подпаялся к нему.В общем, как и ожидалось, схема заработала сразу после сборки. Изображение на видео немного мельтешит из-за того, что камера различает динамическую развертку. В реальности все работает ровно. И светодиодные индикаторы остались только двухцветные, а я сразу не обратил на это внимание.Конечно же я не удержался и заказал печатную плату в зеленке. Посадочные места сразу были предусмотрены под индикаторы и под планарные светодиодики. С этим я не прогадал, так как индикаторы закончились при сборке прототипа. Пришлось паять SMD."'https://habrastorage.org/webt/ae/e9/lh/aee9lhjxutnbruw3kk5xf95cky4.jpeg'"['https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/r/w780q1/webt/bs/fu/bz/bsfubztjqwb29bfq-zdydpuuo6a.jpeg', 'https://habrastorage.org/r/w1560/webt/vj/fl/h9/vjflh9hhiyq_0ctyv6gqdqiivbq.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/a11/3c2/1cf/a113c21cfc15fd82493ce716f5cd4dc9.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f90/d95/5f8/f90d955f8384663ffc1fc21342cd2ecc.jpeg', 'https://habrastorage.org/r/w1560/webt/pp/s4/ak/pps4akd8ybzc0e0ybvg4phgsh9e.png', 'https://habrastorage.org/r/w1560/webt/p-/u9/l2/p-u9l27ynelxi92bcmdxhu76ma8.png']"
