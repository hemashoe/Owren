post_id'post_id'title'meta_description'link'body'image'images
0'719500'Европа может быть покрыта солёным льдом'Европа, спутник Юпитера – один из самых интересных объектов нашей Солнечной системы. Считается, что под его поверхностью существует океан, в котором, вероятно, содержится в три раза больше воды, чем...'https://habr.com/ru/post/719500/'"2

Европа, спутник Юпитера – один из самых интересных объектов нашей Солнечной системы. Считается, что под его поверхностью существует океан, в котором, вероятно, содержится в три раза больше воды, чем на всей Земле. Потенциально на этом небольшом спутнике может существовать жизнь. Но потенциально обитаемый подповерхностный океан – не единственное, что интересует учёных. Лёд на поверхности спутника для них не менее интересен – а особенно длинные красные полосы, пересекающие его испещрённую трещинами поверхность.Эти полосы – самый характерный визуальный признак Европы, но при этом учёные пока не могут определить их химический состав, поскольку на Земле субстанций с подобными характеристиками нет. В исследовании 2015 года было сделано предположение, что эти красные полоски могут быть отложениями соли из внутреннего океана, которая была вынесена на поверхность излучением.На изучении именно этих полос, а точнее – их химического состава и происхождения, сконцентрировалась международная команда исследователей из Вашингтонского университета. А всё благодаря открытию нового кристалла , который может помочь с объяснением процессов, породивших полосы на Европе. Кристалл был получен в лаборатории, но учёные считают, что он с тем же успехом может сформироваться и на дне глубокого океана на таком небесном теле, как Европа. Кристалл формирует вода и хлорид натрия, известный в быту, как поваренная соль – а это два самых распространённых на Земле химических соединения.Доктор Баптист Жорно, адъюнкт-профессор департамента земных и космических наук при Вашингтонском университете, говорит, что в наши дни фундаментальные открытия в науке случаются редко. «Поведение соли и воды в земных условиях хорошо нам знакомы, а вот касательно других случаев мы пребываем в неведении. И теперь мы изучаем планеты, химические вещества на которых нам очень хорошо знакомы, но находятся они в крайне экзотических условиях. И нам приходится заново переизобретать всю минералогию с XIX века, приспосабливая её для высоких давлений и низких температур. Это очень интересное занятие».В рамках работы исследователи изучали гидрат – ледяную решётку, формирующуюся в холодной солёной воде. До недавнего времени учёным был известен только один гидрат хлорида натрия – гидрогалит . В нём на каждую молекулу соли приходится две молекулы воды (NaCl•2HO).При помощи прозрачных алмазов учёные сжали крохотное количество солёной воды при низкой температуре до давления, в 25 000 раз превосходящего атмосферное. В результате они нашли два новых вида кристалла гидрата хлорида натрия. В первой структуре содержится две молекулы хлорида натрия на 17 молекул воды, в другой – одна молекула хлорида натрия на 13 молекул воды. Также оказалось, что первая структура остаётся стабильной даже при минимальном давлении, близком к вакууму – таком, которое наблюдается на поверхности Луны. Вторая структура оставалась стабильной только при высоких давлениях. Вероятно, эти уникальные кристаллические структуры могут объяснить происходящее на поверхностях спутников Юпитера.«Мы пытались понять, как добавление соли изменит количество льда, которое можно получить – ведь соль работает как антифриз, — сказал Жорно. – Мы с удивлением обнаружили, что при повышении давления начали расти вот эти неожиданные кристаллы. Это была удача».Подобные условия с низкой температурой и большим давлением скорее всего существуют и на Европе. Учёные предполагают, что её океан может быть глубиной в сотни километров, а покрывать его может слой льда толщиной от 5 до 10 км. На дне океана, скорее всего, существуют более плотные ледяные структуры – там ещё холоднее, а давление ещё больше.Далее учёные планируют создать более крупный образец кристалла, чтобы узнать, соответствуют ли красные полосы на Европе свойствам двух найденных кристаллов.У НАСА и Европейского космического агентства ЕКА есть в разработке несколько миссий, которые планируют посетить Европу и Титан для изучения их обитаемости. ЕКА в апреле этого года планирует запустить зонд для изучения ледяных спутников Юпитера JUICE. К системе Юпитера он прибудет в июле 2031 года. Миссия НАСА Europa Clipper запланирована на октябрь 2024 года, и прибудет к Юпитеру в 2030-м. Миссия НАСА к Титану, Dragonfly, должна будет стартовать в 2027 и прибыть к Титану в 2034. Эти миссии будут изучать химический состав этих загадочных и интригующих миров, и помогут учёным разработать наиболее подходящие способы поисков признаков жизни.Доктор Жорно говорит, что это единственные планеты кроме Земли, на которых жидкая вода существует достаточно долго по геологическим масштабам – а это важнейшее условие для появления и развития жизни. «Они, по моему мнению, представляют собой наилучшие места в нашей Солнечной системе для обнаружения внеземной жизни. Нам необходимо изучать их экзотические океаны и общую композицию, чтобы лучше понять историю их формирования, эволюции, и то, как они смогли удержать воду в жидком состоянии в холодных регионах Солнечной системы, на таком расстоянии от Солнца»."'https://habr.com/share/publication/719500/959ea587b1e57b172bbecf031a739ea3/'"['https://habrastorage.org/r/w780q1/getpro/habr/post_images/d56/0bf/a61/d560bfa61ba8ca27072f36f434f3ed96.jpg', 'https://habr.com/share/publication/719500/959ea587b1e57b172bbecf031a739ea3/', 'https://habrastorage.org/r/w780q1/getpro/habr/post_images/3d8/da5/202/3d8da52028b1ffa77a841063ad2295fe.jpg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w32/getpro/habr/avatars/329/fc8/9e5/329fc89e55a9132bf200ff315065f3f7.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/post_images/bbe/dee/8f3/bbedee8f370926b84c3e7cdec68a5fa5.png', 'https://habrastorage.org/getpro/habr/avatars/329/fc8/9e5/329fc89e55a9132bf200ff315065f3f7.jpg']"
1'719200'«Докажите, что кариес — поведенческое заболевание» — ок, давайте мы докажем своими деньгами'Вы как-то спросили, готовы ли мы подписаться под тем, что, если вовремя делать профилактику, кариес не возникнет. Мы некоторое время чесали голову и решили, что готовы. Логика простая: если вы ходили...'https://habr.com/ru/post/719200/'"Краткий ликбез на тему «Что такое кариес»

Этиологический (причинный) фактор — наличие самой бактерии. Повторюсь: с этим мы ничего сделать не можем. От наследственности, кстати, зависит только тяжесть течения болезни, на восприимчивость к кариесу она не влияет.

Патогенетических факторов много: от неправильного питания до нарушения микробного гомеостаза. Один из самых важных — наличие бактериальной бляшки, то есть зубного налёта, в котором размножаются бактерии. И это как раз тот фактор, убрать который проще всего.

Кому и почему мы обещаем вылечить зубы бесплатно

Вам должно быть больше 14 лет. У вас должна быть полностью санирована полость рта.



То есть все кариозные полости должны быть запломбированы. Определить их наличие «на глазок» бывает непросто даже врачу. Поэтому первый приём включает в себя рентгеновские снимки зубов.



Снимки также могут понадобиться и на следующих приёмах, если есть потребность в пристальном наблюдении за чем-нибудь подозрительным.



Не пугайтесь, это довольно безобидно. Дозы лучевой нагрузки минимальные.



Интерпроксимально три-четыре зуба — 0,003 мЗв.

Восемь зубов одной челюсти — 0,04 мЗв.

Восемь зубов на двух челюстях — 0,06 мЗв.

Обе челюсти — 0,07 мЗв.

Вся голова — 0,1 мЗв.

Доза лучевой нагрузки, которую ВОЗ не рекомендует превышать, составляет 150 мЗв в год. Это 50 тысяч интерпроксимальных снимков или 1500 снимков всей головы целиком

Но если что, у нас также есть классный аппарат для трансиллюминации — абсолютно безвредной процедуры, которая позволяет просветить и запечатлеть на фото зубы без использования рентгена.





Наш аппарат для трансиллюминации выглядит вот так





Процесс происходит примерно вот так





Так трансиллюминация показывает здоровый зуб





А так — кариозная полость Вы должны приходить на профгигиену четыре раза в год.



В зубной эмали постоянно протекают два процесса: деминерализация и реминерализация. То есть она одновременно теряет калий, фтор и прочие важные элементы и тут же получает их обратно из слюны.



Если баланс нарушен, возникает так называемый «кариес в стадии пятна». Это деминерализованный, а значит, особенно уязвимый участок на поверхности эмали. При большом приближении это выглядит, как соты, в которых не хватает мёда. Если процесс «откачки мёда», то есть реминерализации продолжится, на этом месте появится кариозная полость.





А теперь представьте, что мёд начинают откачивать



Если это случилось, можно сразу просверлить зуб и поставить пломбу. Но гораздо экологичнее стабилизировать его, наблюдать и поддерживать. Именно поэтому профгигиена всегда заканчивается минерализацией зубов. Если говорить на языке пчёл, мы заполняем соты мёдом и «запечатываем» их до поры до времени.





Мы покрываем зубы специальным составом, который служит источником для эмали, дополняем её потерянными микроэлементами



Эффект от минерализации в среднем сохраняется три месяца. Так что если человек повторяет эту процедуру четыре раза в год, мы точно знаем, что его зубы защищены. А значит, с большой степенью вероятности, с ними ничего не случится. Ну, если не падать на них с третьего этажа, конечно. Вы должны будете соблюдать рекомендации, составленные врачом-гигиенистом.

И это самое важное условие. Потому что все усилия стоматологов будут напрасны, если человек не сможет поддерживать должный уровень личной гигиены.

Что такое гигиенический индекс

Как мы будем чистить ваши зубы

Что, правда учите чистить зубы? Серьёзно?

«Что если я вылечу кариес в другой клинике?»

Прямым — это пломба, то есть та реставрация, которая сделана непосредственно в полости рта (полный FAQ читайте тут).

Непрямым — это вкладка или коронка, то есть, штука, которая сделана в лаборатории, а потом прикреплена к челюсти (про них подробно было здесь).

Главная цель «Белой Радуги» и «почему мы всё это делаем»

Пациентам — понятно, но почему это выгодно клинике?

Вы как-то спросили, готовы ли мы подписаться под тем, что, если вовремя делать профилактику, кариес не возникнет. Мы некоторое время чесали голову и решили, что готовы.Логика простая: если вы ходили на приёмы регулярно, а кариес возник — лечение полностью за наш счёт.То есть те пациенты, которые и так делают всё правильно и не забивают на профилактику, получают бесплатный бонус. Те же, кто ходил нерегулярно, лечить, когда уже сильно заболело, — остаются при своих.Сейчас расскажу, как это всё работает, и почему мы считаем, что это нормально и не разорит нас.Есть в мире инфекционное заболевание, от которого страдает плюс-минус 100% взрослых людей на планете. Оно известно нам испокон веков, но вакцины не изобрели до сих пор, хотя учёные разных стран работают над ней уже больше 40 лет. Ближе всех к решению проблемы, пожалуй, подошли китайские учёные (кстати, в той самой уханьской лаборатории), но и у них тоже рабочего и безопасного препарата пока так и не получилось.Это болезнь, которая не зависит ни от пола, ни от генетики, и почти не зависит от возраста. А, в основном, от диеты и поведения человека.Когда-то люди считали, что кариес появляется, когда зубы начинают грызть специальные невидимые черви, посланные нам, конечно же, за грехи. Но потом наука шагнула вперёд, и стало достоверно известно, что грехи тут ни при чём, а болезнь вызывают куда более мелкие «зверюшки» — бактерии. Главный спонсор стоматологов Streptococcus mutans — одна из самых распространённых бактерий, которая живёт во рту примерно у 100% людей . Хотя кариес могут вызвать и другие её «коллеги»: Streptococcus sanguis, Streptococcus mitis и Lactobacillus acidophilus. Бояться их не стоит: в ротовой полости любого, даже самого здорового, человека живёт около 700 видов микроорганизмов. Не одновременно, но тем не менее.Для развития любой болезни нужно, чтобы «сложился пазл» из этиологии и патогенеза. А чтобы она НЕ развивалась, важно нарушить эту цепочку хотя бы в одном месте.Начну издалека.Стрептококки, как и люди, любят торты, конфеты и вообще простые углеводы. Дело в том, что это анаэробные бактерии, которые боятся кислорода. В ходе гликолиза, то есть сбраживания углеводов, они получают энергию для своей жизнедеятельности, а из оставшейся сахарозы строят «панцирь», защищающий от кислорода. Это и есть зубной налёт. В среднем он успевает образоваться за три-шесть часов. А совсем уж плотная биоплёнка — за сутки. Если бактериям не мешать, разумеется.И можно было бы вполне мирно ужиться со стрептококками, но вся их жизнедеятельность приводит к образованию кислот: пировиноградной, муравьиной, уксусной, пропионовой и т.д. Замечали кисловатый привкус во рту после поедания печенья? Вот — это оно. Кислотность во рту повышается, а, как только pH падает ниже 5.5, эмаль размягчается и начинает терять важные минералы. В течение двух часов слюна потихоньку выравнивает кислотно-щелочной баланс, и крепость эмали восстанавливается. От частых приёмов пищи участок зуба размягчается всё сильнее и сильнее, пока не появится кариозная полость.Шоколад и сахар, кстати, как и другие легкорастворимые углеводы, в этом плане более безопасны: они быстро смываются слюной и всасываются в слизистую. Куда хуже дело обстоит с печеньем, хлебом и прочими высокомолекулярными крахмальными продуктами, которые налипают на зубы. Бактерии разбирают их «по кирпичикам» гидролазами и с удовольствием едят.Зубная эмаль — это композит из органической и минеральной части. Повернуть время вспять и «вырастить» её заново невозможно. Но, если бактерии не успели добраться до органического каркаса, кариес на стадии пятна вполне обратим. И, в любом случае, замедлить процесс образования кариеса вполне реально. Не то что на годы, даже на десятилетия — если помочь процессу реминерализации.И ещё пару слов скажу про вакцину. Сделать прививку и навсегда забыть про кариес весьма заманчиво, конечно. И разработок самых разных хватает: от заместительной терапии до ДНК-вакцин. Но это все пока экспериментальные методы лечения, мы такие не используем — это как минимум неэтично и непрофессионально. Но и когда такие появятся в официальных медицинских протоколах — поверьте, хорошие стоматологи не останутся без работы, даже если заболеваемость кариесом удастся радикально снизить.У нас в «Белой Радуге» недавно появилась классная программа « Smilekeeper »: профессиональная чистка зубов с гарантией. Мы обещаем бесплатно лечить кариес тем, кто приходит к нам на профгигиену раз в три месяца. Важно: мы не берём на себя смелость обещать, что дырок в зубах у вас точно не будет, но говорим, что, если они всё-таки появятся, мы их запломбируем бесплатно, пока маленькие.Важно: на эту программу мы готовы взять далеко не всех. Не можем мы пригласить и тех, кто носит брекет-системы, простите.Да, ортодонтическая аппаратура существенно осложняет самостоятельный уход за зубами и создаёт новые участки, где может задерживаться налёт, поэтому профгигиена раз в три-четыре месяца, безусловно, этим людям нужна. Но, к сожалению, эта же аппаратура не позволяет провести раннюю диагностику и выявить кариес в самом начале. А без диагностики мы не можем дать никаких гарантий.Есть ещё несколько важных условий.Так что предупреждаю — следить за личной гигиеной мы будем строго. Но подробнее об этом я расскажу немного позже.Уровень личной гигиены, кстати, вполне реально оценить объективно. Для этого есть один хороший показатель — гигиенический индекс Вычислить его нам поможет специальный индикатор, позволяющий определить не только объём налёта, но и его возраст.Так вот. Мы, конечно, не ждём и не требуем, чтобы все наши пациенты целыми днями занимались только чисткой зубов, забыв про еду и сон, но принимаем в программу только людей, чей гигиенический индекс не ниже 1 (удовлетворительно). Добиться такого вполне реально, если правильно чистить зубы два раза в день: после завтрака и после ужина. О том, как правильно это делать, очень подробно рассказывала моя коллега Оценить количество и качество зубного налёта, к слову, можно не приходя в клинику: похожий индикатор продаётся в аптеке. Например, таблетки Curaprox, Динал, либо жидкость Curaprox, PresiDENT.Допускаю, что будут и те, кому мы скажем: «К сожалению, у вас не получается поддерживать гигиену на необходимом для этой программы уровне. Оставшуюся невостребованной сумму вы можете потратить на любые другие процедуры». Просто потому, что давать какие бы то ни было гарантии, когда мы сами не уверены, нечестно и несправедливо.Самое важное, о чём я хотел бы сказать: гигиена полости рта — это не какой-то идеал, которого можно однажды достигнуть и закрыть этот вопрос навсегда, а состояние, которое нужно постоянно поддерживать. Это как спортивная форма или мышечная масса.У нас в клинике придерживаются профессионального и научно обоснованного подхода. Это использование ручных инструментов, специальных паст, вращающихся щёток, полимерных головок и других прикольных «игрушек» для стоматологов. Так что мы можем провести профессиональную гигиену абсолютно всем, независимо от особенностей. Да, это занимает больше времени. Но результат очень нравится и нам, и пациентам.Как из точки А в точку Б можно добраться разными видами транспорта, так и чистоты зубов тоже можно добиться разными методами.Среди тех, что на слуху — порошкоструйная очистка зубов Air Flow. Это, конечно, метод очень удобный, быстрый, но не единственный. У него есть свои преимущества и недостатки, довольно существенные.И самое важное: после профессиональной чистки зубов мы научим вас поддерживать гигиену полости рта самостоятельно, потому что считаем, что это одна из самых полезных для здоровья привычек.Конечно, серьёзно.Есть какие-то общие понятия, информацию о которых можно найти в интернете: выбор щётки и пасты, например. Но, кроме этого, у каждого человека есть свои отличительные черты. Правила для людей с высокой резистентностью эмали, например, будут отличаться от правил для тех, у кого она средняя или низкая. Кроме того, важно учесть особенности прикуса, анатомию зубов и т.д. Продумать всё самостоятельно практически невозможно. Но гигиенист нужен ещё и для того, чтобы вампридумывать правила самостоятельно.Сразу после окрашивания зубного налёта врач сфотографирует эти фиолетовые зубы и покажет пациенту, где у него самые уязвимые участки. А потом ещё и щётку подарит, и почистить зубы в своём присутствии попросит, и процесс проконтролирует, и советов надаёт.Есть, кстати, некоторые важные тонкости, о которых мало кто знает. Например, что чистить зубы нужно сухой щёткой. А пасты на неё класть не полтюбика, как в рекламе показывают, а маленькую горошинку. Иначе будет образовываться слишком много пены, а это уменьшает продолжительность чистки зубов.Можно вообще чистить зубы сухой щёткой без пасты где-нибудь на кухне под сериальчик. Особенно этот метод хорошо работает с детьми. Пускай берут щётку и смотрят свои мультики, главное, чтобы водить щёткой по зубам не забывали. Ничего страшного не случится, если они проглотят то, что начистили, это пасту глотать нельзя, а бактерии — можно.Что ж, если лечение проведено в соответствии с современными рекомендациями общероссийской стоматологической ассоциации, причём корректно: не нарушено краевое прилегание, края не нависают и т.д., мы можем взять этого человека в программу. Но с одним условием: гарантия не будет распространяться на рецидивный кариес.Дело в том, что, если коллеги из другой клиники оставили под пломбой хоть немного поражённого дентина, кариес обязательно начнётся снова. А мы не можем ни доставить под пломбу реминерализующий состав, ни убрать оттуда поражённую ткань, ни определить, всё ли там, вообще, в порядке. Брать на себя ответственность за чужую работу неправильно.Про рецидивирующий кариес и прочие тонкости пломбирования зубов углубляться не буду — про это уже рассказывала коллега А вот вторичный кариес, который возникает вокруг пломбы, — это уже наша зона ответственности, он под гарантию попадает.И ещё один тонкий момент.Восстановление зуба может быть:Так вот. Даже если в другой клинике вам поставили очень красивую и аккуратную пломбу, которая замещает больше 40-50% твёрдых тканей зуба, мы не сможем пригласить вас в программу Smilekeeper. Потому что пломба эта будет радовать вас недолго, даже если под ней не осталось никакого поражённого дентина. Потом она потеряет герметичность, и снова здравствуй, кариес! Переделывать свежую пломбу, конечно, не стоит. Лучше ходить на гигиену и внимательно следить, что происходит с зубом. Как только начнётся «разгерметизация», мы это заметим и предложим заменить её на вкладку, пока она не наделала дел. А после этого подключим вас к программе.Сейчас скажу одну вещь, которая, возможно, покажется вам очень странной. Самая главная, глобальная цель «Белой Радуги» — насколько это возможно, уйти от лечения заболеваний. Мы очень хорошо умеем это делать, но в моей идеальной картине мира 80% времени в клинике работают гигиенисты, и только 20% — все остальные: терапевты, хирурги, ортодонты и т.д. Я знаю, что такие клиники есть. Правда, пока не в России. Когда они появятся и у нас, я буду знать, что люди изменили отношение к собственному здоровью.Не поймите меня превратно. Стоматология у нас в стране находится на очень высоком уровне относительно стран запада. Но, в силу географических, экономических и социокультурных факторов, отношение к ней меняется очень медленно. Профилактикой кариеса обеспокоено всего 13,6% наших сограждан. И все они — новый класс.Если человек идёт к стоматологу не для того, чтобы снять острую боль, а заранее — чтобы боль эта не возникала, это уже не медицина, а поддержание высокого качества жизни. Как фитнес, например. До этого нужно дорасти: и ментально, и материально.Мысль о ценности своего здоровья можно поддерживать по-разному. Я знаю, как работают многие клиники в мире. Например, кое-где на западе принята такая практика: если человек регулярно приходит на профгигиену, за стоматологическое лечение он платит всего 25% от реальной стоимости. Если не ходит — то все 100%. А это очень большие деньги. Поэтому тщательно следить за состоянием полости рта там выгодно экономически.Скептики пожмут плечами и спросят: «А как же вы планируете отбивать стоимость дорогого оборудования?» Но уж об этом в ближайшие лет 20 можно не беспокоиться: пациентами на дорогостоящее лечение мы обеспечены ещё надолго.И да, конечно, рабочее место гигиениста ничем не отличается от рабочего места врача-эндодонтиста, который делает повторное лечение корневых каналов, несмотря на то, что чек у них может отличаться в 10 раз. Но ведь и расходные материалы стоят по-разному. И само время доктора тоже. Хотя бы потому, что отличного гигиениста можно взрастить всего за год, а вот хорошего имплантолога — уже нет, для этого нужна высокая квалификация и большой опыт.А ещё людей, которые могут себе позволить лечение за полтора миллиона гораздо меньше, чем тех, кто готов платить 35 тысяч в год за профилактику, так что у гигиениста ещё и охват будет гораздо выше. Впрочем, если вам удобнее оплачивать отдельные визиты, то мы совсем не против. Просто программа на год вперед дешевле обойдется.Вот так путём нехитрых вычислений выясняется, что в итоге рентабельность у дорогих и относительно дешёвых услуг вполне сопоставима.Надо бы закончить статью каким-нибудь патетическим призывом заботиться о здоровье зубов, пока они ещё с вами, регулярно их чистить и приходить к нам на гигиену.Но — не буду, потому что каждый делает свой выбор сам."'https://habrastorage.org/webt/uy/8-/gr/uy8-grccgq1opkxrfc6zib9yyc0.jpeg'"['https://habrastorage.org/r/w780q1/webt/cu/ds/c9/cudsc9drhmcei_lgcioh4yoryck.jpeg', 'https://habrastorage.org/r/w780q1/webt/uy/8-/gr/uy8-grccgq1opkxrfc6zib9yyc0.jpeg', 'https://habrastorage.org/r/w780q1/webt/sa/qx/ud/saqxudyfstov9adkte5aeexfsps.jpeg', 'https://habrastorage.org/r/w780q1/webt/-e/bg/x_/-ebgx_tbv3rafdztekqiufc-mcg.jpeg', 'https://habrastorage.org/r/w780q1/webt/gl/fo/ox/glfooxxxdcwxnh2ajhdgcgziocq.jpeg', 'https://habrastorage.org/getpro/habr/avatars/b6b/ba7/476/b6bba7476cbb58cee7a647547d8ef309.jpg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/webt/uy/8-/gr/uy8-grccgq1opkxrfc6zib9yyc0.jpeg', 'https://habrastorage.org/getpro/habr/company/5d6/3be/9f3/5d63be9f367243930cea591ef4e232d4.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b6b/ba7/476/b6bba7476cbb58cee7a647547d8ef309.jpg', 'https://habrastorage.org/r/w780q1/webt/ve/b8/sa/veb8sa39s7og4wdkeixg4-bf--y.jpeg', 'https://habrastorage.org/r/w780q1/webt/ar/lu/ql/arluqlisc1pmjn-nabqkld2g2y4.jpeg', 'https://habrastorage.org/r/w1560/webt/84/tn/0e/84tn0eeek-qv0m2nzi3ykicyxfk.png', 'https://habrastorage.org/r/w1560/webt/5v/fr/np/5vfrnprhxysvlwzaaxptx7hfqem.png', 'https://habrastorage.org/r/w780q1/webt/uq/5s/e_/uq5se_1otjttm5xlqv1afwa7s88.jpeg']"
2'719402'Проблемы безопасности SNMP на практике: имитация атак и меры профилактики'Уже больше 30 лет для мониторинга оборудования и сервисов используют протокол SNMP. За это время он прошел закономерную эволюцию, получив несколько версий протокола с особенностями безопасной...'https://habr.com/ru/post/719402/'"Знакомство с SNMP

Что нужно учитывать во время обзора проблем безопасности

Менеджер, Network Management Station (NMS) — занимается отправкой запросов агентам, получением «ловушек» (trap) от агентов, анализирует полученную информацию и может реагировать на полученные значения, например, отправляя команды по изменению параметров сетевых устройств. Агент — отвечает на запросы менеджера, отправляя необходимые сведения об устройстве, направляет менеджеру «ловушки» в соответствии с заданным расписанием.

noAuthNoPriv — без аутентификации и шифрования, при использовании этого режима все равно требуется securityName,

— без аутентификации и шифрования, при использовании этого режима все равно требуется securityName, authNoPriv — с аутентификацией, но без шифрования,

— с аутентификацией, но без шифрования, authPriv — с аутентификацией и шифрованием.

В настоящее время SNMPv3 поддерживает алгоритмы MD5 и SHA для вычисления хэшей при аутентификации и алгоритмы DES и AES для шифрования полезной нагрузки.

Какие данные можно получить по SNMP

Какие изменения можно произвести на оборудовании с помощью SNMP

Эксплуатация уязвимостей

Проблема эксплуатации уязвимостей решается своевременными обновлениями прошивок и ограничением доступа к SNMP-агенту.

Примеры реализации проблем безопасности

SNMP-agent — эмулированные устройства,

NMS — легитимный SNMP-сервер, выполняющий роль менеджера (в реальной схеме может быть тот же Zabbix-сервер),

attacker — хост, с которого будут проводиться тестовые попытки доступа к данным протокола SNMP.

Подбор community string

root@attc:~# patator snmp_login host=192.168.100.20 version=2 community=FILE0 0=community

16:07:48 patator INFO - code size time | candidate | num | mesg … 16:08:30 patator INFO - 0-0 40 3.931 | yellow | 116 | No SNMP response received before timeout 16:08:30 patatorINFO - 0-0 576 0.520 | public | 117 | [ObjectType(ObjectIdentity(<ObjectName value object at 0x7fc019d3e190 tagSet <TagSet object at 0x7fc01b5fedf0 tags 0:0:6> payload [1.3.6.1.2.1.1.1.0]>), <DisplayString value object at 0x7fc01994a670 tagSet <TagSet object at 0x7fc01b5fe7f0 tags 0:0:4> subtypeSpec <ConstraintsIntersection object at 0x7fc019708370 consts <ValueSizeConstraint object at 0x7fc01b69bf40 consts 0, 65535>, <ValueSizeConstraint object at 0x7fc019708670 consts 0, 255>, <ValueSizeConstraint object at 0x7fc019708250 consts 0, 255>> encoding iso-8859-1 payload [Linux nmsworker-... EDT 2009 x86_64]>)] 16:08:30 patator INFO - 0-0 450 0.509 | private | 118 | [ObjectType(ObjectIdentity(<ObjectName value object at 0x7fc019cf8520 tagSet <TagSet object at 0x7fc01b5fedf0 tags 0:0:6> payload [1.3.6.1.2.1.1.1.0]>), <NoSuchObject value object at 0x7fc019cf8670 tagSet <TagSet object at 0x7fc01b5c43a0 tags 128:0:0> subtypeSpec <ConstraintsIntersection object at 0x7fc01b5fecd0 consts <SingleValueConstraint object at 0x7fc01b5febe0 consts b''>> encoding iso-8859-1 payload [No Such Object c...ists at this OID]>)] 16:08:32 patator INFO - 0-0 40 3.111 | write | 114 | No SNMP response received before timeout 16:08:33 patator INFO - 0-0 40 3.514 | world | 113 | No SNMP response received before timeout 16:08:33 patator INFO - 0-0 40 3.502 | xyzzy | 115 | No SNMP response received before timeout 16:08:34 patator INFO - Hits/Done/Skip/Fail/Size: 118/118/0/0/118, Avg: 2 r/s, Time: 0h 0m 45s

Обход white-list с помощью IP-spoofing

user@snmp:~# snmpwalk -v2c -c public 192.168.100.20 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 = IpAddress: 192.168.104.1

user@snmp:~# snmpset -v2c -c private 192.168.100.20 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 a 192.168.104.2 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 = IpAddress: 192.168.104.2

usert@snmp:~# snmpwalk -v2c -c public 192.168.100.20 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 = IpAddress: 192.168.104.2

user@snmp:~# snmpwalk -v2c -c public 192.168.100.20 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 = IpAddress: 192.168.104.1

root@attc:~# snmpwalk -v2c -c public 192.168.100.20 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 Timeout: No Response from 192.168.100.20

root@attc:~# snmpset -v2c -c private 192.168.100.20 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 a 192.168.104.5 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 = IpAddress: 192.168.104.5

user@snmp:~# snmpwalk -v2c -c public 192.168.100.20 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 iso.3.6.1.2.1.4.21.1.7.0.0.0.0 = IpAddress: 192.168.104.5

Незащищенные каналы (MITM)

user@snmp:~# snmpwalk -v2c -c SecretCommunityString 192.168.100.20

root@attc:~# tcpdump -pni enp0s6 -vv -X tcpdump: listening on enp0s6, link-type EN10MB (Ethernet), capture size 262144 bytes 12:18:06.427236 IP (tos 0x0, ttl 63, id 4300, offset 0, flags [DF], proto UDP (17), length 83) 192.168.200.10.34125 > 192.168.100.20.161: [udp sum ok] { SNMPv2c C=""SecretCommunityString"" { GetNextRequest(25) R=216409089 .1.3.6.1.2.1 } } 0x0000: 4500 0053 10cc 4000 3f11 7d5e c0a8 c80a E..S..@.?.}^.... 0x0010: c0a8 6414 854d 00a1 003f d93e 3035 0201 ..d..M...?.>05.. 0x0020: 0104 1553 6563 7265 7443 6f6d 6d75 6e69 ...SecretCommuni 0x0030: 7479 5374 7269 6e67 a119 0204 0ce6 2401 tyString......$. 0x0040: 0201 0002 0100 300b 3009 0605 2b06 0102 ......0.0...+... 0x0050: 0105 00 ... 12:18:07.427592 IP (tos 0x0, ttl 63, id 4542, offset 0, flags [DF], proto UDP (17), length 83)

user@snmp:~# snmpwalk -v3 -l authPriv -u snmp -a SHA -A ""Password1"" -x AES -X ""Password2"" 192.168.100.20

192.168.200.10.44328 > 192.168.100.20.161: [udp sum ok] { SNMPv3 { F=r } { USM B=0 T=0 U="""" } { ScopedPDU E= C="""" { GetRequest(14) R=1173627123 } } } 0x0000: 4500 005b 3426 4000 3f11 59fc c0a8 c80a E..[4&@.?.Y..... 0x0010: c0a8 6414 ad28 00a1 0047 88c0 303d 0201 ..d..(...G..0=.. 0x0020: 0330 1002 045e 43cb 9302 0205 c004 0104 .0...^C......... 0x0030: 0201 0304 1030 0e04 0002 0100 0201 0004 .....0.......... 0x0040: 0004 0004 0030 1404 0004 00a0 0e02 0445 .....0.........E 0x0050: f420 f302 0100 0201 0030 00 .........0. 13:18:12.325339 IP (tos 0x0, ttl 128, id 11282, offset 0, flags [none], proto UDP (17), length 123) 192.168.100.20.161 > 192.168.200.10.44328: [udp sum ok] { SNMPv3 { F= } { USM B=0 T=0 U="""" } { ScopedPDU E=_80_00_13_70_01_c0_a8_64_14 C="""" { Report(28) R=0 .1.3.6.1.6.3.15.1.1.4.0=9 } } } 0x0000: 4500 007b 2c12 0000 8011 60f0 c0a8 6414 E..{,.....`...d. 0x0010: c0a8 c80a 00a1 ad28 0067 36d0 305d 0201 .......(.g6.0].. 0x0020: 0330 1002 045e 43cb 9302 0205 dc04 0100 .0...^C......... 0x0030: 0201 0304 1930 1704 0980 0013 7001 c0a8 .....0......p... 0x0040: 6414 0201 0002 0100 0400 0400 0400 302b d.............0+ 0x0050: 0409 8000 1370 01c0 a864 1404 00a8 1c02 .....p...d...... 0x0060: 0100 0201 0002 0100 3011 300f 060a 2b06 ........0.0...+. 0x0070: 0106 030f 0101 0400 4101 09 ........A.. 13:18:12.325605 IP (tos 0x0, ttl 63, id 13351, offset 0, flags [DF], proto UDP (17), length 146) 192.168.200.10.44328 > 192.168.100.20.161: [udp sum ok] { SNMPv3 { F=apr } { USM B=0 T=0 U=""snmp"" } { ScopedPDU [!scoped PDU]7e_09_5f_c2_51_6c_f0_89_b1_99_42_81_0c_63_9c_6d_97_ed_1e_df_89_f0_a1_7f_34_1a_e6_da_de_ac_62_02_ef_90_a9_4f_a5_d6_b1_78_de_3b} } 0x0000: 4500 0092 3427 4000 3f11 59c4 c0a8 c80a E...4'@.?.Y..... 0x0010: c0a8 6414 ad28 00a1 007e dc2c 3074 0201 ..d..(...~.,0t.. 0x0020: 0330 1002 045e 43cb 9202 0205 c004 0107 .0...^C......... 0x0030: 0201 0304 3130 2f04 0980 0013 7001 c0a8 ....10/.....p... 0x0040: 6414 0201 0002 0100 0404 736e 6d70 040c d.........snmp.. 0x0050: 4980 30f2 7794 2a38 c306 adfb 0408 6670 I.0.w.*8......fp 0x0060: 60c8 63ad 6bd6 042a 7e09 5fc2 516c f089 `.c.k..*~._.Ql.. 0x0070: b199 4281 0c63 9c6d 97ed 1edf 89f0 a17f ..B..c.m........ 0x0080: 341a e6da deac 6202 ef90 a94f a5d6 b178 4.....b....O...x 0x0090: de3b .; 13:18:12.326013 IP (tos 0x0, ttl 128, id 11283, offset 0, flags [none], proto UDP (17), length 127) 192.168.100.20.161 > 192.168.200.10.44328: [udp sum ok] { SNMPv3 { F= } { USM B=0 T=0 U=""snmp"" } { ScopedPDU E=_80_00_13_70_01_c0_a8_64_14 C="""" { Report(28) R=0 .1.3.6.1.6.3.15.1.1.3.0=9 } } } 0x0000: 4500 007f 2c13 0000 8011 60eb c0a8 6414 E...,.....`...d. 0x0010: c0a8 c80a 00a1 ad28 006b 4fe1 3061 0201 .......(.kO.0a.. 0x0020: 0330 1002 045e 43cb 9202 0205 dc04 0100 .0...^C......... 0x0030: 0201 0304 1d30 1b04 0980 0013 7001 c0a8 .....0......p... 0x0040: 6414 0201 0002 0100 0404 736e 6d70 0400 d.........snmp.. 0x0050: 0400 302b 0409 8000 1370 01c0 a864 1404 ..0+.....p...d.. 0x0060: 00a8 1c02 0100 0201 0002 0100 3011 300f ............0.0. 0x0070: 060a 2b06 0106 030f 0101 0300 4101 09 ..+.........A..

Как повысить безопасность

Уже больше 30 лет для мониторинга оборудования и сервисов используют протокол SNMP. За это время он прошел закономерную эволюцию, получив несколько версий протокола с особенностями безопасной передачи данных.В рамках статьи попробуем погрузиться в практические аспекты безопасности передаваемых по SNMP данных. И понять, какие угрозы может нести небезопасная настройка и как это исправить.SNMP — это стандартизированный протокол управления устройствами, которые находятся в IP-сетях — маршрутизаторами, коммутаторами, серверами , источниками бесперебойного питания и другими. С помощью SNMP можно отслеживать текущее состояние оборудования, управлять сетевыми устройствами, описывая различные сценарии. Про работу протокола читайте по ссылке В SNMP есть два участника взаимодействия:Стоит отметить, что отправка «ловушек» агентом и направление менеджером запроса к нему могут происходить одновременно, потому что они не зависят друг от друга. Обычно взаимодействие реализуется так, что менеджер опрашивает агенты по определенному состоянию, а на агентах настроена отправка «ловушек» менеджеру в случае критических событий. То есть агент может уведомить менеджера о критическом событии до того, как на менеджере наступит время отправки запроса.. Это позволяет не нагружать сеть TCP-соединениями. Стоит упомянуть, что при обращении мастера к клиенту происходит ожидание ответа и повторный запрос, если его время превышено. В случае же отправки «ловушки» клиентом и потери пакетов по пути, сам клиент не узнает, что она не дошла, а мастер — что что-то должно было прийти.Так в SNMPv1 и SNMPv2 используется аутентификация по community string — в SNMPv3 есть три уровня безопасности:По умолчанию в SNMP не предусмотрено ограничение по запросам от мастера к клиенту. Это значит, что community string (SNMPv1, SNMPv2), логин, пароль и ключ шифрования (SNMPv3) можно подобратьВ рамках SNMP можно получить самую разнообразную информацию — о состоянии подсистем устройств, системных пользователях, об установленном ПО и открытых портах и другом.Например, на сайтах производителей или систем мониторинга можно найти списки с описанием устройств, доступных к запросу и передаче данных по SNMP.В зависимости от конкретного решения можно изменять параметры устройств (например, IP-адреса на сетевых интерфейсах), сбрасывать пароли пользователей до дефолтных значений, перезагружать и выключать устройства.Сам по себе агент SNMP — это такая же служба (приложение), которая может содержать уязвимости. На сайте Mitre можно увидеть количество зарегистрированных и подтвержденных уязвимостей для протоколов SNMP разных версий. Тот же CVE-2022-20924 позволяет перезагружать устройства, а уязвимость CVE-2022-45315 — исполнять произвольный код на устройствах MikroTik c прошивками определенных версий.Соберем следующий стенд для демонстрации проблема безопасности:SNMP-агенты устройств — Router, Server, UPS — будем эмулировать с помощью решения Verax SNMP Simulator. Как видим, на схеме есть несколько различных устройств в одной локальной сети:Как было сказано ранее, по умолчанию SNMP-агент не ограничивает количество обращений и позволяет перебирать community string в версиях SNMPv1-v2 и логин-пароль в SNMPv3. Проверим это на практике.Будем использовать patator с модулем snmp_login для подбора community string для SNMPv2, заранее подготовив файл community со словарем для перебора:В результате получим вывод:Обратите внимание: за 45 секунд patator перебрал 118 слов, с каждым из них в качестве community string обратился к цели и для двух получил значения с public и private. Зная их, мы можем взаимодействовать с SNMP-агентом, получая и отправляя данные. Для SNMPv1 и SNMPv2 знания community string достаточно для аутентификации на агенте.Некоторые SNMP-агенты позволяют задавать access-list и указывать IP, с которых есть доступ к агенту — на запросы с таких адресов он будет отвечать. Это опасно, потому что SNMP работает по UDP и можно использовать spoofing — подмену адреса отправителя. Рассмотрим две ситуации.На агенте SNMP задана дефолтная community string и разрешено менять некоторые параметры через команду SET. С хоста 192.168.100.10 с помощью утилиты snmpwalk поменяем значение одного из интерфейсов UPS на агенте.Меняем значение параметра:Запросим текущее значение:Как видно, значение успешно изменено. Переходим ко второму сценарию.На агенте SNMP задана дефолтная community string, разрешено менять некоторые параметры через команду SET, но теперь на стороне агента включен ACL, а в white list добавлен адрес NMS 192.168.100.10.Для выполнения действий из прошлого сценарию необходимо узнать адрес NMS и подставить его в пакетах при обращении с 192.168.100.5. Способов (в случае локальной сети) может быть несколько — от скана портов, перехвата и анализа трафика до социальной инженерии. В случае с публичными IP-адресами дело обстоит иначе: сканирование не даст результата, если заранее неизвестен диапазон белых адресов и NMS не опубликован на белом IP.Рассмотрим ситуацию, когда нам известен адрес NMS.Зная NMS-адрес в локальной сети, можно указать его на интерфейсе или сформировать UDP-datagram и отправить с помощью инструментов для IP-spoofing, указав в src-ip адрес NMS.Запросим текущее значение с NMS:Как видно, значение успешно изменено. Таким образом, достаточно знать SNMP-community, чтобы аутентифицироваться на агенте и изменить значение.В случае, если SNMP-агент и NMS находятся не в одной сети, трафик проходит маршрутизаторы, FW, прокси (при наличии) и другие узлы. На каждом из устройств может быть включено логирование трафика. По аналогии с передачей паролей по HTTP в SNMPv1 и SNMPv2, значение community string может быть перехвачено. Рассмотрим схему, где есть NMS, router и SNMP-агент:NMS опрашивает агента по SNMPv2c и отправляет значение community string «SecretCommunityString»:На роутере включено логирование всех пакетов. В итоге видим следующий результат перехвата трафика:Как видим, community string передалось открытом виде. Зная его значение, IP-адреса NMS и SNMP-агента, с последним можно взаимодействовать.В случае с SNMPv3 ситуация другая. Отправим запрос агенту по протоколу SNMPv3:Видно, что в перехваченных дампах нет аутетификатора и пароля шифрования в открытом виде, потому что передается хэш. А приватные ключи прописываются непосредственно на NMS и SNMP-агенте до начала передачи информации. Единственное, что передается в открытом виде — это логин пользователя:В заголовках SNMPv3 видим, что пользователь SNMP в открытом виде. Он будет использован на стороне агента фактически для авторизации. Зная только имя пользователя, мы не сможем аутентифицироваться на SNMP-агенте, соответственно, не сможем получить доступ к SNMP-агенту и придется брутить пароль.Давайте разберемся, как не допустить рассмотренных ситуаций и обезопасить свои устройства. Я постарался выделить основные рекомендации.Необходимо планировать сети так, чтобы сервисные и технологические хосты — в том числе SNMP-агенты — были вынесены в отдельные сети. Так, чтобы к ним не было доступа из гостевых и пользовательских WiFi, сетей с данными и другого.Если оборудование и NMS поддерживают SNMPv3, то стоит отдать предпочтение последней версии.Относитесь к community string как к паролю — беспокойтесь о её сложности, если используете SNMPv1, SNMPv2 и длинные наборы символов в качестве паролей и ключей шифрования для SNMPv3.В рамках межсетевого взаимодействия со спуфингом подойдут роутер или firewall. Используйте межсетевые экраны , разрешайте SNMP только в локальных сетях или в VPN-туннелях. При публикации SNMP-агента в интернет, настраивайте фильтрацию по source IP-адресу, меняйте стандартные порты, включайте SNMPv3. А также устанавливайте сложные community string, если используете SNMPv2.При включении SNMP-агентов определите список параметров (OID), которые отдает агент. По возможности отключите все остальные OIDs.Если нет необходимости изменять настройки устройств при помощи SNMP, отключите режим записи и оставьте SNMP-агента в режиме read only.Необходимо четко понимать, оборудование каких вендоров используется в вашей инфраструктуре, и отслеживать информацию об уязвимостях в прошивках устройств. Делать это можно как на ресурсах вендоров, так и в базах данных уязвимостей."'https://habrastorage.org/webt/wk/7h/gz/wk7hgzw_88lekxy_k7gbuk7_mks.png'"['https://habrastorage.org/getpro/habr/company/66a/f7d/039/66af7d03979b6d18654293d8f1e72837.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/webt/wk/7h/gz/wk7hgzw_88lekxy_k7gbuk7_mks.png', 'https://habrastorage.org/r/w1560/webt/xe/xh/k1/xexhk1f6fq-larj5ku3uq9tsfum.png', 'https://habrastorage.org/webt/wk/7h/gz/wk7hgzw_88lekxy_k7gbuk7_mks.png', 'https://habrastorage.org/r/w780q1/webt/vn/bd/tg/vnbdtg5fb_ywzr93payoasfuezi.jpeg', 'https://habrastorage.org/r/w780q1/webt/2f/sh/z1/2fshz1cvtxsrprc8s91idqwi1co.jpeg']"
3'716846'Проверки защиты персональных данных ФСТЭК: как это происходит на практике'В прошлом году мы писали гайд по подготовке к прохождению проверок защиты персональных данных со стороны разных регуляторов. В одном из комментариев один из хабравчан ( Vadiara50 это про тебя)...'https://habr.com/ru/post/716846/'"В прошлом году мы писали гайд по подготовке к прохождению проверок защиты персональных данных со стороны разных регуляторов. В одном из комментариев один из хабравчан (Vadiara50 это про тебя) заинтересовался тем, как происходят реальные проверки. Я обратил внимание на этот комментарий и решил рассказать о своем опыте прохождения проверки ФСТЭК в одном из госорганов. Поделюсь нюансами и тем, на какие моменты нужно обращать внимание, если регулятор заинтересуется вашей компанией.

В чем заключалась моя ФСТЭК-проверка

До того, как устроиться специалистом по защите персональных данных в «Бастион» я работал в отделе по защите ПДн в структуре министерства одного из регионов. На тот момент ФСТЭК проверяла целый субъект РФ, и под список проверяемых организаций попали многие — по линиям персональных данных (ПДн) и государственной тайны (ГТ). Мое подразделение оказывало госуслуги в области Гостехнадзора — это похоже на работу ГИБДД, только в сельском хозяйстве: регистрация самоходных машин, прием экзаменов и выдача прав на управление.

К госорганам, требований даже больше, чем к коммерческим компаниям, что, конечно, пугало. В частности, проблема в том, что у госорганов есть государственная информационная система (ГИС), в которой надо обязательно согласовывать модель угроз со ФСТЭК.

Проверка была плановая. Для нее выделили куратора по региону, а компаниям дали чуть больше года на подготовку. Непрохождение проверки в нашем случае грозило административной ответственностью.

К нам едет ревизор! Что нужно сделать в первую очередь?

Во-первых: не паниковать. Люди зачастую волнуются и боятся больше, чем стоит — отсюда ошибки. А в госорганах «любят» пугать, поэтому многие наши сотрудники боялись. Я — нет, но не потому, что супер-герой, а потому что подготовился.

Отсюда во-вторых: подготовиться самим и подготовить место. После объявления о начале подготовки к проверке я пошел на курсы повышения квалификации в области персональных данных. Они дают +100 к спокойствию, если вы будете заниматься всем этим сами. На сайте той же ФСТЭК есть список лицензированных учебных заведений, среди которых можно выбрать подходящее.

Обучение в среднем длится недели 2 по вечерам. Но лучше, конечно, иметь профильное образование. При выборе учебных программ можно ориентироваться, например на недавно утвержденный профстандарт «Специалист по информационной безопасности в кредитно-финансовой сфере», вступающий в силу с сентября.

Непосредственно перед самой проверкой я подготовил место для встречи проверяющих. Лучше, чтобы это был отдельный кабинет с коньяком и конфетами. Главное, чтобы там лежал комплект необходимых документов. В нашем случае он был подготовлен на базе независимого аудита. Я проводил его силами сторонней частной компании, поскольку считаю, что именно такая проверка будет более объективной.

Как обычно происходят проверки у ФСТЭК

Как верно отметили коллеги в прошлой статье, есть два варианта: когда проверяющий — молодой специалист, и когда уже опытный. Молодой может досконально проверять все подряд, а вот опытный, загруженный работой инспектор выберет самые показательные (а иногда и каверзные) моменты, но вряд ли будет закапываться в детали.

В нашем случае проверкой занимался инспектор из второй категории. Мы поняли это, когда показывали эталонное рабочее место сотрудника, где были установлены все нужные защитные системы. Далеко не все рабочие места были в таком образцовом состоянии, но, смотреть дальше он не стал.

Как правило, регуляторы общаются друг с другом и хорошо понимают, у какой компании что надо проверять, особенно, если проверки идут одна за другой. И, как правило, повод поставить вас в план проверок известен, часто он общий у многих проверяемых. Планы регуляторов — это официальные открытые региональные документы. Можно посмотреть их, а затем попробовать связаться с компаниями (их безопасниками, юристами, кадровиками), прошедшими проверку, и поинтересоваться, на что инспекторы обращают повышенное внимание в этом году.

Обычно ФСТЭК обращает больше внимания на реализацию информационных систем персональных данных: какие ИСПДн используются в организации, как они защищены и документированы. В том числе:

Какой уровень защищенности определен для ИСПДн?

Какое моделирование угроз проведено?

Какие реализованы меры по предотвращению угроз?

Проводилась ли оценка эффективности этих мер?

Какие СЗИ установлены? Порядок их эксплуатации и учета.

Цели проверки: в теории — дать понимание, что вас в принципе могут проверить; если это простой запрос комплекта документов, как делает Роскомнадзор, то им нужно понимать, стоит ли вас включить в план проверки; на практике же — они хотят проверить соблюдение требований по защите информации.

Лайфхаки для подготовки

Мой главный секрет — это коммуникация. Проверяющие — тоже люди, и надо просто найти с ними общий язык. Я рекомендую не стесняться, а общаться с позиции эксперта, разговаривать с проверяющими, так сказать, в их информационном поле.

Самое сложное, с чем мы столкнулись в процессе подготовки — модель угроз и частное техническое задание (ЧТЗ). Составление таких документов обязательно, если имеется ГИС. Они требуют согласования со ФСТЭК и это означает, что будут долгие переписки с кучей замечаний. К этому надо быть готовыми.

Есть и такие аспекты подготовки, которыми можно пренебречь на практике. Тут главное — правильно расставить приоритеты. Например, если мало времени, то допустимо оставить без внимание то, что легко исправить в процессе проверки. Как правило, инспекторы дают такую возможность. Похоже даже они не хотят писать громоздкие отчеты с описанием мелких, незначительных нарушений.

В случае массовых, плановых проверок у вас будет достаточно много времени на их устранение, по крайней мере, если вы заранее понимаете, где ваши слабые места. Так, я получил акт с нарушениями спустя 3 месяца. Немного проактивности и к этому моменту у вас уже будет все хорошо.

Подтвердить устранение нарушений легко: вы просто составляете соответствующее письмо и отправляете его от организации во ФСТЭК. В нашем случае этого хватило, но проверяющие не всегда верят на слово, так что рекомендую не лукавить. Лучше действительно все исправить.

Стоит регулярно проводить постоянно инструктаж с коллегами, непосредственно ведущими обработку ПДн.

Законодательство о проверках меняется очень часто, буквально ежеквартально. Поэтому есть смысл его мониторить. Советую безопаснику тратить примерно 300 часов в год на изучение законодательства и закладывать это время в годовой план. Обязательно посещать сайты регуляторов, читать профильные материалы, пользоваться консультациями той же ФСТЭК, они их охотно дают.

Аккуратность и собранность я тоже отнесу к лайфхакам. Когда вы знаете, где лежат нужные бумаги и достаете их сразу, как только их попросят, а не ищете три часа, к вам сразу как то лучше относятся. Пусть будет видно, что вы реально готовились: все аккуратно прошито, пронумеровано и разложено по полочкам.

Главный же лайфхак в общении с проверяющими: доброжелательность и чай. И постараться не волноваться. Но вообще, обязательно нужно ответственно подойти к проверке, не допускать работы «спустя рукава».

Как проходила проверка у нас и какие проблемы нашла ФСТЭК

Проверка состояла из следующих этапов:

представление; проверка должностных регламентов (чтобы им понимать, с кем общаться); техническая проверка по ГТ; бумажная безопасность по ПДн.

От ФСТЭК приехало четыре человека. Сотрудники вели себя крайне культурно, общались легко и первым же делом направились к руководителю и попросили принести документы.

Далее они пошли в отдел кадров, чтобы проверить должностные регламенты специалиста, ответственного за организацию обработки персональных данных и безопасника. Последнего могут еще проверить на соответствие стандартам. У безопасника сегодня должно быть профильное образование или профпереподготовка не менее 512 часов (так что, повторю: идите учиться), при этом не должно быть лишних обязанностей, например, системного администратора, как часто бывает. Оно и логично: безопасник проверяет сисадмина.

Начиная примерно с 2020 года ситуация такая: если безопасник, ответственный за проверку, не соответствует должностным регламентам, проверяющие с ним не будут общаться. Разговор продолжится с руководителем, а он может не все знать. В результате проблемы возникают на пустом месте.

Напомню, у меня проверяли два направления: ГТ и ПДн. Так как ГТ проверяло еще и ФСБ, ее ФСТЭК проверила первым делом. Их интересовали технические вопросы и сетевой экран. Это был первый этап, после которого они ушли.

Вернулись они через день, чтобы проверить линию ПДн. Чаще всего, проверяющие загружены и могут отобрать для проверки только какую-то часть направления. В моем случае это была бумажная безопасность. Я предоставил только комплект документов, которые приготовил заранее.

Проверка длилась примерно 3 часа. Резюмируя, можно сказать, что в первую очередь это была проверка правильного распределения и назначений ответственных. Что касается документов, то проверяли наличие «самых толстых» папок, типа модели угроз.

Проблемы, которые у нас нашли

В основном проблемы были с организационно-распорядительными документами (ОРД). Они не были актуализированы по причине человеческого фактора. Честно говоря, я забыл их актуализировать. Также не на всех рабочих местах, где происходила обработка персональных данных были установлены сертифицированные ФСТЭК средства защиты от несанкционированного доступа (НСД).

ФСТЭК сообщает о проблемах не сразу. При мне представители службы ничего не говорили, а предложили исправления позже, в письменном виде и через куратора. Это был отчет в виде перечислений нарушений с вежливой просьбой их исправить. Я был согласен с найденными проблемами, так как они действительно были и ничего не обжаловал. А вообще-то можно и обжаловать — такая процедура предусмотрена законом.

Обжалование может быть основано как на несогласии с указанными нарушениями, так и на неправомерных действиях проверяющих (не были предоставлены документы, предписывающие проверку или процесс длился дольше, чем это регламентировано и т. д). Такие формальные нарушения в регламенте, в теории могут спасти от негативных результатов проверки даже в безнадежных случаях, но это средство последней надежды. Чтобы разыграть эту карту, нужно очень хорошо знать, что именно представители ФСТЭК должны и не должны делать.

Вы спросите, можно ли пройти такую проверку вообще без замечаний со стороны государственных органов? Я думаю нет. Во-первых, идеально тут все равно не подготовиться, и это в некотором роде снижает градус тревожности, однако не отменяет серьезного отношения к подготовке. А во-вторых, система так устроена, что проверяющим нужно что-то найти. Да-да. Как однажды мне сказал один профессор: «Законодательство написано так, чтобы было место для маневра — как со стороны проверяющих, так и со стороны проверяемого. Каждый понимает это по-своему, а с проверяющими лучше сильно не спорить».

Какие ошибки мы допустили и что сделали бы иначе

Особенных ошибок у нас не было. Единственное — это некоторые неактуализированные ОРД и небольшая хитрость с тем эталонным удаленным рабочим местом, которое мы выдали за типовое.

Что я сделал бы иначе, проходи я такую проверку снова? Воспользовался бы аутсорсингом — это экономит время. На подготовку уходит очень много времени, а если не готовиться, то можно ее не пройти и потратить еще больше на исправление найденных проблем. Оптимизировать подготовку к проверкам можно, обратившись к профессиональной компании либо к опытным коллегам из своей или из другой организации.

И в качестве заключения дам совет о том, что нужно делать компании, чтобы проверка прошла безболезненно. Я считаю, что важно вкладывать деньги в защиту информации и относится к данному направлению серьезно. Если же таким подходом пренебречь, последствия могут быть плачевные: от удара по репутации при утечках информации до постоянно растущих штрафов, в том числе и персональных. Также безопаснику сегодня важно быть профпригодным. Если руководитель может отнестись к этому вопросу лояльно, то ФСТЭК — нет. Времена изменились."'https://habrastorage.org/webt/2l/ho/cp/2lhocp7nmvdpvbffj8gtrcrpmio.jpeg'"['https://habrastorage.org/r/w1560/webt/sj/yw/lm/sjywlmelvolii_s8txuln4cbam4.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w32/getpro/habr/avatars/511/cdd/47c/511cdd47c9120e1e2cdc305229325032.jpg', 'https://habrastorage.org/r/w1560/webt/ud/pv/jk/udpvjkuzdxamwo0phgfs8uo0dzc.png', 'https://habrastorage.org/getpro/habr/avatars/511/cdd/47c/511cdd47c9120e1e2cdc305229325032.jpg', 'https://habrastorage.org/webt/2l/ho/cp/2lhocp7nmvdpvbffj8gtrcrpmio.jpeg', 'https://habrastorage.org/getpro/habr/company/1f6/b14/514/1f6b14514c21b431a87f14cd869feba5.jpg', 'https://habrastorage.org/r/w780q1/webt/2l/ho/cp/2lhocp7nmvdpvbffj8gtrcrpmio.jpeg']"
4'719486'SLES 15 и невозможность загрузки ядра Xen'Пришлось столкнуться с забавной ошибкой, по которой сходу не удалось найти никакой информации в интернете. Проблема по первичным признакам такая. Грузится SUSE Linux Enterprise Server 15, доходит до...'https://habr.com/ru/post/719486/'"Пришлось столкнуться с забавной ошибкой, по которой сходу не удалось найти никакой информации в интернете.

Проблема по первичным признакам такая. Грузится SUSE Linux Enterprise Server 15, доходит до меню загрузки GRUB. Далее, если выбрать обычное ядро, всё нормально, а если выбрать ядро для гипервизора Xen, то экран моргает и мы опять возвращаемся в меню. Запустить Xen невозможно никак.

Долгие упражнения с настройками GRUB и параметрами загрузки ядра ничего не дали (а надо отметить, что инициализация сервера при загрузке – это неспешный процесс, поэтому процесс затягивается надолго). Наконец, возникла ведущая к победе мысль – заснять процесс загрузки на смартфон в ускоренном режиме!

После нескольких попыток удалось получить вот такой кадр:

Это изображение держится на экране в самом удачном случае доли секунды.

Дальше уже делом техники было найти описание проблемы на форуме поддержки Lenovo, которое заключается в следующем.

Загрузчик EFI ядра Xen написан весьма вольно, и грузит ядро одной физической командой чтения. До версии SLES 15 SP2 размер ядра составлял чуть менее 16 мегабайт, начиная с SP3 – увеличился до чуть более 16 мегабайт. У ряда контроллеров и дисков размер буфера чтения ограничен как раз величиной 16 мегабайт. Как следствие, загрузка Xen в режиме EFI с недостаточно продвинутого контроллера или диска приводит к ошибке чтения и мгновенному возврату обратно в меню.

Для того, чтобы справиться с проблемой, предлагается воспользоваться одним из следующих решений:

a) Дождаться, пока Xen community исправит ошибку, интегрировав предложения Lenovo/IBM в свой код (пока с версии 15SP3 ничего не произошло, сейчас на дворе 15SP5).

б) Скачать исходники ядра Xen и перекомпилировать с патчем, предложенным на упомянутой выше странице поддержки, где файл читается порциями по 1 мегабайту. Делать так каждый раз после обновления загрузчика (не проверял, но должно работать).

в) Выполнять загрузку сервера не в режиме EFI, а в режиме Legacy (это работает).

Очень поучительная история."'https://habr.com/share/publication/719486/9177cf53bfecb64289c957da5a27ab97/'"['https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/c66/06b/e3f/c6606be3f5e0470d55a221c329be5a93.jpg', 'https://habr.com/share/publication/719486/9177cf53bfecb64289c957da5a27ab97/']"
5'719478'Учимся правильно спать'Если вам кажется, что сон - не самое важное для продуктивной работы в течение дня (и даже недели), поздравляю, значит у вас нет проблем с недосыпанием. Всех остальных приглашаю к прочтению. Зачем?...'https://habr.com/ru/post/719478/'"Если вам кажется, что сон - не самое важное для продуктивной работы в течение дня (и даже недели), поздравляю, значит у вас нет проблем с недосыпанием. Всех остальных приглашаю к прочтению.

Зачем?

Немого фактов:

Лишение человека возможности спать признана ООН одной из самых жестоких пыток

Во сне в организме происходит интенсивная выработка важных гормонов, таких как мелатонин и соматотропин

Также во время сна происходит “перезагрузка” мозга, полученная в течение дня информация “раскладывается по полочкам”, выстраиваются новые нейронные связи, из мозга выводятся токсины, образованные в ходе обменных процессов.

Сон нам жизненно необходим. Однако, люди - первые животные, которые научились сознательно недосыпать.

Ещё одну ложку дёгтя добавляют общественные устои и расписания.

Как получилось, что расписание этого мира составили жаворонки? Они сделали это, пока мы спали…

Выход - научиться эффективно спать (ну или стать миллиардером).

Перед сном

Техники, описанные ниже, я по крупицам собрал во многих источниках, опробовал на себе и оставил то, что мне подходит лучше всего. Поскольку каждый человек сугубо индивидуален, вам не нужно смотреть на них, как на точный алгоритм.

Кодекс - это всего лишь свод указаний, а не жёсткий свод законов (Пираты Карибского моря)

Подготовительная часть включает в себя действия, направленные на формирование оптимальных внутренних (гормональный и психологический фон) и внешних условий для здорового сна.

Долой гаджеты и синий свет

Не ранее, чем за 2 часа до сна постарайтесь отказаться от заглядывания в смартфон, просмотра телевизора и зависания в компьютере. Да, я уже вижу, как тысячи помидоров полетели в мою сторону.

Также, если есть возможность использовать для освещения в доме лампы и светильники с тёплым, желтоватым светом, вместо белого, обязательно ею воспользуйтесь.

Если же вы не можете обойтись без использования гаджетов и ПК, настройте на их дисплеях режим уменьшения синего света.

Дело в эволюции. Днём небо синего цвета - организм бодрствует. К закату свет приобретает тёплые желто-красные оттенки - организм начинает вырабатывать мелатонин и готовиться ко сну. И когда вы читаете 1001-ю статью или отвечаете в чатах на сообщения, глаз человека фиксирует синий свет (вспоминаем RGB-модель: белый на 33% состоит из синего), выработка мелатонина приостанавливается, и заснуть вашему организму будет гораздо сложнее.

Остыньте

Во сне температура тела понижается. Мы можем помочь организму в этом.

Примите прохладный душ. В меру, не ледяной. Да, многим нравится распариться в ванной на ночь, но поверьте, эти ощущения зачастую обманчивы, и после такой пропарки бывает трудно заснуть

Проветрите спальню. Оптимальная температура для сна - +18..+22 °C. Лучше накрыться одеялом и высунуть ножку, чем лежать раскрытым, но изнывать от жары. А насыщение комнаты кислородом благотворно повлияет на обменные процессы в организме во время сна

Не забудьте про туалет

Банально, но на вопрос “сходить сейчас или попозже?” ответ один - сейчас. Вариант “попозже” - это всего лишь отсрочка неизбежного.

Настройтесь на позитив

Если время позднее, а вставать предстоит рано, не нужно корить себя, нервничать и переживать, что мало осталось поспать. Вместо этого, попытайтесь внушить себе: “Я так классно высплюсь за эти 4 часа! Я проснусь свежим, бодрым и отдохнувшим!”

Дело в том, что в состоянии стресса и нервного возбуждения очень непросто заснуть, и вот вы лежите, смторите в потолок и продолжаете себя ругать, только теперь уже за то, что не можете погрузиться в сон.

Для себя я вычислил, что именно в этом случае самовнушение работает очень хорошо!

Укладывайтесь правильно

На одном вебинаре на РБК-pro нашёл один хороший способ улечься в постели, чтобы сон был лучше. Знаю, звучит бредово, но в моём случае это работает. Попробуйте, быть может, вам эта техника тоже подойдёт.

Для лучшего понимания описанного ниже раскрою принцип: представьте, что ваш позвоночник - это небольшой канат. Нижняя часть привязана к земле (копчик), и вам нужно максимально аккуратно уложить его на кровать.

Итак…

Сядьте на кровать в таком положении, как будто вы только что лежали на ней прямо и подняли корпус, то есть, ноги лежат на кровати перед вами, подушка лежит сзади. Переместитесь вперёд сантиметров на 10. Положение должно быть примерно такое, что если вы ляжете, то на подушке окажется только макушка (но ложиться пока не надо).

Теперь упритесь руками в кровать и дайте позвоночнику слегка провиснуть. Из этого положения начинайте медленно с небольшой амплитудой двигать корпусом из стороны в сторону, как будто “вылезаете из люка”. При этом ноги и пятая точка должны оставаться на месте. Одновременно начинайте понемногу пятиться руками назад.

Подобными движениями вы должны как бы “укладывать” на поверхность кровати каждый отдельный позвонок.

Через несколько таких движений, когда руки уйдут достаточно далеко назад, поставьте их на локти и продолжайте те же движения, укладывая теперь позвонки грудного отдела.

Когда и локти уйдут далеко - грудной отдел позвоночника будет “уложен”. В этот момент отпустите руки и лягте.

Теперь нужно уложить шейный отдел. Сделайте это, поддерживая одной рукой голову.

Повторите такое “укладывание” 2-3 раза, почувствуйте, как позвоночник слегка вытянулся и расслабился.

Знаю, текстом сложно объяснить этот процесс. Однако, подобное упражнение я проверил на себе, и после него я сплю гораздо лучше.

Заключение

Повторюсь, все вышеперечисленные техники - это лишь те, которые помогают мне быстрее засыпать и лучше высыпаться, отфильтрованные моим личным опытом. Возможно, некоторые из них вам подойдут, а некоторые нет, в любом случае нужно пробовать всё на себе и оставлять то, что работает.

Буду рад, если что-то из описанного поможет кому-то, а также если вы поделитесь своими методами лёгкого засыпания.

В следующих публикациях расскажу про свои утренние ритуалы лёгкого пробуждения."'https://habrastorage.org/getpro/habr/upload_files/2c4/b65/2f0/2c4b652f025470d2465632b0b5f63524.jpg'"['https://habrastorage.org/getpro/habr/upload_files/2c4/b65/2f0/2c4b652f025470d2465632b0b5f63524.jpg', 'https://habrastorage.org/r/w32/getpro/habr/avatars/dae/f41/0d9/daef410d9401eb6010e80a3bec59ac40.jpg', 'https://habrastorage.org/getpro/habr/avatars/dae/f41/0d9/daef410d9401eb6010e80a3bec59ac40.jpg', 'https://mc.yandex.ru/watch/24049213']"
6'719468'Кофеиновая трилогия. Часть 3. Как не перепить и топ ошибочных мифов о вреде кофеина'Хрупкие кости, снижение либидо и зависимость похлеще, чем от кокаина. При этом, в комментариях под любой схожей статьей присутствует едва ли не Иисус, который превозносит чистоту и прелесть своей...'https://habr.com/ru/post/719468/'"Хрупкие кости, снижение либидо и зависимость похлеще, чем от кокаина. При этом, в комментариях под любой схожей статьей присутствует едва ли не Иисус, который превозносит чистоту и прелесть своей жизни после отказа от кофе. Есть ли смысл отказываться от кофеина, и в чем действительно риски его потребления?

На связи сообщество биохакеров RISE. Писать про кофе сложно, так как он проходит гематоэнцефалический барьер , комплексно воздействует на организм, работает с ЦНС и сосудами. Все это вместе открывает широкое поле для спекуляций. Первый материал рассказал про общие эффекты от употребления кофе . Второй сосредоточен на специфике потребления . Пришла пора взяться за мифы и легенды о черном напитке.

Кофе: наркотик или нет?

Нет, кофе не наркотик. Он не вызывает физиологическую зависимость и не вынуждает пить кофе только для того, чтобы снять симптомы его дефицита. Есть примеры кофеиновой мигрени, но они свидетельствуют о чрезмерном употреблении черного напитка. Как писал в прошлом материале , оптимальная дозировка: 1-3 мг кофеина на 1 кг веса. А то, что называют наркотической кофеиновой зависимостью — проблема в неумении увидеть разницу между толерантностью и адаптивностью человека к кофеину.

Толерантность, предрасположенность, адаптация. В чем между ними разница, и почему она так важна?

В контексте потребления кофе есть три отдельных фактора, которые индивидуальныдля каждого человека. Их определяет совокупность генетического наследия, социальной среды, и даже личных убеждений. Чаще всего, атрибуты этих факторов специально путают друг с другом, чтобы демонизировать кофе, или придать ему Божественного Эффекта. На практике всё немного проще.

Толерантность к кофе. Буквально означает, что организм человека перестает ощущать бодрость и вдохновение. Из-за этого, якобы, потребителю кофе придется постоянно повышать дозировку, чтобы получать тот же эффект. Вот только период выведения кофе из организма 8 часов. И 1-2 кружки в первой половине дня будут ощущаться так же бодро и на следующий день, и через неделю. Толерантность к кофе есть, но она и близко не такая сильная, как её стараются преподнести сторонники чистоты. Можно попробовать воздержаться от кофе на 3-5 дней. Эффект новой кружки будет достаточно сильным. Но он уже связан с адаптацией к кофе.

Адаптация к кофе. Сколько вам нужно выпить кофе, чтобы почувствовать его эффект? Кому-то достаточно капучино в 11 утра, чтобы бодрячком доработать до 6-ти вечера. А кто-то фигачит порцию эспрессо каждые 2 часа с момента пробуждения и до отбоя. Адаптация завязана как на толерантности, и связана с частотой потребления кофе, так и на личной предрасположенности.

Личная предрасположенность. Тот самый бэкграунд генетики, состояния ЦНС, образа жизни, съеденной пищи, возбужденности до того, как вы пили кофе и личного чувства тревоги. В этом материале речь шла о том , что кофе не стимулятор, а подкреплятор. Он усиливает то чувство, которое уже сейчас испытывает организм.

Эти три фактора характеризуют отношение конкретного человека к кофе. С учетом того, сколько он пьет кружек, сколько потребляет миллиграмм, какой у него организм и т.д. Само собой, если насильно пить по 5 кружек в день, ища ответ на вопрос как сохранить работоспособность , то повысишь только прибыль брендов кофе. Но, если вы держитесь своей оптимальной дозировки 1-3 мг на 1 кг веса, чувствуете эффект бодрости и вам это нравится, то ни о какой зависимости речь точно не идет.

Оптимальный ритуал потребления кофе

Наш организм развивается по принципу: выбери успешный шаблон поведения, и придерживайся его. Разные коучи и гуру успеха говорят о том, что нужно ходить разными дорогами на работу, бриться разными руками, пробовать что-то новое. Но есть и другая сторона. В материале про рост продуктивности предлагается простая концепция:

Автоматизируй все, что можешь. Переведи базовые потребности в рутину, дай организму стабильную основу, а в личном развитии креативь так, как душе угодно.

Это важно для потребления кофе, так как выработав свою систему ритуалов и рецепт идеального напитка, вам будет проще следить за уровнем своей продуктивности. Оптимальный рецепт выглядит так:

Если вы любите кофе в кофейнях, не стесняйтесь, спрашивайте баристу о том, какую порцию закладывают в кофемашину, что это за сорт, арабика или робуста. Это позволит для начала понять, сколько мг кофе вы уже сейчас потребляете. Можно ли увеличить дозировку, или стоит уже уменьшать.Если вы берете большой американо, особенно в стаканах под американский стиль — огромных таких, на 450 мл, то в них может быть 1000 мг кофе, что оптимально для человека весом в 300 кг!

Если готовите кофе дома, то почитайте больше о том, как проходит этот процесс. Сколько выделяется кофеина на вашу кружку. Как можно увеличить или сократить этот объем.

Пейте кофе спустя 2 часа после пробуждения. В противном случае, уже в 2-3 часа дня будете клевать носом. А выпитый кофе, даже за 8 часов до отбоя, все равно будет оказывать незначительное влияние на характер сна.

Утро оптимально начинать с легкой прохлады и солнечного света. Хотя бы на 5 минут. Если нет солнца, то 15-30. Особенно здорово собачникам, хочешь, не хочешь, а кортизол повышаешь. При чем кофе к утреннему подъему? Выпитый кофе рано утром не дает аденозину снизиться, и поэтому днем-вечером мозг тупит, а ты немного вялый. Отложи кофе на 2 часа с момента пробуждения и жизнь заиграет новыми красками.

Пьешь кофе — загрузись водичкой и электролитами. Особенно здорово, если есть бутылка минералочки. Один стакан до или после чашечки кофе, это просто топ! Поможет уберечь организм от перепада в балансе солей.

Мой личный рецепт: френч пресс на 150 мл, в нем 50 мг кофеина. Завариваю в 11:00 и в 14:00. Если день сложный, есть дедлайны и нужно поработать вечером, то добавляю еще в 19:00. Бывало и такое, что пил по 2 френч-пресса по 800 мл в день, По 100 мг кофеина на каждый. Но это опять очень «нежная» дозировка.

Последствия злоупотребления кофе, и как от них избавиться

https://www.youtube.com/watch?app=desktop&v=IhejOr-xxa4

Кофе истощает нервную систему, вызывает тревожность, панику, тремор… Все это симптомы того, что доза была слишком большой. Опять же, силу действия кофе можно снизить, если использовать даже молоко. Меньше кофе впитается в ЖКТ, да и вкус будет более нежным. Но для тех, кто не хочет идти на компромиссы есть отдельное средство!

L-теанин, и что делать, когда перепил кофе?

Это вечная связка на всех энергетических напитках, предтренировочных комплексах и некоторых сортах кофе. В чем-то это даже маркетинговый ход, так как L-теанин помогает проглотить больше кофе без побочного эффекта, а значит компания продаст большее количество драгоценного напитка. Вообще использовать L-теанин для снижения побочек кофе я не рекомендую, куда эффективнее определить свою дозировку и её придерживаться.

L-теанин очень схож с глутаматом и работает с теми же рецепторами, проходя через ГЭБ. Но, вот это достаточно крупное и комплексное исследование , показывает, что при попадании L-теанина в мозг, количество внеклеточного глутамата падает, а синтез ГАМК наоборот растет. То есть, L-теанин успокаивает ЦНС, и не дает мозгу перевозбудиться от кофеина.

Оптимальная доза L-теанина, которая убережет от кофейного перевозбуждения: 200-400 мг, однако я бы рекомендовал начать со 100-200 мг. При этом его можно принимать просто как пищевую добавку, наблюдая за результатами.

Если вы уже перепили кофе, то вам может помочь:

2-3 щепотки соли и запить их пол стаканом воды. Повторить процедуру через 15-20 минут. Если пить только воду, то тремор может усилиться, а с ним и рост тревоги.

Если дома есть капсула магния, речь о пищевой добавке, то она отлично дополнит соль. Но помните про пол стакана воды.

Сок лимона, в совокупности и перечисленными выше элементами, также поможет снять симптомы злоупотребления кофе.

Если есть возможность купить минеральную водичку, в частности Боржоми или аналоги, то это будет лучшим решением. Причем эти же рекомендации могут помочь при борьбе со стрессом и тревожностью .

L-теанин, как и приведенные методы, важны только в том случае, когда речь идет о переизбытке кофе, его чрезмерном воспитии и выходе за рамки возможностей организма. Во всех остальных случаях, кофе — это кофе. Хоть и сопровождаемый страшными мифами.

Популярные мифы о вреде кофеина

Тема кофе, как и других добавок, вроде Магния , окружена мифами и сомнениями. Но если от кофеина и есть побочные эффекты, то они — результат злоупотребления. А как на счет регулярного наслаждения черной жидкостью? Быть может, кофе разрушает наш организм с годами, просто делает это незаметно?

Вымывание кальция и снижение прочности костей. Кофеин действительно вымывает соли из организма, но важно то, из каких именно участков. Кофеин — диуретик, он выводит воду через почки. А с ней и все витамины и минералы, которые организм не успел получить. С другой стороны, если ваше питание сбалансировано, или вы используете мультивитаминные комплексы, опасаться нечего!

Кофе сужает сосуды сердца и головного мозга. Из-за этого мозг недополучает питательных веществ, а сердце изнашивается. На самом деле, кофе расслабляет сосуды сердца. А сужение сосудов мозга компенсируется ростом активности за счет повышенного тока крови. А также за счет того, что активно синтезируются два брата: дофамин и норадреналин.

Кофе снижает тестостерон у мужчин и эстроген у женщин. Это крайне незначительная корреляция, и связана она не с гормонами, а с белком глобулином.

Глобулин связывает половые гормоны в кровотоке, не давая им оказывать свой прямой эффект. Кофеин крайне незначительно повышает выработку глобулина. При этом, если вы используете кофеин как предтрен или пьете перед пешей прогулкой на работу, ваши половые гормоны, из-за физической активности, будут выделяться куда интенсивнее, чем глобулин.

Вреден ли кофе, как его описывают в «страшилках»?

Эспрессо под микроскопом намекает, что кофе — это золото)

Кофе — это инструмент. Иногда он действует мощно и поднимает эффективность. Иногда вызывает только тревогу и спазмы в ЖКТ. Ведь не существует идеальной таблетки для продуктивности или повышения эффективности, и все познается методом проб и ошибок.

Если в тема биохакинга интересна и хотите чаще читать подобный контент, то можете подписаться на наш паблик mind_rise в телеграме, будем рады."'https://habrastorage.org/getpro/habr/upload_files/343/3a0/378/3433a0378968787719b3a3059b551801.png'"['https://habrastorage.org/r/w1560/getpro/habr/upload_files/436/7ba/991/4367ba991c40189c3abee40ec4a71e29.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/d1e/653/ec2/d1e653ec2c8dc4da5a9bd6fc911b7e6b.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/343/3a0/378/3433a0378968787719b3a3059b551801.png', 'https://habrastorage.org/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg', 'https://habrastorage.org/getpro/habr/upload_files/343/3a0/378/3433a0378968787719b3a3059b551801.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/3c9/268/25d/3c926825d65731be4f68ca15d0a1e586.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/231/1b5/43b/2311b543b09e0678f604b72cfba6d6bc.jpg']"
7'719466'Настройка кластера K8S на 3 хостах CentOS'Друзья, привет! Как-то томным осеннем вечером взбрело мне в голову начать изучать Kubernetes. Прочитал много разных статей и литературы, и понял, что нужно приступать к опытам на живую. И для этого...'https://habr.com/ru/post/719466/'"Друзья, привет!

Как-то томным осеннем вечером взбрело мне в голову начать изучать Kubernetes. Прочитал много разных статей и литературы, и понял, что нужно приступать к опытам на живую. И для этого мне необходимо поднять кластер у себя локально на компьютере. Minikube использовать не хотел так как в реальности одноузлового кластера нигде не встретишь. Поэтому было решено развернуть его у себя локально на трех узлах с использованием VirtualBox. Но полностью рабочего гайда по настройке, без каких-либо подводных камней я так и не нашел. Поэтому пропустив через себя множество всяких статей, страницы официальной доки кубера и всякую литературу по нему, хочу поделиться с вами своим опытом настройки кластера. Не судите, пожалуйста, строго это моя первая статья и первый кластер K8S.

Настройка виртуалок

В качестве OS для наших узлов я выбрал CentOS 9. Скачиваем его с http://centos-mirror.rbc.ru/pub/centos/7.9.2009/isos/x86_64/ и выбираем минимальный образ CentOS-7-x86_64-Minimal-2009.iso

Далее настроим наши виртуальные машины (ВМ), на которых будет развернут кластер. Я буду делать это в VirtualBox версии 6.1.34 r150636 (https://www.virtualbox.org)

Создадим шаблонную ВМ с именем kube_node_template. И задаем ей 2Гб оперативы.

Дадим ему 10 ГБ места на диске.

Дадим ему 2 ядра

И установим адаптер сети

В разделе «Носители» нужно будет выбрать виртуальный привод. Здесь уже отображается файл виртуального диска, но он почти пустой, так как операционная система еще не была установлена. Поэтому для установки системы нужно будет выбрать ISO файл образа с операционной системой.

Нажмите на «Пусто», в правой части окна напротив пункта «Оптический привод» нажмите на кнопку с изображением диска, а затем в контекстном меню выберите пункт «Выбрать файл диска ». И выбираем свой скаченный iso файл CentOS-7-x86_64-Minimal-2009.iso.

Переходим к установке операционной системы и создания пользователя. Нажимаем ""Запустить"" нашу ВМ.

И выбираем Install CentOS 7

Создаем пользователей.

Задаю пароль для root и создаю пользователя kube_admin.

После того как наша ОС установится, отключим работу со swap памяти, так как K8S работу с ним не поддерживает. (Swap -это файл подкачки, механизм виртуальной памяти перемещающий отдельные фрагменты памяти из оперативной памяти на жёсткий диск, внешний накопитель, специально выделенный раздел или файл, тем самым выполняя своё предназначение и освобождая оперативную память для других активных фрагментов памяти.)

Проверим что он есть командой SUDO SWAPON -S а затем отключим его SUDO SWAPOFF -A

И сделаем так чтобы при перезагрузке системы он опять не включился. В sudo vi /etc/fstab комментируем последнюю строку

После чего для применения настроек делаем ребут системы и проверяем sudo shutdown -r now

Далее включим ethernet adapter. Для этого отредактируем файл sudo vi /etc/sysconfig/network-scripts/ifcfg-enp0s3 и включим ONBOOT=yes

Сделаем рестрат sudo shutdown -r now и проверим командой ip addr

Далее мы из нашего шаблона создадим 3 ВМ, которые будут нашими нодами кластера. Одна будет мастером и две воркер. Выбираем в VirtualBox клонировать. Указываю имя и в политике MAC-адреса выбираем сгенерировать новый MAC

Получилось 3 виртуалки

Запускаем их. Далее нам необходимо сделать статические IP для наших ВМ. Для этого нужно отредактировать файлы ifcfg-enp0s3 в каталоге sudo vi /etc/sysconfig/network-scripts/ifcfg-enp0s в ipaddr указываем нужный нам ip

Выполняем ребут сервера sudo shutdown -r now и проверим командой ip addr что IP адресс для адаптера enp0s3 изменился на указанный нами в конфиге

Делаем это на всех наших ВМ кластер, только указываем другой IPADDR.

Теперь для удобства мы можем подклюичться к нашим ВМ машинам по SSH. Я буду делать это через MobaXterm (https://mobaxterm.mobatek.net) это также можно сделать через обычную командную строку вашего компьютера. Но я привык к MOBA.

Жмем создать сессию и указываем IP адрес ВМ

Переименуем наши хосты чтобы в дальнейшем не путаться (пример для мастера). Для этого в sudo vi /etc/hostname указываем имя нашей ноды. В данном случае это master

Добавим все наши хосты в файлик /etc/hosts, чтобы можно было обращаться к нашим хостам по имени узла

Делаем ребут сервера и проверяем (Ну или можно перезапустить службу sudo systemctl restart systemd-hostnamed но нужно будет перезайти в виртуалку). Проверяем чьл поменялось имя машины с localhost на master и можно сделать пинг по имени машины например worker2

Теперь необходимо открыть следующий список TCP-портов в брандмауре firewalld. Проверить что он запущен можно с помощью sudo systemctl status firewalld.service. Проверить список открытых портов sudo firewall-cmd --list-all

На мастер ноде откроем следующие порты и перезапустим службу firewalld. Чтобы это правило действовало постоянно добавьте –permanent

sudo firewall-cmd --permanent --add-port=6443/tcp sudo firewall-cmd --permanent --add-port=2379-2380/tcp sudo firewall-cmd --permanent --add-port=10250/tcp sudo firewall-cmd --permanent --add-port=10251/tcp sudo firewall-cmd --permanent --add-port=10252/tcp sudo firewall-cmd --permanent --add-port=10255/tcp sudo firewall-cmd --permanent --add-port=8472/udp sudo firewall-cmd --add-masquerade --permanent sudo firewall-cmd --permanent --add-port=30000-32767/tcp

И рестартуем службу sudo systemctl restart firewalld

Проверяем sudo firewall-cmd --list-all

На воркерах открываем следующие и также ребутаем службу.

sudo firewall-cmd --permanent --add-port=10250/tcp sudo firewall-cmd --permanent --add-port=10255/tcp sudo firewall-cmd --permanent --add-port=8472/udp sudo firewall-cmd --permanent --add-port=30000-32767/tcp sudo firewall-cmd --add-masquerade --permanent

Отключим SELinux. Для этого в sudo vi /etc/sysconfig/selinux нужно указать disabled

Также для K8S необходимо чтобы все пакеты проходящие через сетевые мосты обрабатывались через iptables. Для этого необходимо установить переменную ядра net.bridge.bridge-nf-call-iptables=1:

sudo cat << EOF > /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables=1 EOF

И загрузим его в ядро командой sudo modprobe br_netfilter

И выполняем рестарт sudo sysctl --system

Для выкачивания пакетов из интернета нам необходимо сделать следующие настройки. В sudo vi /etc/resolv.conf добавив в него nameserver 8.8.8.8

А также в sudo vi /etc/sysconfig/network добавить NETWORKING=yes и GATEWAY=192.168.1.1

И выполняем рестарт сервера sudo shutdown -r now

Настройка master ноды

Устанавливаем containerd

sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y containerd.io sudo mkdir -p /etc/containerd containerd config default | sudo tee /etc/containerd/config.toml

Перезаупскаем службу

sudo systemctl enable containerd sudo systemctl start containerd sudo systemctl status containerd

Переходим к установке K8S

Добавим репозиторий кубера в пакетный менеджер:

sudo cat > tee /etc/yum.repos.d/kubernetes.repo << EOF [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF

Перезачитаем кэш yum sudo yum makecache fast

Переходим к настройке мастер узла:

sudo yum -y install kubelet kubeadm kubectl sudo systemctl enable kubelet.service sudo systemctl start kubelet.service sudo systemctl status kubelet.service

Ставим Flannel

Сетевой плагин Flannel настраивает сетевое взаимодействие между контейнерами.

sudo yum install wget sudo wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml grep -i network kube-flannel.yml

Далее запускаем инициализацию нашей мастер ноды с указанием подсети которую создал flannel 10.244.0.0/16

sudo kubeadm init --pod-network-cidr 10.244.0.0/16

Инициализация занимает несколько минут и результатом ее выполнения будет:

Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run ""kubectl apply -f [podnetwork].yaml"" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.1.100:6443 --token 1lbb8b.o2haph49cvjdc679 --discovery-token-ca-cert-hash sha256:b16ceb25ebf3b9f04e82c32310f2e98f0d755b9127cb85f225bff5cab495ee12

на мастер ноде выполним команды из строк 5-7. Таким образом мы скопируем конфигурационный файл в домашнюю директорию. Строка 19 это токен для подключения воркер узлов к мастеру.

Настраиваем воркеры

Настраиваем containerd и kubernetes также как и для мастер узла. После настройки используем наш токен из 19 строки. И затем проверяем что все наши ноды добавились и активны командой kubectl get nodes

Установка веб консоли K8S

На мастер ноде выполняем команду с помощью которой мы скачали файлик со всеми ресурсами для настройки UI

wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml

Дальше нам необходимо чтобы была возможность подключаться с нашего компьютера к кластеру через браузер. Нам нужно настроить ресурс Service. Добавляем type: NodePort и указываем любой порт nodePort в диапазоне 30000-32767.

kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 30555 selector: k8s-app: kubernetes-dashboard

После выполняем kubectl apply -f recommended.yaml В результате которого создаются все описанные в файле recommended.yaml ресурсы.

Проверяем что создалась наша служба (Service) с типом NodePort: kubectl get svc -n kubernetes-dashboard

Смотрим на какой ноде развернут наш pod для UI: kubectl get pods -o wide -n kubernetes-dashboard

В моем случае это worker2 у которого айпишник 192.168.1.52

Идем в браузер и проверяем https://192.168.1.52:30555

Теперь необходимо настроить админскую учетку. Для примера можно посмотреть тут https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md. Создадим файл sudo vi admin-user.yaml

apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard

И применим его kubectl apply -f admin-user.yaml

После создадим токен с помощью которого залогинимся в UI kubectl -n kubernetes-dashboard create token admin-user копируем его и заходим.

Готово: мы настроили свой кластер!"'https://habr.com/share/publication/719466/09b2f223cbe3c8e1b0375a3c51b3143b/'"['https://habrastorage.org/r/w1560/getpro/habr/upload_files/cc8/7b7/9fe/cc87b79fe8918f8645f7027dd6fd6756.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0f6/b67/6d6/0f6b676d666dbdfd12da67ca226805ff.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a1f/060/b6c/a1f060b6c76de5ab25b56f2b88b7ce56.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/65a/15a/b7e/65a15ab7e41c36586ede5d3819e34ef6.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/4fb/b02/c0b/4fbb02c0b686961cec5d56cd28b9d995.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/577/d10/cb8/577d10cb8709696453516a9ea076b218.png', 'https://habrastorage.org/getpro/habr/avatars/d2f/245/415/d2f24541576955e0689e6fe112c6dcb5.png', 'https://habr.com/share/publication/719466/09b2f223cbe3c8e1b0375a3c51b3143b/', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/725/422/c1f/725422c1f18690dcd62fe95b51d9d132.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/d2f/245/415/d2f24541576955e0689e6fe112c6dcb5.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ac6/2bb/aa0/ac62bbaa0f5ef69fc8ce9054fb4aaec9.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/22e/a50/175/22ea5017591bfef413e90c02b0c2fed4.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ee4/232/316/ee4232316bd11dcdd22d4770773c7425.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/df2/ee7/0b1/df2ee70b1b6270ce7bc52d65c10b295f.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/06a/7a3/ccf/06a7a3ccfa214aefaab72b8243da43b8.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/41c/477/594/41c477594e8a5034c01b206d28a2e710.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/46b/542/610/46b542610aa3d10e4bc328bffc4d75f7.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/fea/431/d0c/fea431d0c29589b25e33f87a25cdadac.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/da4/090/f51/da4090f51bfc7d812a299935b8fe8ba9.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/da5/5e2/c28/da55e2c280e2bb53769487099c11f698.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/e6a/313/238/e6a313238e167b78ab827d6b3fbbfe14.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/338/331/6e0/3383316e0dc082ec6fcf4038c116e0a9.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/1ac/2a8/652/1ac2a8652370249298bb726da4808601.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/610/50a/a8c61050a0457fa16501f62fbe157626.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/406/f41/420/406f41420824d59a1b32d878310ae596.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/2fa/43b/476/2fa43b476f7adb03b30a912f02a484e7.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/23b/4d7/455/23b4d74551541ed0336658c8cb80ecad.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/15c/539/4e3/15c5394e3ccfc60f50521e5d40e691d5.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/b94/407/8f3/b944078f3cc755dd913fddf0ed025fb1.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/d26/9bd/7e4/d269bd7e4af1cd36ec2750c1534fd0df.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/573/e44/cf7/573e44cf76e4eea5aca655e794c8d5a6.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/8e0/916/137/8e091613724be36adce64c1ebf1c2bc6.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/f51/e58/83e/f51e5883e531262538dc76b6b12e0962.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/402/51f/dc2/40251fdc2f309b6f4d3945579961621d.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/3c2/720/70e/3c272070e6242101aa16abfbdf96dcb8.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/868/974/9ab/8689749abfcb61f04adfb4efdf6e3ae7.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/aca/399/94f/aca39994f160a494a8d5913774c5baab.png']"
8'719260'Security Week 2309: безопасность голосовой биометрии'Журналисты издания Motherboard на прошлой неделе показали ( оригинальная статья , новость на Хабре) практическую атаку на систему аутентификации по голосу. Голосовую биометрию используют некоторые...'https://habr.com/ru/post/719260/'Журналисты издания Motherboard на прошлой неделе показали ( оригинальная статья новость на Хабре) практическую атаку на систему аутентификации по голосу. Голосовую биометрию используют некоторые банковские организации для идентификации клиентов, позвонивших в службу поддержки. Автор статьи Джозеф Кокс при помощи одного из сервисов генерации голосовых сообщений по образцу смог получить доступ к персональным данным собственной учетной записи в британском банке Lloyds Bank.Общение с голосовым помощником банка происходило следующим образом. Сначала автор статьи попросил его сообщить баланс на счете. Начался процесс аутентификации: Джозефу потребовалось указать дату рождения, а затем произнести фразу «мой голос — это мой пароль». После этого исследователь успешно авторизовался и мог, например, проверить список последних транзакций по счету. Все фразы в эксперименте произносил не человек: они генерировались с помощью AI-сервиса компании Eleven Labs.Эту атаку нельзя назвать принципиально новой. Еще в 2020 году у некой компании украли крупную сумму денег (35 миллионов долларов) при помощи сгенерированного голоса. Менеджеру в банке якобы позвонил клиент, гендиректор компании, которого он знал лично. Их общение перешло в электронную почту, и в итоге денежный перевод успешно отправился на счет мошенников. Эксперимент издания Motherboard показывает, что подобная атака больше не требует особой подготовки, а главное — что распространенные системы идентификации по голосу легко «взламываются» при помощи общедоступных инструментов.Хотя биометрия делает нашу жизнь проще и регулярно применяется для работы с финансами (например, для оплаты покупок телефоном после идентификации по отпечатку пальца), у нее есть фундаментальный недостаток. Если биометрические данные смогут подделать, их не получится сменить, как обычный пароль. Эксперимент показал, что для доступа к чувствительным банковским данным аутентификации по голосу явно недостаточно, а дополнительная проверка с помощью даты рождения не особо усложняет потенциальную атаку. Что касается Eleven Labs, то после ряда инцидентов, в которых ее услуги применили для создания фейковых голосовых записей от имени известных личностей, компания ввела дополнительные ограничения на использование сервиса. Что, конечно же, никак не решает фундаментальную проблему — побочный эффект развития новых технологий.Вслед за Apple компания Samsung вводит защиту от атак типа zero-click во встроенном мессенджере. Фича Samsung Message Guard доступна в смартфонах серии S23. Технических деталей не приводится, говорится только о некоем сканировании вложений (графических файлов) на наличие вредоносного кода. Предложенное в прошлом году решение такой же проблемы от Apple несколько отличается: режим Lockdown Mode урезает функциональность смартфона с целью не допустить эксплуатации новых уязвимостей.«Лаборатория Касперского» публикует отчет об эволюции мобильных угроз за 2022 год. В другой публикации описываются фишинговые атаки на пользователей Telegram с помощью поддельных веб-версий мессенджера. А в этой статье описываются эксперименты с ботом ChatGPT на тему информационной безопасности. Среди результатов: ChatGPT не смог определить известное вредоносное ПО по его хешу, но корректно распознал вредоносные процессы, когда ему показали список задач с зараженной системы.Тем временем под видом «десктопного клиента ChatGPT» в Сети распространяется вредоносное программное обеспечение.Издание Bleeping Computer рассказывает о любопытном методе идентификации читеров в игре Dota 2. Разработчик игры, компания Valve, создала «ханипот», который помог идентифицировать тех, кто использует сторонние инструменты для доступа к технической информации. Если говорить точнее, в клиенте для многопользовательской игры были размещены блоки данных, к которым честный игрок никогда не обращается. Запросы к ним фиксировались, что в итоге привело к бану 40 тысяч игроков.'https://habr.com/share/publication/719260/274f88009a06915431a7ae65b8208960/'"['https://habrastorage.org/r/w780q1/webt/nu/m5/mh/num5mhxp9iajs-qfftb2yyhculc.jpeg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w32/getpro/habr/avatars/fe4/0e2/2a9/fe40e22a957a2624684a47d3da2d924f.png', 'https://habrastorage.org/getpro/habr/company/8a6/991/272/8a69912727889ab6bdd5244d5f2e4a2c.png', 'https://habr.com/share/publication/719260/274f88009a06915431a7ae65b8208960/', 'https://habrastorage.org/getpro/habr/avatars/fe4/0e2/2a9/fe40e22a957a2624684a47d3da2d924f.png']"
9'719438'Как экспертиза в области мониторинга событий ИБ помогает создавать качественные продукты. Часть 2'Друзья, всем привет. Недавно мы анонсировали серию публикаций о детектировании атак (attack detection) и тех вызовах, c которыми сталкиваются пользователи средств защиты. В первой статье этого цикла...'https://habr.com/ru/post/719438/'"Друзья, всем привет. Недавно мы анонсировали серию публикаций о детектировании атак (attack detection) и тех вызовах, c которыми сталкиваются пользователи средств защиты. В первой статье этого цикла материалов мы уже раскрыли секреты attack detection в привязке к SIEM-решениям (системам мониторинга событий ИБ и выявления инцидентов, security information and event management) и поделились лайфхаками, как облегчить работу операторов и автоматизировать часть рутинных задач. В этом материале — подробнее о том, как механизм построения цепочек запускаемых процессов в MaxPatrol SIEM помогает выявлять атакующих в сети.

Любая интерактивная атака злоумышленников на инфраструктуру компании не обойдется без запуска каких-либо процессов независимо от операционной системы, в которой у злоумышленника появилась возможность выполнять команды. Большое количество правил корреляции для выявления TTP, то есть tactics, techniques, and procedures (тактики, техники, процедуры), атакующих в MaxPatrol SIEM основано на событиях, в которых присутствуют данные о процессе.

Во время анализа сработок правил корреляции у специалистов SOC Positive Technologies много времени уходит на «раскручивание» цепочки запускаемых процессов (последовательности запуска связанных между собой процессов), так как для принятия решения, что это — true positive или false negative, — зачастую недостаточно данных только о родителе процесса. Это было основным фактором, побудившим нас, сотрудников PT Expert Security Center (PT ESC), разработать механизм, автоматизирующий построение цепочек запускаемых процессов на основе событий безопасности Windows EID 4688, Sysmon EID 1 и событий подсистемы аудита Linux (auditd). Мы придумали механизм, обогащающий любое скоррелированное событие, в котором есть информация о процессе, его полной цепочкой и записывающий данную информацию в отдельное поле таксономии.

Рис. 1. Пример нормализованного события запуска процессов Sysmon EID 1

Рис. 2. Пример нормализованного события подсистемы аудита Linux (auditd)

Это решение позволило не только разгрузить операторов SOC за счет автоматизации задач по «раскручиванию» цепочек процессов, но и расширить возможности продукта: новое поле таксономии с данными о цепочках процессов в некоторых случаях облегчает написание правил корреляции, используется для вайтлистинга , блэклистинга , применение моделей Machine learning (ML).

По собственному опыту работы с другими продуктами этого класса и по результатам анализа их возможностей могу сказать, что я пока нигде больше не встречал реализации подобной функциональности. Некоторые производители применяют визуализацию цепочек процессов при реагировании на инциденты, используя данные от своих же EDR -решений или расширения, которые анализируют соответствующие события из базы данных и визуализируют деревья процессов при необходимости (кстати, для MaxPatrol SIEM есть подобное расширение — найти его можно вот тут (см. рис. 3)). При активации механизма в MaxPatrol SIEM цепочки процессов строятся независимо от данных EDR или дополнительных расширений в режиме реального времени и без участия человека; с этими данными можно работать как с любым другим полем таксономии. Об этом поговорим дальше.

Рис. 3. Пример расширения для браузера, строящего дерево процессов по событиям из базы данных по запросу пользователя

Анализ атомарных сработок правил корреляции

В сработках правил корреляции нам, как правило, не хватало дополнительного контекста о цепочке процессов. Задача механизма построения цепочки запускаемых процессов состоит не в их визуализации как таковой для расследования, а в записи в отдельное поле таксономии для быстрого визуального анализа прямо из карточки события или практического применения этих данных в корреляциях, обогащениях и т. д.

Наличие в карточке события данных о цепочке процессов в разы сокращает время, необходимое операторам на понимание контекста сработки даже путем визуального анализа данных. Любая сработка правила корреляции в MaxPatrol SIEM, имеющая данные о процессе (имя процесса и его PID), будет обогащаться цепочкой запускаемых процессов независимо от типа события.

Рассмотрим несколько практических примеров обнаружения различных TTP, относящихся к данному разделу.

1. Discovery. Account Discovery. Пример сработки правила корреляции на рекогносцировку активности пользователей через взломанный сервер Exchange.

Рис. 4. Сработка правила корреляции на рекогносцировку активности пользователей с механизмом построения цепочек запускаемых процессов

2. Discovery. Remote System Discovery. Пример сработки правила корреляции на рекогносцировку контроллера домена, основанного на событии запуска процесса без данных о цепочке процессов, и та же сработка правила корреляции с данными о цепочке процессов.

Рис. 5. Сработка правила корреляции на рекогносцировку контроллера домена без механизма построения цепочек запускаемых процессов

Рис. 6. Сработка правила корреляции на рекогносцировку контроллера домена с механизмом построения цепочек запускаемых процессов

3. Discovery. System Network Configuration Discovery. Пример сработки правила корреляции на рекогносцировку конфигурации сетевого подключения в операционной системе Linux с механизмом построения цепочек запускаемых процессов.

Рис. 7. Сработка правила корреляции на рекогносцировку конфигурации сетевого адаптера с механизмом построения цепочек запускаемых процессов

4. Discovery. System Network Connections Discovery. Пример сработки правила корреляции после запуска пользователем вредоносного офисного документа.

Рис. 8. Сработка правила корреляции на рекогносцировку сетевых подключений с механизмом построения цепочек запускаемых процессов

Даже квалифицированному сотруднику потребуется немало времени для нахождения вредоносного процесса, который инициировал последующую активность, и сработки правил корреляции. Однако, имея в карточке события поля с цепочкой процессов, относящиеся к конкретной сработке, оператор MaxPatrol SIEM освободит себя от необходимости выяснять это.

Написание правил корреляции на основе данных о цепочке процесса

Для того чтобы учесть в корреляции цепочку из нескольких процессов, необходимо писать минимум два правила корреляции или использовать табличный список для записи временных данных. Благодаря наличию поля таксономии с данными о цепочке процесса, оператору не нужно будет писать дополнительные правила корреляции или использовать дополнительные табличные списки.

Рис. 9. Пример фильтра события в правиле корреляции, обнаруживающего аномальные цепочки запуска процессов, родителем которых является агент антивируса Kaspersky klnagent

Рис. 10. Пример фильтра события в правиле корреляции, обнаруживающего цепочку запуска процессов с утилитами веб-сервера

В данном случае хорошими кейсами являются правила, выявляющие аномальную активность процессов веб-серверов, и правила, выявляющие целевой фишинг через мессенджеры.

Особенности механизма построения цепочек процессов

Как будет выглядеть цепочка процесса, когда пользователем был запущен файл, загруженный через мессенджер или браузер? И как она будет выглядеть до процесса, если злоумышленнику удастся мигрировать в другой процесс и продолжить свою активность в нем?

При анализе сработок правил корреляции бывают случаи, когда с первого взгляда оператор может посчитать сработку false positive, но активность является нелегитимной. Рассмотрим два сценария.

Первый сценарий. Пользователю пришло фишинговое письмо, он перешел по ссылке, скачал и запустил вредоносный файл — у злоумышленника появилась возможность выполнять команды на зараженном компьютере. В случае, если какое-либо правило корреляции сработает на последующую активность данного вредоносного процесса, то цепочка до процесса будет начинаться от процесса explorer.exe. Однако разработанный нами механизм предусматривает такой сценарий и продолжает выстраивать цепочку процесса с момента загрузки файла из браузера.

Рис. 11. Пример построения цепочки процессов

Второй сценарий. Часто после успешного «пробива» узла злоумышленнику необходимо мигрировать в другой процесс для сохранения доступа на скомпрометированном компьютере или для сокрытия следов активности за счет работы внутри легитимного процесса. В случае если такая ситуация произошла, а после этого сработало правило на какую-либо последующую активность, то в цепочке процессов будет формироваться цепочка до процесса, в который произошла миграция. Разработанный нами механизм предусматривает и такие кейсы и строит всю цепочку процессов до момента миграции.

Рис. 12. Отображение процесса, в который мигрировал злоумышленник (в фигурных скобках)

После визуального анализа только по одному полю с цепочкой процессов можно сразу сделать вывод, что компьютер пользователя был скомпрометирован.

«Тюнинг» сработок правил корреляции

Данные о цепочке процесса можно использовать при осуществлении «тюнинга» системы — вайтлистинга. Иногда целесообразнее добавить в исключение цепочку процессов, вместо того чтобы писать регулярные выражения. А в случае, если цепочка процессов является вредоносной, ее можно добавить в блэклист. Подробнее о механизмах работы с исключениями в MaxPatrol SIEM мы рассказали тут и тут.

Рис. 13. Пример шаблона исключений для данных с цепочкой процесса

Надеюсь, что данный материал был полезен и вы найдете добавленному в продукт механизму свое применение. Мы будем продолжать знакомить вас с историями о том, как наша экспертиза помогает делать продукты еще более удобными для специалистов по ИБ. Так что следите за выходом новых материалов 😊

До новых встреч!

Автор: Алексей Потапов, эксперт отдела обнаружения атак, PT Expert Security Center"'https://habrastorage.org/getpro/habr/upload_files/a7f/528/aec/a7f528aecebc76786752f6227cdcb7bc.gif'"['https://habrastorage.org/r/w32/getpro/habr/avatars/a5b/a6c/1d7/a5ba6c1d738adc618b3b066a29ace706.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/eba/7ab/b58/eba7abb58c87903dcf58569d9508058b.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/d9a/19f/ba6/d9a19fba62743c935943caf4538c345e.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/1b1/041/56b/1b104156b12c993dd157e79f194274f2.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/b5d/ac8/a87/b5dac8a87a6cc1ef6c716a54e32f3288.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/8a4/09f/aae/8a409faae7109be89543cbf7662035b6.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/a32/f34/d1e/a32f34d1e268e0b1f1557961dd0c5e37.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/81b/46a/0c0/81b46a0c0a012a1f5aea478488b33e70.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/4d4/f55/b1b/4d4f55b1bd1a4b1ee06cf4a359b93584.png', 'https://habrastorage.org/getpro/habr/upload_files/a7f/528/aec/a7f528aecebc76786752f6227cdcb7bc.gif', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/431/e69/353/431e693533573dd6a3d00ef1f3fa4a36.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/cab/a35/f9d/caba35f9d1e03e91cbc3925e657266f4.png', 'https://habrastorage.org/getpro/habr/avatars/a5b/a6c/1d7/a5ba6c1d738adc618b3b066a29ace706.png', 'https://habrastorage.org/getpro/habr/company/00b/f9c/27a/00bf9c27a7e0ab9d98f5f973a18d62fd.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c14/0f6/568/c140f65686fc40049750aff947e77193.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/29f/d4e/3b5/29fd4e3b5335a1466bf5bcff0760ff0c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/e5e/399/165/e5e399165bf75bc488132f6fe74e5bcc.png']"
10'719460'Современный способ глубокого клонирования объектов в JavaScript'Вы знали, что теперь в JavaScript есть нативный способ делать глубокие копии объектов? Это стало возможным с помощью функции structuredClone , встроенной в среду выполнения JavaScript: const...'https://habr.com/ru/post/719460/'"Вы знали, что теперь в JavaScript есть нативный способ делать глубокие копии объектов? Это стало возможным с помощью функции structuredClone , встроенной в среду выполнения JavaScript:

const calendarEvent = { title: ""Builder.io Conf"", date: new Date(123), attendees: [""Steve""] } // 😍 const copied = structuredClone(calendarEvent)

Вы заметили, что в этом примере мы скопировали не только объект, но и вложенный массив, и даже объект Date?

И код работает именно так, как мы и ожидали:

copied.attendees // [""Steve""] copied.date // Date: Wed Dec 31 1969 16:00:00 cocalendarEvent.attendees === copied.attendees // false

structuredClone может делать не только вышеперечисленное, но и также:

Клонировать бесконечно вложенные объекты и массивы.

Клонировать циклические ссылки.

Клонировать широкий спектр типов JavaScript, таких как: Date , Set , Map , Error , RegExp , ArrayBuffer , Blob , File , ImageData и многие другие .

Передавать любые передаваемые объекты .

Это безумие даже будет работать так, как мы и ожидали:

const kitchenSink = { set: new Set([1, 3, 3]), map: new Map([[1, 2]]), regex: /foo/, deep: { array: [ new File(someBlobData, 'file.txt') ] }, error: new Error('Hello!') } kitchenSink.circular = kitchenSink // ✅ Выполнено полное глубокое копирование const clonedSink = structuredClone(kitchenSink)

Почему бы просто не сделать object spread?

Важным отметить, что мы говорим о глубоком копировании. Если же нужно просто выполнить поверхностное копирование, то есть копирование без включения вложенных объектов или массивов, то можно просто выполнить spread объекта :

const simpleEvent = { title: ""Builder.io Conf"", } // ✅ нет вложенных объектов или массивов const shallowCopy = {...calendarEvent}

Или даже один из этих вариантов, если хотите:

const shallowCopy = Object.assign({}, simpleEvent) const shallowCopy = Object.create(simpleEvent)

Но как только появляются вложенные элементы, мы сталкиваемся с проблемой:

const calendarEvent = { title: ""Builder.io Conf"", date: new Date(123), attendees: [""Steve""] } const shallowCopy = {...calendarEvent} // 🚩 упс - мы добавили ""Bob"" и в копию и в воригинальное событие shallowCopy.attendees.push(""Bob"") // 🚩 упс - мы обновили дату копии и исходного события shallowCopy.date.setTime(456)

Как видно, мы не сделали полную копию этого объекта.

Вложенные дата и массив по-прежнему являются общей ссылкой для оригинала и «копии». Это может привести к проблеме – если мы захотим отредактировать их, думая, что обновляем только скопированный объект события календаря.

Почему не JSON.parse(JSON.stringify(x))?

На самом деле это отличный хак и на удивление производительный, но с некоторыми недостатками, которые устраняет structuredClone .

Возьмем для примера:

const calendarEvent = { title: ""Builder.io Conf"", date: new Date(123), attendees: [""Steve""] } // 🚩 JSON.stringify преобразовал дату в строку const problematicCopy = JSON.parse(JSON.stringify(calendarEvent))

Если вывести ProblematicCopy , мы получим:

{ title: ""Builder.io Conf"", date: ""1970-01-01T00:00:00.123Z"" attendees: [""Steve""] }

Мы хотели не этого. date должен быть не строкой, а объектом Date .

Это произошло потому, что JSON.stringify может обрабатывать только базовые объекты, массивы и примитивы. Любой другой тип может быть обработан непредсказуемым образом. Например, Dates преобразуются в string. Но Set просто преобразуется в {} .

Что-то JSON.stringify даже игнорирует – например, undefined или функции.

Скажем, если мы скопируем пример kitchenSink с помощью этого метода:

const kitchenSink = { set: new Set([1, 3, 3]), map: new Map([[1, 2]]), regex: /foo/, deep: { array: [ new File(someBlobData, 'file.txt') ] }, error: new Error('Hello!') } const veryProblematicCopy = JSON.parse(JSON.stringify(kitchenSink))

То мы получим:

{ ""set"": {}, ""map"": {}, ""regex"": {}, ""deep"": { ""array"": [ {} ] }, ""error"": {}, }

Фу!

И да, пришлось удалить циклическую ссылку, которая у нас изначально для этого была, поскольку JSON.stringify просто выдает ошибки, если встречается с одной из них.

Метод JSON.stringify удобен, в случае если наши требования соответствуют его возможностям. Однако с помощью StructuredClone можно сделать многое из того, чего не может JSON.stringify .

Почему не _.cloneDeep?

До сих пор распространенным решением этой проблемы была функция cloneDeep библиотеки Lodash.

Она действительно работает так, как ожидается:

import cloneDeep from 'lodash/cloneDeep' const calendarEvent = { title: ""Builder.io Conf"", date: new Date(123), attendees: [""Steve""] } // ✅ Все в порядке const clonedEvent = structuredClone(calendarEvent)

Но с одной оговоркой. Согласно данным работы расширения Import Cost в IDE, которое выводит вес в Кб всего, что я импортирую, эта функция занимает 17,4 Кб в сжатом виде (5,3 Кб в архиве):

Это предполагает, что вы импортируете только эту функцию. Если вместо этого импортировать более распространенным способом, не принимая в расчет, что tree shaking не всегда работает так, как ожидается, можно случайно импортировать до 25 Кб только для этой одной функции.

Хотя это и не станет концом света, в нашем случае это просто не нужно – не тогда, когда браузеры уже имеют встроенный structuredClone .

Что structuredClone не может клонировать

Функции

Иначе они вызовут исключение DataCloneError :

// 🚩 Ошибка! structuredClone({ fn: () => { } })

Узлы DOM

Также выбрасывают исключение DataCloneError :

// 🚩 Ошибка! structuredClone({ el: document.body })

Дескрипторы свойств, сеттеры и геттеры

Также не клонируются аналогичные метадата-подобные фичи.

К примеру, при использовании геттера клонируется результирующее значение, но не сама функция геттера (или любые другие метаданные свойства):

structuredClone({ get foo() { return 'bar' } }) // Становится: { foo: 'bar' }

Прототипы объектов

Не происходит обход цепочки прототипов. Поэтому в случае клонирования экземпляра MyClass клонированный объект больше не будет известен как экземпляр этого класса. Но все валидные свойства этого класса будут клонированы.

class MyClass { foo = 'bar' myMethod() { /* ... */ } } const myClass = new MyClass() const cloned = structuredClone(myClass) // Становится: { foo: 'bar' } cloned instanceof myClass // ложь

Полный список поддерживаемых типов

Все, что не входит в приведенный ниже список, клонировать нельзя:

JS Built-ins

Array , ArrayBuffer , Boolean , DataView , Date , Error types (указанные в списке ниже), Map , Object (но только простые объекты – например, из объектных литералов), примитивные типы (за исключением symbol – number , string , null , undefined , boolean , BigInt ), RegExp , Set , TypedArray

Error types (Ошибки типизации)

Error , EvalError , RangeError , ReferenceError , SyntaxError , TypeError , URIError

Web/API типы

AudioData , Blob , CryptoKey , DOMException , DOMMatrix , DOMMatrixReadOnly , DOMPoint , DomQuad , DomRect , File , FileList , FileSystemDirectoryHandle , FileSystemFileHandle , FileSystemHandle , ImageBitmap , ImageData , RTCCertificate , VideoFrame

Поддержка браузеров и сред выполнения

И здесь самое интересное – structuredClone поддерживается во всех основных браузерах, и даже в Node.js и Deno.

Правда, с одной оговоркой – поддержка Web Workers более ограничена:

Источник: MDN

Заключение

Мы долго этого ждали, и теперь у нас наконец-то есть structuredClone , благодаря которому глубокое клонирование объектов в JavaScript становится простым делом. Спасибо, Surma .

В заключение статьи приглашаем на открытое занятие «Прототипное наследование в JavaScript», которое состоится завтра вечером. На занятии мы разберемся, что такое прототипное наследование и как оно может помочь при разработке программ. В результате вы лучше поймете объектную модель Javascript и сможете писать ООП код с экономией памяти. Запись на урок открыта по ссылке."'https://habrastorage.org/getpro/habr/upload_files/7df/375/07a/7df37507a8a05df6239aa16d3f4d9fc7.png'"['https://habrastorage.org/getpro/habr/upload_files/7df/375/07a/7df37507a8a05df6239aa16d3f4d9fc7.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/403/0f5/bf1/4030f5bf1f55dbce849c4f44a4e9d1b8.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/company/2d5/0ed/b57/2d50edb57cf45fa07cc4f39f53b78395.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/d66/506/31c/d6650631c32fdf87698d68320062a544.jpeg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ff/053/30e/0ff05330e8bf583a2aaa01c3c0f7a264.png']"
11'719446'Ложь на собеседовании: ваше преимущество или риск?'Все мы с какой-то частотой ищем работу. Новая итерация — новое резюме, фокус на том, что сейчас нужно компаниям и рынку. К использованию “мы” в резюме под предлогом своего результата, кажется, уже...'https://habr.com/ru/post/719446/'"Все мы с какой-то частотой ищем работу. Новая итерация — новое резюме, фокус на том, что сейчас нужно компаниям и рынку.

К использованию “мы” в резюме под предлогом своего результата, кажется, уже привыкли все, но это было только начало. В целом, все объяснимо, если основная задача соискателя — привлечь внимание рекрутера по наличию ключевых слов или цифр в CV.

Но фантазии (читать как огромное желание найти хорошую работу) не заканчиваются в написании резюме. Ложь на собеседованиях встречается довольно часто, и не всегда она выявляется по щелчку пальцев. Заканчивая серию постов #ihateinterview, разберемся, какие лайфхаки помогают кандидатам в текущих реалиях находить работу быстрее.

Наиболее распространенные примеры лжи кандидатов при поиске работы:

1. Сменить возраст в резюме

Как правило, HR ставят фильтр по возрасту “не более 45 лет”, поэтому какой бы не был у вас опыт, ваше резюме может не появиться в поле выдачи. Зачем это делается: кто-то считает, что кандидату не хватит духа бодрости и заряженности, а все хотят видеть “горящие глаза”. Другие уверены, что кандидат просто не впишется в команду, а когда это поймет, сам покинет компанию.

Но поскольку дискриминация в любом ее виде запрещена, никто вам об этом не скажет. Тем не менее ситуация улучшается. 7-10 лет назад, цифра 40 была знаком для завершения карьеры в продуктовых командах, сейчас люди в таком возрасте делают крутые продукты и занимают ТОПовые позиции, к ним тянутся, они эксперты.

2. Сменить в резюме фамилию на “не русскую” для прохождения скрининга HR зарубежных компаний

Мы как HR можем сказать, что на уровне зарубежных компаний запрета на найм людей родом из России нет. Это только и только дополнительная подстраховка самих соискателей. Безусловно, никто не застрахован от дискриминации в любой сфере, но в текущих реалиях это не тренд, а единичные случаи.

Не путайте это с необходимым требованием наличия резидентства другой страны или территориальным нахождением человека.

3. Убрать лишний / менеджерский опыт работы в резюме

Зачастую такое решение основывается на частых отказах ввиду overqualified’а (уровня кандидата выше необходимого). Компании понимают риск того, что сотрудник может заскучать (непривычные и более легкие задачи, другой уровень влияния, на уровень ниже). Еще одна распространенная проблема — руководители не готовы брать более сильного кандидата или с идентичным уровнем из-за конкуренции. Это в корне неправильно, но очень редко, когда удается сломить психологию.

4. Добавить в резюме задачи, которых не делали сами

В ситуации, когда мастхэв требования — это 3 года коммерческой разработки и опыт работы с Angular (а не другими инструментами, фреймворками, Vue, например. При условии, что переход между ними быстрый и несложный), кандидаты добавляют в резюме необходимые данные, чтобы пройти скрининг HR. Объясняют они это тем, что задачи такого рода делали их коллеги, поэтому с легкостью смогут повторить это самостоятельно. Откуда уверенность? Они же наблюдали, кругозор появился, да и об ошибках наслышаны.

5. Добавить в резюме опыт работы / +1 грейд (на деле уровень junior, но в резюме как middle)

HR не проверяет технические навыки, а служит одним из интрументов-помощников для отсечения кандидатов, неподходящих по требованиям. Поскольку у всех критерии оценки различаются, а единого подхода к грейдированию нет, кандидаты пытаются любыми способами снова “проскочить” HR.

Так, встречаются случаи, когда при отсутствии коммерческого опыта работы, кандидаты уверенно рассказывают о 2 годах опыта работы в компании, опыте работы с конкретной задачей (например, уход от монолитной архитектуры к микросервисной), потому что именно этот опыт является основной причиной найма человека. Получается, человек похож на идеального кандидата, потому что по каждому критерию у него стоит галочка от рекрутера, и он попадает на техническое интервью к нанимающему менеджеру.

6. Добавить в резюме опыт работы менеджером (Lead)

Не все компании готовы рассматривать развитие из senior в Lead. А на рынке все еще продолжается тренд профессионального развития, а не горизонтального. Поэтому кандидаты смело приписывают опыт работы в роли руководителя, объясняя сами себе это тем, что по отдельности нет ничего сложного в выполнении базовых задач лида: декомпозиции задач, оценке сроков, коммуникации внутри команды (1to1, встречи, поддержка, развитие), найме. Рассматривают все это по отдельности, но не как комплексную роль и навык владения инструментами для решения конкретных проблем бизнеса. А если еще и за главного человек оставался, когда лид уходил в отпуск, то он точно уверен в себе и, конечно, же в коммерческом опыте управления командой.

7. Добавить в резюме опыт работы в престижной известной компании (Яндекс, например)

Некоторые работодатели в поисках специалистов высокого уровня, рассматривают кандидатов из определенных компаний, зная, что они нанимают людей исключительно с сильными навыками. Соответственно, наличие в резюме опыта работы в таких компаниях воспринимается как “кандидат senior уровня”. Таких людей хантят и идут им навстречу (предлагают уровень З.П. выше, готовы обсуждать финансовую поддержку, пакет бенефитов).

Основной риск даже не в том, что ваш новый потенциальный работодатель проверит, работали ли вы в этой компании или нет, а в том, что HR или нанимающий менеджер могут намного лучше знать специфику того же Яндекса, например, чем вы ожидаете. Если Яндекс ваше преимущество перед другими кандидатами, будьте готовы, что и разговор у вас будет строиться вокруг вашей работы в Яндексе.

8. Рассказывать о пет-проектах как о коммерческом опыте

Даже на junior позиции требуется год коммерческого опыта, как его получать, если никто не рассматривает “зеленых” кандидатов, — считают соискатели и прибегают к представленному методу.

9. На вопрос о личностных навыках или ментальном состоянии говорить о недостатках как о преимуществах

— Есть ли что-то, что может вызвать у вас негативные эмоции на работе (вспыльчивость или стресс, например?)

— Нет, ни в коем случае. Я очень стрессоустойчив и подхожу к любым вопросам с холодной головой. Люди, в ситуации, когда работа нужна здесь и сейчас, а финансовая подушка безопасности закончилась еще 3 месяца назад, отвечают так. Хотя на самом деле у человека может проявляться злость при любом совете или обратной связи в его сторону.

10. Увеличить продолжительность работы на одном месте (работал 7 месяцев, написал год)

“Работал по несколько месяцев, значит, ветряный, нестабильный. У нас долго не продержится, нет смысла рассматривать”. Так мыслит большинство. И даже не HR, а нанимающих менеджеров, которые транслируют требования HR. Действительно, частая смена работы может свидетельствовать о завышенных ожиданиях кандидата или, например, о проблемах на И.С. (сложно сработаться с командой), однако независящие от сотрудника обстоятельства встречаются еще чаще: закрыли юнит, стартап не поднял раунд, токсичное руководство, обязательных переход в офис и ваша неготовность и т.д. Что важно — писать о причинах ухода в резюме. Тогда частая смена будет воспринимать совершенно по-другому.

Какие могут быть риски при красочных рассказах?

Нанимающие менеджеры возьмут рекомендацию на вашу кандидатуру от предыдущего работодателя. Из-за фантазий это может обернуться не просто отказом, но вероятностью шеринга кейса в коммьюнити HR (история обмана + ваше ФИО и CV). В перспективе месяца-двух будет затишье с откликами. Потом — забудется. Единицы внесут в черный список, у остальных нет для этого инструмента. Не в заметках же писать :) Увольнение на И.С. или после его продления. Не всегда 3 месяца хватает, чтобы с точностью сказать, насколько эффективно работает кандидат (особенно часто это бывает у компаний с невыстроенными процессами, нехваткой ролей, отсутствием выделенных людей для онбординга новеньких и т.д.). Понижение зарплаты. Схватывать на лету получилось, но результаты все же не такие, как ожидали от человека с нужным опытом. Однако перспективы есть! Вы уйдете сами. У вас получилось неимоверно быстро улучшить навыки и знания, не допустить критичных ошибок и проявить себя как сильного специалиста. Все, казалось бы, в порядке, но работать вам самим некомфортно: задачи оказались не вашей зоной интереса / корпоративная культура вам не близка (микроменеджмент или отсутствие ролей, задачи которых распределяются на других, непривычные и неудобные для вас процессы). Вроде бы по отдельности не так критично, но в совокупности — работать сложно. Вас будет ждать выгорание. Когда человек получает то, что на самом деле ему не нужно / не хочет / не готов, вероятность выгорания быстро растет. А при условии, что путь к точке В. был нелегким, просто так отказаться от результата он не сможет, значит, будет пытаться обмануть самого себя. А время, которое потребуется, чтобы прийти в себя, прибавится ко времени, которое человек потратит на поиск работы.

Ложь дорого обходится бизнесу, усложняет и замедляет поиск. Но заключение соглашения между двумя сторонами — это процесс, когда они договариваются и отстаивают свои интересы, то есть каждый сам за себя. Не все методы в бою надо использовать, хотя бы потому что некоторые могут сильно сыграть против, но некоторые, действительно, помогут найти работу быстрее. Потому что успешность прохождения тех. интервью зависит только и только от вас.

Наше мнение насчет того, какая ложь допустима в резюме:(не является единственно верным)

Допустимо:

Сменить возраст в резюме

Сменить в резюме фамилию на “не русскую” для прохождения скрининга HR зарубежных компаний

Убрать лишний / менеджерский опыт работы в резюме

Добавить в резюме опыт работы / +1 грейд (на деле уровень junior, но в резюме как middle)

Рассказывать о пет-проектах как о коммерческом опыте (но сильно опасно, т.к. выявляется очень просто и быстро).

Увеличить продолжительность работы на одном месте (работал 7 месяцев, написал год)

Недопустимо:

Добавить в резюме задачи, которых не делали сами

Добавить в резюме опыт работы менеджером (Lead)

Добавить в резюме опыт работы в престижной известной компании (Яндекс, например)

На вопрос о личностных навыках или ментальном состоянии говорить о недостатках как о преимуществах

Почему такое распределение?

Тех. интервью проверяет ваше знания и навыки, а не количество лет карьеры.

Отсечение кандидатов по возрасту, опыту, интсрументам лишь повысят вероятность быстрее найти подходящего, но не факт, что люди, получившие отказ, не смогут пройти собеседование.

И в конце концов, задача HR и нанимающего менеджера не только проверять знания, но и выявлять ложь.

Это статья не для того, чтобы научить морали. Просто при заполнении пробелов вашего опыта оценивайте риски, задавайте вопрос сами себе: а будет ли мне комфортно в такой компании, на такой роли, с такими коллегами, руководителем и фаундером?

Как показывает практика, ложь позволит найти работу быстро, но это точно не будет вашим лучшим местом, долго вы там не задержитесь. Открытость и честность — залог успеха и комфортной рабочей атмосферы. Быстро и легко не будет, зато потом окупится. Получается, вопрос приоритетов. А судьи мы сами себе."'https://habr.com/share/publication/719446/4f4c8181eafca4f6f919a1ece6c5bde1/'"['https://habrastorage.org/getpro/habr/avatars/78f/f5e/bc9/78ff5ebc969ad9d946927060ef75db87.jpg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w32/getpro/habr/avatars/78f/f5e/bc9/78ff5ebc969ad9d946927060ef75db87.jpg', 'https://habr.com/share/publication/719446/4f4c8181eafca4f6f919a1ece6c5bde1/']"
12'715426'В Kubernetes-платформе Deckhouse появилась система виртуализации нового поколения'Привет, Хабр! Сегодня у меня для вас отличные новости. В последние несколько лет мы во «Фланте» внимательно следили за технологиями-лидерами в cloud-native. Но это вовсе не праздное любопытство: из...'https://habr.com/ru/post/715426/'"Привет, Хабр! Сегодня у меня для вас отличные новости. В последние несколько лет мы во «Фланте» внимательно следили за технологиями-лидерами в cloud-native. Но это вовсе не праздное любопытство: из них мы собрали кое-что интересное и теперь готовы представить вам. Речь о новой системе виртуализации , которая появилась в сегодняшнем релизе Deckhouse v1.43.

Для начала давайте разберемся, зачем понадобилась ещё одна система виртуализации, когда рынок наводнен ими настолько, что порой бывает сложно сориентироваться. Дело в принципиально новом подходе. Идея гиперконвергентной виртуальной инфраструктуры на базе Kubernetes не нова, однако пока на рынке нет решений которые реализовали бы эту идею в полной мере. Такие решения оставляют за собой право так или иначе отходить от некоторых принципов, которые подарил нам Kubernetes.

Выпуская платформу виртуализации, каждый производитель ориентируется прежде всего на свои нужды. Мы — не исключение, поэтому пара слов о наших целях и потребностях:

Удобный интерфейс . В первую очередь нам хотелось предоставить максимально простой и понятный интерфейс пользователям Deckhouse.

Управление из Kubernetes . Как крупнейшие K8s adopter'ы на российском рынке, мы стремились сделать управление платформой виртуализации частью оркестратора. Другими словами, платформа виртуализации должна расширять и дополнять стандартный API Kubernetes, чтобы управление виртуальными машинами было таким же простым, как управление другими рабочими нагрузками в кластере.

Максимальная производительность при минимальном потреблении ресурсов. Перед тем, как выбирать ту или иную технологию, мы проводили нагрузочное тестирование и делились его результатами с общественностью. Выбранные технологии, на наш взгляд, — лучшие из тех, что есть на рынке, и реальные тесты это доказывают.

О каких технологиях идёт речь

Kubernetes

Сегодня Kubernetes — де-факто стандарт доставки и развертывания рабочих нагрузок на production-серверах. Оно и понятно: удобный и легко расширяемый API, логика контроллеров и reconcile'а, а также новомодные DevOps-практики помогают разрабатывать приложения максимально быстро и эффективно. Kubernetes закрывает кучу проблем в области наблюдаемости (observability), обнаружения сервисов, унификации и контроля за безопасностью приложения. Не удивительно, что Kubernetes взяли в оборот и крупные вендоры, и небольшие предприятия. Он сильно упростил проектирование и управление приложениями, а также повысил стабильность их работы.

Cilium

Для сетевого взаимодействия мы решили полностью положиться на Cilium. Это мощная SDN (Software Defined Network), которая базируется на стеке eBPF — ультрабыстрой технологии в ядре Linux. Cilium может работать как распределенный сетевой балансировщик, распределенный файрвол; обеспечивает хорошую наблюдаемость (observability) и предлагает множество других полезных функций.

Наша виртуализация переиспользует возможности Cilium в полной мере. Их поддержка потребовала небольших правок в коде проекта. Жёстко завязавшись на Cilium, мы можем гарантировать исправную и стабильную работу сети и для Pod’ов, и для виртуальных машин.

У нас Cilium работает во многих кластерах; самый крупный насчитывает более 180+ узлов, 12000+ подов и 6000+ сервисов. Опыт эксплуатации, накопленный «Флантом», говорит о надежности этого решения. Cilium прекрасно справляется с ответственными задачами в production.

LINSTOR

LINSTOR — блочное SDS (Software Defined Storage). Базируется на проверенных временем технологиях и позволяет организовать надёжное хранилище для дисков виртуальных машин. Для создания томов используется менеджер логических томов LVM или ZFS, а технология DRBD обеспечивает их репликацию между физическими серверами. Модуль DRBD уже 10 лет в составе «ванильного» Linux; он зарекомендовал себя как самое быстрое отказоустойчивое решение, работающее на уровне ядра.

Хотя LINSTOR — необязательный компонент для запуска виртуальных машин, модуль виртуализации требовал надёжного и быстрого хранилища, которое бы шло в комплекте с платформой. Мы протестировали разные виды хранилищ и поняли, что LINSTOR лучше всего подходит для нужд виртуализации. На его основе мы сделали отдельный модуль Deckhouse, который можно использовать как для виртуальных машин, так и для классических контейнеров.

У меня есть опыт развертывания больших кластеров на LINSTOR на предыдущей работе. Например, в одном из проектов было 600+ серверов (часть из них — diskless), 450 NVME и 2500+ виртуальных дисков (persistent volumes).

Libvirt/QEMU

Libvirt с QEMU/KVM — стандартный стек для запуска виртуальных машин в Linux. Эту связку можно использовать как самостоятельное решение, так и в составе различных систем виртуализации.

«Флант» управляет 189 гипервизорами; на них запущено 975 виртуальных машин у 26 клиентов. Всё это работает на классическом стеке QEMU (KVM) + Libvirtd. В некоторых ситуациях используется Proxmox как управляющий слой поверх QEMU. Мы отлично разбираемся в этом стеке.

KubeVirt

KubeVirt — безусловно, самая успешная попытка принести виртуальные машины в Kubernetes. Как и «ванильный» Kubernetes, технология KubeVirt открыта для всех желающих. Это позволило нескольким крупным вендорам объединиться для решения общих задач по организации системы виртуализации на основе Kubernetes. Теперь и мы входим в их число . Совместная работа позволяет не тратить силы на разработку общей логики по запуску виртуальных машин в Kubernetes, а сконцентрироваться на фичах, уникальных для каждой платформы.

Встречайте Deckhouse Virtualization

На базе перечисленных выше технологий мы создали систему виртуализации, которая реализует наше видение гиперконвергентной инфраструктуры. При этом мы не просто скомбинировали их вместе, а постарались «выжать» максимум из каждой.

Мы также хотели сохранить интерфейс взаимодействия максимально простым для конечного пользователя. Для этого пришлось внести несколько существенных изменений. В первую очередь было решено отказаться от API «ванильного» KubeVirt из-за его чрезмерной сложности и непонятности.

Подчеркну, основная идея платформы Deckhouse — дружелюбность к пользователю. Пользователь, оперируя высокоуровневыми абстракциями, имеет доступ к ограниченной функциональности, но зато эти возможности тщательно протестированы и гарантировано работают в пределах платформы. При работе с примитивами Deckhouse пользователю не нужно задумываться о том, как они функционируют внутри. Платформа делает это за него.

Обратите внимание: наша система виртуализации — это не очередная попытка переиспользовать KubeVirt. Учитывая идеологию и более широкий стек технологий, мы позиционируем её как совершенно новый продукт на рынке виртуализации.

Почему не подошёл «ванильный» KubeVirt

Как и в случае «ванильного» Kubernetes, разработка KubeVirt ведётся без оглядки на конечных пользователей. Вендоры просто объединились для решения глобальных задач и создания общей кодовой базы, которая переиспользуется в их проектах. Примеры: OpenShift, Harvester , и теперь Deckhouse. Примитивы KubeVirt стали очень громоздкими и сложными из-за необходимости удовлетворить потребности каждого вендора.

Кроме того, KubeVirt — это довольно серьёзный проект. Чтобы принести новые функции и исправления, расширяющие логику общепринятых компонентов, нужно серьёзное обоснование и поддержка со стороны крупных игроков вроде RedHat. Текущий курс проекта — миграция на механизм CNI chaining. Это сложная задача, реализация которой займет немалое время. Поэтому некоторые из наших предложений до сих пор не попали в основную ветку проекта.

Именно несогласие с концепцией организации сети в KubeVirt и собственное видение удобного API заставили нас отделиться от основной ветки проекта и принести три важных изменения в форк.

Пытаясь «выжать» максимальную производительность из сети и при этом задействовать все возможности CNI, мы реализовали поддержку MacVTap для сети Pod'ов. Это не требует дополнительных CNI-плагинов, подключаемых через Multus. Другими словами, нам удалось достичь практически нативной производительности сети Pod'ов, но использовать её для запуска виртуальных машин. Виртуальные машины работают в той же сети, что и стандартные Pod'ы, позволяя использовать все её возможности, а именно: сетевые политики, IPAM и стандартные Kubernetes-сервисы. Виртуальная машина задействует сетевой интерфейс Pod'а напрямую, не расходуя ресурсы на маскарадинг или сетевые мосты, что отлично видно в тестах .

Другое важное изменение — live-миграция виртуальных машин с сохранением IP-адреса . KubeVirt пока не умеет мигрировать виртуальные машины, использующие адрес Pod'а на своем сетевом интерфейсе. Эта возможность доступна, только если сеть Pod’ов подключена с использованием маскарадинга. А это накладывает ограничения: сниженная производительность и необходимость в дополнительном NAT. Проблема была решена с помощью дополнительного IPAM (IP Address Management), который выдаёт IP-адреса из диапазона, отведенного для виртуальных машин. Таким образом, к pod network и service network добавилась еще и vm network. Виртуальные машины получают из нее адрес и работают как обычные Pod'ы в кластере. При этом при миграции на другой узел IP-адрес сохраняется. Еще одно изменение коснулось томов, с которыми работают виртуальные машины. Для операций с томами в KubeVirt был введён специальный ресурс DataVolume, который описывает том с конкретными данными. Мы решили заменить его на более понятные и привычные пользователю сущности: Disk и Image. Image представляет собой образ, из которого можно создать виртуальную машину. Disk описывает диск с данными, который можно физически подключить к виртуальной машине. Вся остальная логика скрыта от конечного пользователя.

Полный список сущностей можно посмотреть в документации модуля virtualization платформы Deckhouse.

Что уже готово

Модуль активно разрабатывается и дорос до публичной альфа-версии (PoC). Базовая функциональность уже доступна и ее можно опробовать:

Управление виртуальными машинами: создание, запуск, остановка, удаление.

Механизм резервации IP-адресов.

Управление дисками: копирование, импорт.

Высокая доступность как для виртуальных машин, так и для компонентов платформы.

SDN с мощными сетевыми политиками на базе Cilium.

Гибкий SDS на базе LINSTOR с поддержкой снапшотов, бэкапирования, шифрования и прочего.

Встроенный мониторинг, дашборды и алерты для системных Pod’ов и вышеперечисленных модулей.

Управление доступом на основе ролей и аутентификация на базе различных источников OAuth 2.0.

Автоматическое обновление всех компонентов платформы.

Примеры создания виртуальной машины приведены в документации модуля .

В ближайшем будущем планируется:

Улучшить механизм миграции виртуальных машин между гипервизорами.

Расширить пользовательский опыт: дополнительный CLI, мониторинг событий, документация и пр.

Сделать веб-интерфейс для управления кластером и виртуальными машинами.

Добавить поддержку VPC (virtual private cloud). Можно будет создавать отдельные изолированные VLAN'ы и подключать к ним виртуальные машины.

На всякий случай напомню, что модуль виртуализации решает исключительно задачи запуска виртуальных машин.

Сейчас у вас есть уникальная возможность повлиять на разработку. Нам очень нужны ваши мнения, идеи, советы — ведь мы хотим создать действительно полезный, удобный и жизнеспособный продукт на рынке виртуализации!

P.S.

Читайте также в нашем блоге:"'https://habrastorage.org/getpro/habr/upload_files/627/99f/3c3/62799f3c38613d1aa03a53f022af847d.png'"['https://habrastorage.org/getpro/habr/company/de7/635/363/de763536359ce6e2d2a978f8dded1964.png', 'https://habrastorage.org/getpro/habr/upload_files/627/99f/3c3/62799f3c38613d1aa03a53f022af847d.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/branding/3d4/c06/8ba/3d4c068ba151a5c21727ee9bb31f95de.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/getpro/habr/avatars/6b0/66b/bd0/6b066bbd0dd29407f3204245325adcf1.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/2bb/8d3/f6e/2bb8d3f6e5a35f9a203a4e728acd31d5.png']"
13'719444'30 фактов о доменных именах, которые вас могут слегка удивить'Привет! Меня зовут Максим Кульгин, я основатель  xmldatafeed.com  и  clickfraud.ru . Мы занимаемся парсингом сайтов и защитой от скликивания. Сейчас работаем с заказчиками в России, но...'https://habr.com/ru/post/719444/'"Привет! Меня зовут Максим Кульгин, я основатель xmldatafeed.com и clickfraud.ru. Мы занимаемся парсингом сайтов и защитой от скликивания. Сейчас работаем с заказчиками в России, но мечтаем выйти и на глобальный рынок. И для таких мечтателей как мы, подготовил довольно интересные факты по доменным именам...

Какие самые популярные доменные расширения? Какова наиболее распространенная длина доменного имени? Надеюсь, ответы на эти вопросы будут полезны тем, кто думает открыть свой бизнес в Интернете и задумался о домене. Из опыта всем советую рассматривать расширение .com, но не всегда это возможно по причинам, изложенным далее (посмотрите еще зону .dev как альтернативу).

Итак...

1. Зарегистрировано ~220 миллионов доменных имен.

Интернет растет, о чем свидетельствует тот факт, что количество доменных имен увеличилось на 13,2 миллиона или 3,9% по сравнению с прошлым годом.

zonefiles.io - под VPN открывайте

2. Каждый день регистрируется ~33 000 новых доменных имен.

Если вы не хотите заниматься подсчетами в уме, то это примерно один новый домен каждые 2,61 секунды.

3. С 76,6 миллионами доменов самым популярным регистратором доменных имен является GoDaddy.

Следующим по популярности является Namecheap с 16,5 миллионами. Вы только держите в уме, что после начало СВО Namecheap посчитал нас недостаточно достойными, чтобы продолжать работу, но достаточно достойными, чтобы не возвращать уплаченные деньги… было много на этот счет публикаций.

4. Статистика показывает, что средняя длина имени с расширением. com составляет 13,5 символов.

Однако наиболее распространенная длина — 12 символов. Если мы посмотрим на статистику доменных имен в зоне .net, то увидим, что эти сайты в среднем имеют 12,4 символа.

5. Средняя длина доменного имени пяти самых популярных сайтов составляет шесть символов.

Более короткие доменные имена, как правило, приносят больше трафика.

6. Уже существует 1 602 расширений доменных имен (TLDs, расширений или зон другими словами).

Количество TLDs постоянно растет. От первоначальных восьми общих и известных доменных зон (.com, .net, .org и т. д.) их число дошло до 1 602 из-за возросшего спроса на новые домены. Теперь у нас есть такие интересные домены, как .pizza, .ninja и.photography :) (интересные и никому особо не нужные).

7. 43% всех доменов имеют первоначальные расширения (.com, .net, .org, .gov и т.д.)

8. С 37,1% глобальной доли самым популярным расширением домена является .com.

Здесь нет никаких сюрпризов. Для большинства людей это расширение является синонимом самого Интернета.

9. Существует 160,9 миллионов доменов с расширением .com

10. Самым доверяемым доменным расширением является тоже .com

Исследование из 1500 человек, проведенное компанией Growth Badger, показало, что .com по-прежнему является наиболее доверяемым расширением домена, со средним рейтингом доверия 3,5. Второе и третье места заняли .co и .org с показателями 3,4 и 3,3 соответственно.

11. Забыв расширение у домена, люди в 3,8 раза чаще предполагают, что это .com

12. Регистрация доменных имен с новыми расширениями (зонами) обычно дороже — если .com стоит $11,99, то .build — $99,99.

Новые TDLs являются более ""брендовыми"", поскольку содержат ключевые слова, характерные для конкретной отрасли, и это может повлиять на их цену. Например, TDLs для высокоприбыльных и высококонкурентных отраслей, таких как .inc, .protection и .security, могут стоить ~2 000 долларов. Однако это относится не ко всем новым TDLs — доменные имена с такими расширениями, как .club, .online и .site, могут стоить от 10 до 25 долларов.

13. Статистика доменных имен показывает, что. surf является самым злоупотребляемым зонами

Исследование, проведенное Spamhaus, показывает, что 72,3% доменов с расширением .surf являются ""плохими"" — спамными, вредоносными и т.д.

14. 40% всех доменов имеют страновые расширения (.uk,. cn,. de и т.д.)

15. Существует 340 зон для стран (региональные зоны)

Это может звучать странно, т.к. в мире всего 195 стран (193 члена ООН и две страны-наблюдателя). Причина простая - зоны могут быть присвоены даже конкретным территориям внутри стран. Например, Французская Полинезия, Мартиника и Сектор Газа имеют свои расширения.

16. .cn — третье по популярности расширение, занимающее 4,14% от общего числа региональных зон.

17. В США зарегистрировано около 126,9 млн доменов, что составляет 19,77% от общего числа доменов в мире.

Статистика доменных имен показывает, что вторым в списке является Китай (2,84%) , а третье место занимает Канада (2,58%). В России зарегистрировано ~5.5 млн. доменов.

Данные с сайта statdom.ru

18. Доход в индустрии продаж доменных имен в США достигнет 8,6 млрд в 2023 году.

Рост на 6,1% в годовом исчислении, и рынок демонстрирует устойчивый подъем — среднегодовой рост на 3,9% за последние пять лет.

19. На Токелау, крошечной территории Новой Зеландии, проживает всего 1 411 человек, но 4,23% всех глобальных доменов имеют расширение. tk :)

Группа из трех атоллов предлагает бесплатную регистрацию доменов, что сделало ее чрезвычайно популярной среди мошенников. Если вы начинаете свой бизнес в ИТ и ищете способы сэкономить, выбор этого расширения только потому, что оно предлагает бесплатную регистрацию, — плохой из-за репутации.

20. Самым быстрорастущим страновым расширением доменов является габонский .ga

И снова мы имеем небольшую страну (2,28 млн жителей) с быстрорастущей интернет-популяцией, насчитывающей почти 9,5 млн доменов. И причины схожи — бесплатная регистрация и, как следствие, популярность среди мошенников.

21. Symbolics.com, первый в истории домен, был зарегистрирован 15 марта 1985 года.

22. К 1992 году было зарегистрировано всего около 15 000 доменных имен.

23. Средняя цена нового доменного имени составляет ~$10-$12

Цена во многом зависит от выбранного вами расширения домена, компании-регистратора, длительности регистрации и т.д.

24. Самая высокая стоимость, когда-либо заплаченная за доменное имя, составила 30 миллионов долларов.

Домен voice.com был продан в 2019 году за 30 миллионов долларов.

25. Одно из самых длинных доменных имен состоит из 64 символов

llanfairpwllgwyngyllgogerychwyrndrobwllllllantysiliogogogoch.co.uk попал в Книгу рекордов Гиннесса как самое длинное доменное имя. Это домен туристической кампании для деревни в Уэльсе. ""Очаровательное"" название переводится на английский язык как «Церковь Святой Марии в ложбине белого орешника возле стремительного водоворота и церковь Святого Тисилио из красной пещеры».

26. Регистрация домена была бесплатной до 1995 года. Да, до 1995 года вы даже могли получить домен. com бесплатно.

27. Самая частая начальная буква доменов — ""S"". Она же является и самой частой последней буквой.

Если вам интересно, наименее часто встречающаяся начальная буква — ""Q"".

28. Все трехбуквенные домены. com уже зарегистрированы. Последний был куплен в 1997 году.

29. Элон Маск заплатил ~11 миллионов долларов за домен tesla.com в 2016 году.

До 2016 года компания использовала домен teslamotors.com. По словам самого Маска, на сделку ушло более десяти лет переговоров.

30. Домен google.com был случайно продан за 12 долларов в 2015 году.

Компания заплатила порядка $12 000, чтобы выкупить его обратно, а предыдущий владелец отдал деньги на благотворительность.

Больше информации вы можете найти в моем личном Телеграм- канале «Русский ИТ бизнес» — в нем пишу всю «изнанку», с чем сталкиваемся в процессе работы, без приукрашивания. Если что-то упустил — спрашивайте в комментариях, отвечу обязательно."'https://habrastorage.org/getpro/habr/upload_files/d26/770/cbc/d26770cbc7e074f7114a05914f25241c.png'"['https://habrastorage.org/r/w32/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/d26/770/cbc/d26770cbc7e074f7114a05914f25241c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0a5/2be/4ce/0a52be4ceebfed8e18fef7b093ec3687.png', 'https://habrastorage.org/getpro/habr/company/84b/811/faa/84b811faa91bf503b4d9c3fd1fedd3dc.png', 'https://habrastorage.org/getpro/habr/upload_files/d26/770/cbc/d26770cbc7e074f7114a05914f25241c.png', 'https://habrastorage.org/getpro/habr/avatars/6a3/595/d5a/6a3595d5a310ba86011506b2ae5f62e9.jpg']"
14'719424'«Еще умнее — еще проще для пользователя»: CEO Postgres Pro Олег Бартунов о будущем СУБД, open source и астрономии'С вами директор Мегаплана Сергей Козлов. Несмотря на то что гаражная версия нашей CRM была рождена с использованием MySQL, первые пользователи пришли в систему, когда...'https://habr.com/ru/post/719424/'"С вами директор Мегаплана Сергей Козлов. Несмотря на то что гаражная версия нашей CRM была рождена с использованием MySQL, первые пользователи пришли в систему, когда она работала на PostgreSQL. Самое ценное, что у нас есть, — это данные, и мы не можем хранить их в чем‑то ненадежном, молодежно‑хипстерском, с коротким сроком жизни или раздираемом бюрократическими склоками. Мы выбрали PostgreSQL и ни разу ему не изменили. Как и он нам. Мы были очень рады, когда генеральный директор Postgres Professional, ведущий разработчик PostgreSQL Олег Бартунов согласился поговорить с нами об открытом ПО и новых вызовах, которые сейчас стоят перед разработчиками и пользователями, а еще о том, как большие данные помогают науке и в космических одиссеях. Слово Олегу Бартунову.

Олег Бартунов — сооснователь и генеральный директор российской компании-разработчика системы управления базами данных (СУБД) Postgres Professional. Ведущий разработчик (Major Contributor) PostgreSQL. Разработал для PostgreSQL поддержку интернационализации (русского и других языков), систему полнотекстового поиска, средства поддержки слабоструктурированных данных, индексные методы доступа, в том числе к пространственным данным, и многое другое. Профессиональный астроном, научный сотрудник в отделе физики эмиссионных звезд и галактик ГАИШ МГУ. Увлекается горным туризмом и легкой атлетикой, основал корпоративную команду по бегу.

Как устроен Postgres (спойлер: по законам рынка)

Наша компания Postgres Professional работает сразу в двух направлениях. Уже 8 лет мы одновременно развиваем коммерческую СУБД Postgres Pro и open source СУБД PostgreSQL с открытым исходным кодом. Когда‑то нас в этом упрекали, но история Postgres доказала, что это единственный правильный способ развивать open source решения.

Вплоть до 1994 года Postgres был академическим проектом, разработанным студентами и выпускниками университета Berkley под руководством Майкла Стоунбрейкера. В 1994 году Стоунбрейкер открыл исходные коды системы. С этого момента вокруг Postgres стало активно формироваться международное сообщество разработчиков. Сначала сообщество было совсем небольшим и состояло из энтузиастов, которые использовали систему для решения собственных задач, чаще всего научных — например, для изучения сверхновых звезд, как я. Если какой‑то функциональности не хватало, любой участник сообщества мог добавить ее самостоятельно, как принято в open source культуре. Именно так и развивалось сообщество, при этом участники не получали за эту работу ни копейки.

В 2000-х годах, по мере того как сообщество росло, вокруг Postgres стали появляться postgres‑центричные компании, которые начали предлагать свои услуги и продукты на базе этой СУБД. Они были заинтересованы в развитии системы, поэтому начали нанимать контрибьюторов open source. Появление первых крупных заказчиков в 2010-х годах сильно стимулировало этот процесс.

В итоге уже к 2015 году большинство главных разработчиков сообщества работали на крупных коммерческих игроков. С этого момента именно компании стали определять развитие Postgres: они разрабатывают новые патчи, тестируют их, внедряют в свои коммерческие решения, а затем возвращают их в open source. Сообщество, в свою очередь, поддерживает код, оценивает и принимает (или не принимает) предлагаемые компаниями патчи. Благодаря такой трансформации Postgres стал профессиональной СУБД — системой, форки которой используются для решения задач коммерческих клиентов.

Теперь Postgres развивается по законам рынка и за счет большого экспертного open source сообщества является одной из самых популярных и эффективных СУБД в мире. Что ждет Postgres дальше? Это большая интересная тема для отдельного разговора.

Не все так просто с open source

Многие считают, что open source — панацея от любых проблем, однако на деле это не так. Такое ПО действительно имеет ряд серьезных плюсов. Например, отлично подходит для образовательных целей: позволяет людям заглянуть под капот больших систем. Open source также хорош, чтобы запустить проект, протестировать его и показать миру, на что ты способен. Однако с использованием в коммерческом секторе не все так просто. Как показывает практика, open source решения опасно использовать без наличия поддержки на уровне ядра в критических системах. Серьезный энтерпрайз требует серьезного подхода: обеспечения повышенной безопасности, сертификации продукта, дополнительных фич, доработки в области производительности. Именно за это крупные коммерческие заказчики выбирают enterprise‑версии.

Демократичность сообщества — тоже палка о двух концах. С одной стороны, каждый пользователь может предложить любую доработку, получить обратную связь, подискутировать и даже прийти после обсуждений к новым интересным идеям. С другой стороны, каждый коммит требует согласия членов сообщества, а сообщество консервативно и не всегда охотно принимает новые фичи. Часто, чтобы отстоять свою позицию, требуется потратить большое количество сил и, главное, времени. При этом скорость — критичный показатель для коммерческих компаний, клиентам которых нужен быстрый результат.

Живой пример — востребованный у заказчиков Postgres Pro Enterprise патч 64-битных счетчиков транзакций, он нужен компаниям, которые совершают сотни миллионов транзакций в день. Мы успешно внедрили его и используем в enterprise‑версии, при этом в open source сообщество мы стараемся его отдать вот уже несколько лет. Все из‑за того, что каждый человек может в любой момент поднять руку и сказать: «мне не нравится эта реализация», «не думаю, что эта фича будет востребована», — и запускается новый виток дискуссий. Такие ограничения и мотивируют коммерческие компании активно развивать свои версии.

И все же сотрудничество сообщества с коммерческими компаниями — взаимовыгодный процесс, где каждый отдает и каждый приобретает. Например, сообщество замечает какие‑то баги, мы исправляем их, и наши клиенты получают более стабильную версию коммерческого продукта. В то же время сообщество получает ряд объективных улучшений, которые делают работу с продуктом еще быстрее, проще и легче.

Как будет развиваться СУБД

PostgreSQL — это мировой тренд. Как показывают графики, популярность этой СУБД растет гораздо быстрее, чем популярность Oracle, Microsoft или MySQL. Чтобы Postgres продолжил и дальше укреплять свои позиции, важно постоянно его совершенствовать. Есть два базовых направления развития, которые будут актуальны всегда: горизонтальное и вертикальное масштабирование. Горизонтальное — возможность сервера работать при увеличении количества данных. Вертикальное — стабильная работа сервера при все большем количестве запросов.

Наряду с этим очень важно упрощать систему в использовании — делать ее доступней для обывателя. Почему это важно? Информационные технологии давно стали частью жизни любого из нас, при этом количество ИТ‑экспертов (настоящих профессионалов, которые могут разобраться в «кишках» решения) снижается, и этот тренд будет все более выражен, в том числе и в СУБД. Сейчас, чтобы работать с базой данных, пользователю нужно знать массу всего. Например, Мегаплан производит продукт, который является интерфейсом между пользователем и информацией. Разработчики системы должны писать заумные многоэтажные SQL‑запросы, уметь оптимизировать их, думать о том, как сделать работу системы более устойчивой, как масштабировать сервер с ростом запросов и решать другие задачи.

В свете растущей популярности low code / no code разработки, база данных должна предъявлять минимальные требования к разработчикам приложений. В будущем СУБД должна стать такой же простой, как и телефон: управляться голосом, предугадывать дальнейшие шаги пользователя и давать подсказки.

Другая важная задача для всех СУБД — сочетать производительность и масштабируемость базы c высокой степенью защиты от компрометирования и несанкционированного доступа. Реляционные базы данных уже сейчас могут обеспечить очень высокий уровень безопасности. В частности, Postgres Pro Enterprise включает функции, обеспечивающие максимальную надежность системы и безопасность данных, благодаря чему ее активно используют даже в объектах критической инфраструктуры федеральных информационных систем. Безопасность и надежность СУБД — то, за что нас ценят наши заказчики, и мы стремимся постоянно повышать этот уровень.

Есть и перспективные направления разработки. Ими важно заниматься, чтобы компания видела новые горизонты для развития, мыслила реалиями не только сегодняшнего, но и завтрашнего дня. Для таких направлений у нас в Postgres Pro есть целая лаборатория. Многими из таких разработок мы делимся с сообществом. Например, эффективными способами работы с неструктурированными данными (JSON, JSONB), TOAST, умными методы индексирования (smart индексы) и другими.

Последнее, но не менее важное направление — создание возобновляемого кадрового резерва системных разработчиков. Развитие любой СУБД возможно только при условии достаточного количества квалифицированных специалистов. Чтобы создать такую кадровую базу, мы активно занимаемся отбором и выращиванием студентов: сотрудничаем с вузами, запускаем конкурсы, организуем стажировки, разработали программу роста молодых специалистов внутри компании. Системные разработчики — это особый тип людей, умеющих работать на перспективу и фокусировать внимание на долгосрочных задачах, результат которых может быть виден через месяцы, а то и годы. Найти или вырастить таких — непростая задача. Мы гордимся тем, что справляемся с ней, и планируем активно увеличивать штат и дальше.

Как IT-рынок пережил 2022 год

Один из постулатов open source сообщества — равные возможности для всех участников, независимо от страны проживания, политических взглядов, религии и других факторов. Конечно, определенные дискуссии были, однако PostgreSQL сообщество признает огромный вклад россиян в СУБД, поэтому санкций против нас не ввели. Мы остаемся частью международного сообщества и продолжаем работать вместе на благо open source.

В России уже появилось около десяти российских СУБД на базе, поэтому нас и правда можно назвать «родиной слонов». С одной стороны, такая конкуренция — большой плюс: она полезна для рынка, поскольку помогает развивать качество продукта, а нам как ведущей СУБД на рынке — не бронзоветь. Проблема в том, что в последнее время появились «вендоры», которые создают не новые качественные форки, а лишь модификацию ОСПО с незначительными доработками, клеят на продукт свой шильдик и пытаются продать.

Работа настоящего вендора, напротив, подразумевает серьезные изменения ядра продукта. Вдобавок она выходит далеко за рамки продажи решения. Как минимум нужно тестировать ПО на всех железных и софтверных платформах, под разные процессоры и кучу информационных систем. На нашей ферме, например, тесты запускаются каждые пять минут. Тесты и релизы под разные архитектуры позволяют найти баги. А в нашем деле они могут быть очень серьезными вплоть до утечки данных. Всего же за 2022 год мы выпустили свыше 49 000 пакетов релизов СУБД и расширений. Обладает ли всем этим набором функций новоиспеченный «вендор» — сложный вопрос. В любом случае важно десять раз подумать, прежде чем использовать малоизвестную СУБД в коммерческой компании.

Сейчас не время снимать пенки, плодить клоны и распылять силы на соперничество. Важно объединять усилия, развивать компетенции и продукт, растить качественные полезные проекты, делиться опытом и знаниями. Хорошим решением могла бы стать конференция, где разработчики смогли бы сравнить решения по гамбургскому счету: открыто рассказать про свои «ядерные» патчи, показывать тесты, бенчмарки и другое.

А какие прогнозы?

Мы пережили прошлый год довольно хорошо: с выручкой, прибылью и оборотами все в порядке, мы продолжаем активно расти. Отдельная гордость — расширение штата. За 2022-й мы набрали около 60 человек, к нам пришла группа технических специалистов из Oracle во главе с Марком Ривкиным. Это знак рынку, что наша компания — лидер, которому доверяют. Конечно, не обошлось и без потерь: некоторые сотрудники покинули Россию, но их можно пересчитать по пальцам одной руки.

Сейчас у нас важная миссия — обеспечивать технологическую состоятельность России. Если страна считает себя независимой, то у нее должен быть собственный софт, по крайней мере системное ПО. Последние 7 или 8 лет санкций — особенно недавние события — выдвинули российский Postgres в мировые лидеры по использованию в системах федерального масштаба. Больше ни в одной стране Postgres не применяется так активно, так широко и в таких больших нагрузочных системах. Среди наших клиентов — крупнейшие системы федерального уровня, которые работают 24/7.

Кроме того, сегодня российское сообщество является самым большим сообществом Postgres в мире, а мы — одна из ключевых компаний, развивающих его. Каждый год Postgres Professional отправляет в PostgreSQL больше 100 патчей — например, в выпуске PostgreSQL 15 приняло участие 27 наших сотрудников.

В будущее я смотрю с оптимизмом. Перед нами открылось окно возможностей, которое важно использовать для развития — не просто заместить ушедших конкурентов, а стать лучше. И если не будет серьезных внешних потрясений, мы с этой задачей обязательно справимся.

Как технологии помогают науке

Астрономия — наука данных, и когда их стало много (а это случилось гораздо раньше, чем в промышленности или любой другой отрасли, поскольку звезд на небе больше, чем вообще всего), мы писали свои маленькие программки по обработке и поиску данных. Тогда я обнаружил, что существует целый мир баз данных, который поможет мне в работе.

Раньше я занимался изучением сверхновых — это звезды, которые взрываются в других галактиках. Сейчас несколько раз в неделю я хожу в ГАИШ (Государственный астрономический институт им. П. К. Штернберга при МГУ), общаюсь с коллегами, помогаю, чем могу. Кстати, сотни терабайт данных хранятся у нас именно на Postgres. А некоторые постгресовые индексы небесных тел, над которыми мы работали для эффективного поиска астрономических данных, используются в астрономических проектах по всему миру.

Иногда с грустью вспоминаю, как ночами сидел с телескопом, вставлял в него огромные фотопластины, наводил вручную, делал снимки, а затем проявлял изображения. Это была романтика. Привычка смотреть на небо у меня осталась и сейчас, но в телескоп я уже давно просто так не смотрю, разве что детей удивить. Я, например, перед Новым годом внукам и детям показывал звезду на шпиле университета. Дети кричали: «Вау, какая она, оказывается, ледяная и заснеженная» — и тут же фотографировали на телефон, чтобы рассказать об этом в каком‑нибудь блоге.

Астрономы все еще ездят в обсерватории, но многие наблюдения происходят удаленно. Например, у ГАИШ по всему миру развернута сеть телескопов‑роботов «Мастер». Она автоматически сканирует небо для обнаружения новых объектов. Все это происходит прямо в базе данных в Postgres. Эдакая машина по открытию новых объектов.

Для работы астрономы пользуются Linux и Postgres. Еще нужны сервисы по обработке изображений, их сегодня разрабатывает много любителей. А научные статьи пишут в LaTeX — это популярная во всем научном мире программа, там удобно строить графики и писать формулы.

Какими бывают большие данные

Если раньше мы писали формулы и теории, а потом при помощи их объясняли открытия, то теперь наоборот: мы ищем закономерности в больших данных, идем от информации. Поэтому серьезные научные открытия сегодня происходят на стыке наук. Например, открытие тех же самых гравитационных волн было сделано при помощи больших данных.

Большие данные — вещь относительная. Никакой конкретной цифры не существует. В целом под ними можно понимать любые данные, систематизировать и обработать которые вы не можете с помощью обычных инструментов. Посмотрите на любого блогера: он генерирует кучу данных, в его телефоне десятки, а то и сотни гигабайтов изображений и видео. Если он не может обработать их с помощью подручных средств, их вполне можно считать большими данными.

Известное высказывание о больших данных принадлежит Дэну Ариели — американскому экономисту израильского происхождения

Опять же все относительно. Например, оцифрованная Библиотека конгресса в США совсем маленькая, хранить ее у себя дома может любой. Телескопы, на которых работают в Америке, могут производить несколько десятков терабайт за одну ночь. А радиотелескоп, размер которого квадратный километр, будет производить петабайты.

О космическом настоящем и будущем

На мой взгляд, одно из важнейших недавних открытий — то, что Вселенная расширяется с ускорением, этот факт имеет большое значение для судьбы Вселенной. Возможно, люди еще недопоняли значимость этого открытия, но оно действительно колоссальное.

Многие открытия ученые давно предсказывали и писали формулы на кончике пера, но совершить их удалось только сейчас. Это, например, награжденное Нобелевской премией открытие гравитационных волн и полученное учеными изображение тени черной дыры. Еще хотелось бы отметить прогресс в поиске экзопланет, то есть планет, находящихся вне Солнечной системы. Раньше мы и мечтать не могли о том, что увидим планеты у других звезд. А теперь это реальность.

Мечты о космосе и внеземные цивилизации

Когда я вижу, что очередной миллионер полетел в космос, я за него радуюсь. Ведь он заработал столько денег, чтобы исполнить свою детскую мечту. Я бы и сам туда хотел попасть, чтобы посмотреть на Землю со стороны. Мне кажется, такое желание есть у каждого человека. Очень хочется взглянуть на черный космос своими глазами, потому красивые снимки — во многом результат обработки искусственным интеллектом. Из науки мы знаем, что там очень темно и блистают звезды. Когда я хожу в горы, ощущаю схожий эффект: если поднимаешься выше и выше, небо становится все темнее.

А еще человечеству всегда хочется быть уверенным в том, что мы не одиноки во Вселенной. В детстве я мечтал увидеть кого‑то, познакомиться, получить какие‑то халявные знания. Сейчас астрономы бьются в поисках экзопланет, которые по размеру, массе и близости к своей звезде похожи на Землю. Мы интуитивно ищем на других планетах внеземную жизнь в виде нас, похожих на нас. Нам кажется, что в таких же условиях появятся такие же люди, как мы. Хотя кто его знает.

Думаю, что мы еще не доросли до того уровня, чтобы нас вообще замечали. Какой смысл какой‑то внеземной цивилизации, которая прошла все эти «болезни роста», с нами контактировать? Даже если они дадут нам какое‑то важное знание, то мы не поймем, как его применить. Или, может, они будут нас учить, как надо жить? Но ведь мы не верим даже самим себе. Так что мы сами должны пройти тот путь развития, чтобы с нами стали общаться «по‑человечески»."'https://habrastorage.org/getpro/habr/upload_files/50f/d1e/cf3/50fd1ecf3aa9a0869dd5b9ac1aac4e29.jpg'"['https://habrastorage.org/getpro/habr/upload_files/69a/a4b/303/69aa4b303d42f1ef47d590cafc947b31.JPG', 'https://habrastorage.org/getpro/habr/upload_files/50f/d1e/cf3/50fd1ecf3aa9a0869dd5b9ac1aac4e29.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/36e/431/580/36e431580a3052ec0d178f29fa343de1.png', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/50f/d1e/cf3/50fd1ecf3aa9a0869dd5b9ac1aac4e29.jpg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w32/getpro/habr/avatars/030/fd9/699/030fd96991c11c2c63e79826794c7fb4.jpg', 'https://habrastorage.org/getpro/habr/avatars/030/fd9/699/030fd96991c11c2c63e79826794c7fb4.jpg']"
15'718540'Тестирование конвейера релизов с помощью Fastlane'Пару недель назад я выступил с докладом о том, как обрести уверенность в процессе релиза, на Mobile Devops Summit , дистанционном мероприятии, организованном Bitrise ....'https://habr.com/ru/post/718540/'"Пару недель назад я выступил с докладом о том, как обрести уверенность в процессе релиза, на Mobile Devops Summit, дистанционном мероприятии, организованном Bitrise. В конце концов, я подумал, что было бы неплохо написать статью с описанием специфики выступления и мотивов, стоящих за ним.

Если вы пропустили выступление и хотели бы его посмотреть, я выложил запись на моём канале Youtube.

Мотивация

Для разработчика iOS есть определённые конвейеры CI (continuous integration — непрерывная интеграция), которые имеют решающее значение для доставки приложения, но из‑за своей природы они не запускаются часто. Отличным примером этого является конвейер релиза, который автоматизирует архивирование приложения, его подписание и отправку в App Store Connect и запускается только тогда, когда приложение готово к релизу.

Когда конвейер запускается нечасто, любые проблемы с ним останутся незамеченными и возникнут только тогда, когда конвейер понадобится в следующий раз. Хотя некоторые из этих проблем легко исправить. Вам необходимо, чтобы такие процессы проходили как можно более гладко, и, в случае конвейера релиза, получить уверенность в том, что приложение будет доставлено пользователям быстро, а не тратить время на исправление ошибок.

Давайте рассмотрим в следующих разделах две разные ошибки, которые могут произойти в день релиза и, безусловно, могут быть сложными для отладки.

Ошибки архивации

Ошибки сборки легко обнаружить, так как приложение обычно создается на CI много раз каждый день. С другой стороны, есть некоторые ошибки, характерные для архивирования приложения, процесса, который обычно происходит только тогда, когда нам требуется сгенерировать артефакт, который затем необходимо распространить.

Давайте рассмотрим модульное приложение для iOS, которое определяет iOS 15 как минимальную версию для развёртывания. Мы хотим представить новую функцию, полностью созданную с помощью SwiftUI, поэтому мы создаём новый модуль Schedule (как Swift package):

Package.swift

// swift-tools-version: 5.6 import PackageDescription let package = Package( name: ""Schedule"", products: [ .library( name: ""Schedule"", targets: [""Schedule""] ) ], dependencies: [], targets: [ .target( name: ""Schedule"", dependencies: [] ), .testTarget( name: ""ScheduleTests"", dependencies: [""Schedule""] ) ] )

Затем новый модуль импортируется целевым приложением и отображается при необходимости. Приложение можно собрать, тесты проходят нормально, новое view (представление, вью, вьюшка) выглядит великолепно, теперь приложение использует SwiftUI!

Время идет, и наступает следующий день релиза, когда пользователи с большим воодушевлением получают отзывы об этом новом view. Но как только запускается конвейер релиза, возникает ошибка, связанная с архивацией приложения:

Смотрим на журнал сборки выше: похоже, что приложение архивируется для armv7. Проблема здесь в том, что SwiftUI недоступен в SDK armv7, из‑за чего компилятор не может найти символы SwiftUI. Посмотрев на некоторые связанные ветки форума разработчиков Apple, пришёл к выводу, что если приложение имеет минимальную версию развертывания iOS 11 или выше, его не следует создавать для этой архитектуры.

Так что же происходит? Что ж, после многократных попыток исправить ошибку выясняется, что даже несмотря на то, что новый пакет импортируется target с минимальной версией развертывания iOS 15, минимальная версия iOS должна быть установлена под platforms (платформами) в Package.swift для того, чтобы ошибка исчезла:

Package.swift

// swift-tools-version: 5.6 import PackageDescription let package = Package( name: ""Schedule"", platforms: [ .iOS(.v15) ], products: [ .library( name: ""Schedule"", targets: [""Schedule""] ) ], dependencies: [], targets: [ .target( name: ""Schedule"", dependencies: [] ), .testTarget( name: ""ScheduleTests"", dependencies: [""Schedule""] ) ] )

Обратите внимание, что эта ошибка характерна для Xcode 13 и не является проблемой для Xcode 14.

Ошибки загрузки

Теперь, когда мы увидели ошибку архивирования, давайте рассмотрим пример ошибки загрузки. Давайте теперь рассмотрим, что новый модуль SwiftUI вместо этого является фреймворком (в проекте Xcode) и используется разными target. Каждый из них встраивает и подписывает фреймворк.

Приложение собирается, запускается и архивируется без проблем, но как только оно загружается в App Store Connect, возникает ошибка:

Встраивая и подписывая несколько раз, мы создаём дубликаты одного и того же пакета, что вызывает ошибку загрузки. Это связано с тем, что не может быть более одного пакета с одним и тем же идентификатором. Исправление простое, но иногда его трудно обнаружить, если вы новичок в модульных кодовых базах. Чтобы обойти эту проблему, инфраструктура должна быть встроена и подписана только один раз на уровне target приложения, а затем любой другой target, который её использует, должен отказаться от её внедрения.

Раннее обнаружение этих ошибок

Несмотря на то, что описанные выше проблемы не требовали значительных изменений кода, их диагностика и расследование, безусловно, требовали времени. И это время, на которое вы откладываете свой релиз. Это может не иметь большого значения, если ваш релиз включает только новые функции и улучшения. Но подумайте о ситуации, когда вы делаете выпуск патча, который исправляет серьёзный сбой. Вы, безусловно, хотите, чтобы ваше приложение стало доступно пользователям как можно быстрее.

Важно отметить, что эта статья не показывает, как предотвратить возникновение этих проблем, а скорее помогает обнаружить их на ранней стадии, чтобы у вас было время исправить их до следующего релиза. Проблема с тестированием конвейеров такого типа заключается в том, что они могут быть довольно громоздкими и длительными, а использование большого количества ресурсов и времени CI в рабочее время команды может привести к сбоям. Вот где запланированные запуски CI очень кстати.

Идея, стоящая за ними, заключается в том, что вы можете запланировать повторный запуск вашего конвейера в определенную дату и время, используя cron expressions. В следующих разделах я создам Github Action, которое заархивирует приложение, подпишет его для App Store, а затем проверит двоичный файл с помощью App Store Connect с помощью fastlane.

Реализация nightly Github Action

Создание nightly lane

Давайте начнём с просмотра того, как выглядит lane релиза в Fastfile:

Fastfile

lane :release do # Let's make some magic happen 🪄 gym( project: ""./NutriFit.xcodeproj"", clean: true, derived_data_path: ""./derived-data"", output_directory: ""./build"", output_name: ""NutriFit.ipa"", scheme: ""NutriFit"", export_options: { provisioningProfiles: { ""dev.polpiella.NutriFit"" => ""NutriFit App Store"", } } ) deliver( ipa: ""build/Nutrifit.ipa"" ) end

Глядя на ошибки, обнаруженные выше, новая nightly lane должна убедиться, что приложение может быть правильно заархивировано и что созданный двоичный файл может быть загружен в App Store Connect. Проблема в том, что если мы дословно продублируем код релиза, он отправит сборку в TestFlight, а это не то, что нам необходимо. Вместо этого мы должны использовать флаг доставки verify_only, чтобы сборка никогда не отправлялась, а только проверялась:

Fastfile

lane :release do # Let's make some magic happen 🪄 gym( project: ""./NutriFit.xcodeproj"", clean: true, derived_data_path: ""./derived-data"", output_directory: ""./build"", output_name: ""NutriFit.ipa"", scheme: ""NutriFit"", export_options: { provisioningProfiles: { ""dev.polpiella.NutriFit"" => ""NutriFit App Store"", } } ) deliver( ipa: ""build/Nutrifit.ipa"", verify_only: true ) end

Если вы хотите узнать больше о том, как работает флаг verify_only, вы можете взглянуть на оригинальный pull request. Я работал над внесением этого изменения в код, поэтому, если у вас есть дополнительные вопросы, не стесняйтесь, напишите мне сообщение в Twitter.

Создание nightly workflow

Теперь, когда nightly lane реализована, её необходимо запускать в определённое время каждый день. Для этого в каталоге .github/workflows создаётся новый файл Github Actions workflow с именем nightly.yml, который работает в системе с macos‑latest в качестве операционной системы и просто вызывает nightly lane в репозитории. Кроме того, в приведённом ниже действии используется тег schedule с chron expression, чтобы сообщить Github, что это действие должно выполняться каждый день в полночь:

nightly.yml

name: Nightly on: schedule: - cron: '0 0 * * *' jobs: nightly: runs-on: macos-latest steps: - uses: actions/checkout@v2 - name: Run nightly lane run: bundle exec fastlane nightly

Есть некоторые дополнительные настройки, такие как аутентификация с помощью App Store Connect, которые для простоты проигнорированы в этой статье. Если вам интересно узнать немного больше о том, как обрабатывать аутентификацию с помощью App Store Connect и fastlane, следите за этим блогом, так как я скоро напишу статью на эту тему.

Когда запланированные рабочие процессы сияют

Запланированные рабочие процессы очень удобны, когда вы хотите получить уверенность в процессах, которые очень важны, но не запускаются очень часто (например, конвейер релиза).

Они также отлично подходят для выполнения задач, требующих много времени и ресурсов (таких как сквозные тесты) с минимальными перерывами и затратами. Например, вместо того, чтобы запускать E2E‑тесты при каждой отправке на main, их можно запускать один раз вечером, проверяя все изменения, внесённые за день.

И последнее, но не менее важное: еще один отличный вариант использования запланированных запусков CI — это автоматизация повторяющихся процессов. Например, на работе у нас есть сертификат, который необходимо выпускать каждый месяц, поэтому мы создали Github Action, которое запускается в начале каждого месяца и заменяет текущий сертификат новым."'https://habr.com/share/publication/718540/48fafaa1e737cbb9df48d9bc3b1679d7/'"['https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/getpro/habr/upload_files/3dc/782/bd9/3dc782bd922e9e8377a3ab538832baf9.webp', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b7e/27b/bbd/b7e27bbbd2d1a34f1c0f6bca1d5e2f96.jpg', 'https://habr.com/share/publication/718540/48fafaa1e737cbb9df48d9bc3b1679d7/', 'https://habrastorage.org/getpro/habr/avatars/b7e/27b/bbd/b7e27bbbd2d1a34f1c0f6bca1d5e2f96.jpg', 'https://habrastorage.org/getpro/habr/upload_files/c7c/ec0/e37/c7cec0e3702e4128309540d9d8c899c0.webp']"
16'719426'Как выбрать для своего конвейера данных максимально эффективную архитектуру'Привет! Меня зовут Михаил Благов, я руководитель департамента «Чаптер инженеров данных и разработчиков» в beeline tech. В этом посте я хочу поделиться способом, с помощью которого можно выбрать...'https://habr.com/ru/post/719426/'"Привет! Меня зовут Михаил Благов, я руководитель департамента «Чаптер инженеров данных и разработчиков» в beeline tech. В этом посте я хочу поделиться способом, с помощью которого можно выбрать подходящую архитектуру для конвейера данных в зависимости от требований к нему. В частности, обсудим паттерн CDC (change data capture, aka «захват изменений»), основная идея которого — быстрая репликация какого-то источника в аналитическое хранилище.

Под катом мы:

познакомимся с вариантами архитектуры конвейеров данных: из каких компонентов и как его можно собирать,

рассмотрим и сравним четыре разные архитектуры конвейеров.

Disclaimer: серебряной пули не будет, в этой статье я поделюсь опытом выбора архитектуры для решения конкретной задачи. Аналогичный выбор для других случаев потребует дополнительных исследований и замеров производительности.

Начнем с матчасти

Помните главные отличия OLAP и OLTP ?

OLTP — Online Transaction Processing тип нагрузки на базу данных, при котором требуется быстро обрабатывать insert’ы, update’ы, delete’ы, но точечно, по одной записи. Для работы с таким типом нагрузки предназначено большинство реляционных баз данных, таких как PostgreSQL, Oracle, MsSQL и др.

OLAP — Online Analytical Processing, аналитический тип нагрузки, характеризующийся чтением значительной доли данных в таблице для формирования метрик. Это запросы вида «Я хочу посчитать количество с группировкой по чему-нибудь», «Я хочу посчитать среднее значение числовой колонки» и прочие. С такой нагрузкой плохо справляются обычные реляционные СУБД, и их обычно заменяют на колоночные СУБД, например, Clickhouse, или специальные распределённые системы хранения данных, такие как Hadoop с его специальными форматами хранения данных.

У систем хранения данных, оптимизированных под OLAP-нагрузку, есть специфика — обновления и удаления либо не работают вообще, либо работают очень медленно.

Теперь представьте себе ситуацию, когда у компании есть хорошо работающий продукт, использующий классическую OLTP базу данных. В какой-то момент руководителю компании потребуется принимать решения о его дальнейшем развитии и позиционировании. Мудрый руководитель принимает решения, основываясь на данных, и поэтому перед внедрением глобальных изменений нанимает дата-аналитика и просит проанализировать работу продукта. Возникает необходимость делать одновременно и быструю обработку транзакций, и существенную аналитику по ним (OLAP-запросы).

Что произойдёт с продуктивной базой, если впустить туда дата-аналитиков? Она будет работать медленно для обоих типов нагрузки.

Что же делать, если на проекте требуется делать одновременно и быструю обработку транзакций, и существенную аналитику по ним? А если ещё и во времени, близком к реальному? Ответ обычно следует из принципа разделения обязанностей. Пусть продуктивная база отвечает за продуктивную нагрузку, а её копия – за аналитическую. А если ещё эту копию сделать на OLAP-системе… В этот момент возникает необходимость содержать оба типа СУБД и строить конвейеры данных, эффективно перемещающие информацию из одной в другую.

Выглядит это просто:

В чем же здесь проблема? В том, как реализовать блок, отвечающий за перемещение данных, или, по-другому, репликацию. Обычно начинают с простых решений. Например, можно копировать все данные каждый день и говорить: «Окей, у нас время доставки T-1 день». Или каждый час. Тогда «свежесть» данных для аналитики уже существенно повышается. Для многих типов отчетности этого достаточно (например, для построения ежемесячных или ежеквартальных отчетов, сверок счетов и т. п.). Это вполне себе рабочий подход, если данных не очень много, а нужны они не срочно.

Но есть и недостатки. Если данных достаточно много или они должны быть достаточно «свежими», то вся эта схема перестает работать.

CDC спешит на помощь

Решить задачу можно, применяя широко известный паттерн Change Data Capture, или Захват Изменений Данных. Его смысл заключается в том, чтобы перемещать только те данные, которые изменились с момента предыдущего копирования. Способов реализации достаточно много.

Например, в исходные данные можно добавить какую-нибудь колонку типа timestamp, в котором исходная система будет сохранять дату последней модификации записи. Тогда каждый раз, копируя данные, конвейер может сохранять последнюю скопированную временную метку, а в следующий запуск оперировать только с данными младше этого времени. Это базовая реализация CDC. Она тоже подразумевает пакетную обработку раз в какой-то промежуток времени, но даже такой подход позволяет существенно сократить объём копируемых данных.

Другой способ реализации паттерна — применение изменений. Такой подход даёт возможность построить репликацию во времени, близком к реальному. Основа решения — подписка на информацию об изменениях в источнике. Далее она применяется к целевой системе. Здесь важно иметь в виду, что изменения всегда берутся с какой-то временной точки, поэтому важно написать пакетный конвейер данных, очень похожий на нативное решение по репликации, чтобы синхронизировать начальное состояние продуктивного аналитического хранилищ.

Хватит теории! Практику давай!

Рассмотрим построение аналитической системы, где в качестве продуктивной БД выступает MongoDB, а в качестве аналитической — Clickhouse.

При построении репликации требуется обеспечить семантику доставки данных “at-least-once”, при этом требуется максимизировать пропускную способность конвейера.

Захват изменений будет реализован через чтение лога операций — стандартный механизм получения оповещений об изменениях в MongoDB.

Маппинг коллекций MongoDB на таблицы Clickhouse известен и не меняется.

Дополнительно известно, что лог операций в MongoDB достаточно жёстко ограничен по объёму, что требует дополнительной буферизации изменений в промежуточном хранилище — Apache Kafka.

Выбор компонентов обусловлен уже существующим стеком проекта, поэтому примем его как данность.

Обзор возможностей компонентов

MongoDB — документо-ориентированная база, данные доступны в формате JSON, запросы к ней пишутся также в JSON. У этой системы хранения данных есть бесплатная общественная версия, а также широкая поддержка коммерческой функциональности, такой как безопасность, высокая доступность и масштабируемость.

Для репликации используется Oplog — коллекция, в которую попадают операции, произошедшие в Mongo с указанием типа изменения, например, i - insert, u - update, d - delete. Каждое сообщение в этой коллекции содержит временную метку, что делает их пригодными к потреблению паттерном «Захват изменений».

Apache Kafka — это распределённый брокер сообщений. Обладает открытым кодом, хорошо масштабируется и держит большие нагрузки.

Clickhouse — колоночная база данных с SQL-интерфейсом, в которой даже работают update’ы.

Архитектура решения

Каким образом можно реализовать конвейер данных с описанными требованиями на этих компонентах?

Первый вариант — вставка напрямую

В зависимости от типа операции в Clickhouse выполняется соответствующий запрос. i = insert, u = update, d = delete. Одной записи в Oplog соответствует один запрос, схлопывание однотипных запросов в батч не выполняется.

Одной коллекции в MongoDB соответствует одна таблицу в Clickhouse. Для репликации в этом случае можно использовать простое Java-приложение или какой-нибудь фреймворк, например, Apache Spark.

Второй вариант — Slowly Changing Dimensions (SCD) Type 2. Все операции, неважно, insert, update или delete, выполняются как insert на целевом хранилище. Каждой новой версии записи по соответствующему идентификатору присваиваем порядковый номер или timestamp обновления. Эту дополнительную колонку впоследствии можно использовать для того, чтобы выбрать последнюю версию записи или сформировать слепок на определённый момент времени.

Третий вариант — использование промежуточного кеша, поддерживающего обновления. Идея проста: не стоит обновлять данные в хранилище, которое не поддерживает операции обновления, вместо этого достаточно применить эти операции к какому-нибудь in-memory-хранилищу. Insert, update, delete работают быстро, однако раз в какое-то время будет требоваться полная перезапись в Clickhouse. Это архитектура табличного обновления.

И четвёртый подход. Если данные предполагают естественное разбиение на части, например, по времени появления в системе, то их можно регионировать, или партицировать. В таком случае при регулярном обновлении из кеша в целевое хранилище не обязательно перезаписывать всю таблицу, достаточно заменить только те партиции, которые поменялись.

В остальном, идея ровно такая же, как с табличным обновлением.

Какая архитектура выиграет? Ответ оказывается неоднозначным.

Время замерять результат

О тестовом стенде. MongoDB, Kafka и Clickhouse можно развёрнуть на виртуальных машинах в публичном облаке. Для построения графиков, приведённых в этом посте, использовались виртуальные машины с 2 CPU, 4 Gb RAM, HDD, гигабитной сетью и остальными настройками по умолчанию. Операционная система: Ubuntu 20.04.

Далее потребуется генератор данных, который позволяет совершать операции всех видов в MongoDB.

Будем записывать в MongoDB N штук изменений, где N — достаточно большое. Замерять будем общее время обработки этого количества записей, включая инициализацию и завершение, усредненную скорость (record per second, rps) и максимальную задержку появления данных в аналитической системе (t минус что-то).

Для статистической достоверности результатов запустим приложение десять раз, отбросим 2 наиболее отличающихся результата, потом посчитаем среднее значение и стандартное отклонение.

Тестовый стенд

Настройка компонентов инфраструктуры. В MongoDB придется настроить реплика-сет, состоящий из одного узла, генератор данных будем запускать в единственном экземпляре. Рассмотрение оптимизации с точки зрения параллелизма, кластерности, улучшения машин, на которых всё запускается, не входит в нашу задачу. В частности, в зависимости от всех этих параметров могут получиться совершенно иные результаты, и конкретный подход лучше выбирать на железе, аналогичном предполагаемому к использованию в продуктивной среде. В данном случае при строительстве стенда мы априорно стремимся к тому, чтобы узким местом в системе была производительность выполнения операций в Clickhouse.

Для такого теста также важно, какие данные будут проходить через систему.

Будем использовать два профиля: первый — исключительно insert’ы. На этом профиле мы не будем использовать «тяжелых» операций при записи в Clickhouse, и все архитектуры должны показать себя одинаково хорошо.

Второй профиль — 40% вставки, 40% обновлений и 20% удалений.

В реальной жизни профили зависят от того, что происходит в продуктивной базе, от специфики нагрузки, но даже базовая оценка распределения операций по типам достаточна для проведения теста.

Ось X — количество записей в батче, выполненном в MongoDB, ось Y — количество обработанных записей в секунду (rps)

Как видно из диаграммы, rps растут в зависимости от количества записей, это означает, что все реализации обладают достаточно большим overhead’ом на инициализацию. Есть способы избавиться от его влияния на результаты. Например, можно «прогреть» систему или делать замеры на постоянном потоке обновлений в MongoDB.

На первом профиле данных простая вставка в любом случае проигрывает. Проигрывает она по одной простой причине: вставка батчами всегда быстрее, чем она же по одной записи. Вставка в Clickhouse — все равно что вставка в колоночный формат, достаточно тяжелая операция.

SCD2 — просто insert’ы, они делались в данном случае батчами, batch size был достаточно большим (записи в Kafka, пришедшие за секунду), поэтому можно даже сравнить, насколько подобная оптимизация ускоряет работу пайплайна.

При табличном обновлении запись в кэш происходит быстро, но запись непосредственно в Clickhouse достаточно медленная, потому что приходится перезаписывать все данные каждый раз на каждый батч (также записи в Kafka, пришедшие за секунду). Если мы сначала все сохраним в кэш, а потом все сразу запишем в целевое хранилище, высота столбика должна получиться примерно такой же, как в SCD2.

Важно! В данном сравнительном анализе не учитывается время, которое будет затрачено на выборку конечного результата в Clickhouse. Запросы, требующие создания слепка данных в модели SCD2, конечно, будут работать медленнее, чем в других вариантах архитектур.

На втором профиле результаты другие. Столбик с простым применением существенно просел за счет того, что операции обновления и удаления существенно дольше выполняются. Остальные столбики, в принципе, остались примерно такими же, что говорит о том, что вне зависимости от профиля данных SCD2 будет работать примерно одинаково. Это даёт некую надежду на универсальность и отсутствие необходимости считать этот профиль каждый раз для каждой нагрузки.

Что в итоге

В сравнительной таблице приведены ещё несколько факторов, которые будут достаточно важными для принятия решения об использовании той или иной архитектуры:

сложность разработки,

производительность на вставку,

производительность обновления,

скорость запросов,

толерантность к горячей секции,

задержка доставки данных до источника.

У каждой архитектуры есть свой недостаток.

Выбор надо делать, исходя из того, что именно требуется максимизировать: если важна скорость доставки, то, конечно, выбор за SCD2, но для выборки актуальной версии данных потребуются запросы с оконными функциями или self-join’ы, или надо будет сделать еще один батчовый шаг по обновлению слепка данных на определённое время.

Если же важна сложность разработки, требуется быстро внедрить пайплайн для проверки какой-нибудь гипотезы, то почему бы не воспользоваться стандартным API, это достаточно быстро.

С кэшем получается и дорого, и больно, но зато сразу получается слепок, к которому можно писать запросы.

Финал

Конечно же, однозначного ответа не получилось. Серебряной пули опять не существует, а каждому гвоздю требуется свой молоток. Оказалось, что даже в сильных ограничениях на технологии, которые были введены в этом посте, есть вариативность при выборе архитектуры решения, что удалось наглядно показать, используя данные."'https://habrastorage.org/getpro/habr/upload_files/e33/456/d80/e33456d809e597624ea17edc52a2991f.png'"['https://habrastorage.org/r/w1560/getpro/habr/upload_files/fe5/15a/ad5/fe515aad50e6483f3308dae2457f0fce.png', 'https://habrastorage.org/getpro/habr/upload_files/e33/456/d80/e33456d809e597624ea17edc52a2991f.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/1af/be9/f1b/1afbe9f1b924f5ff74f20f39a9f0055f.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/fbc/008/259/fbc008259e53edea1898e459ea06e862.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/994/a1f/43f/994a1f43fb59c77fb12200a1d6230f8b.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/e86/c2f/517/e86c2f5178ccc5559036f4639d7dcce1.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/910/eed/d41/910eedd41878dbf28ca34a94651762de.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/0f1/8df/fbb/0f18dffbba76b9bd384edfab09206d85.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/824/338/9a0/8243389a09c14f2d5045d2ad6d9039ab.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/fb9/448/332/fb9448332fd09b2f9dc27d4eb02d9a58.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/54f/77e/5be/54f77e5bee10d0309a160fdc54bf8db3.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/9dc/78e/cd3/9dc78ecd382e195cfbfa38db58e5a2ee.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/51f/a06/375/51fa06375367d04716a269459aa9eb83.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/51f/86e/25f/51f86e25fd7d8531fc1f2c3c45c0dc4f.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/65a/38b/bbf/65a38bbbfcb735e8618133cfdc6e19a3.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c33/235/c06/c33235c06485641a6544eb810a416ebf.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/25e/ef6/96b/25eef696b4a45131dad6f386aa07f48a.png', 'https://habrastorage.org/getpro/habr/company/e9e/78a/75b/e9e78a75b8b034e5ebe639345bb6df4d.jpg', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/993/11e/b1c/99311eb1c77d593a6380f57615ec2209.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/7b8/888/eca/7b8888eca1864ff1798b8c8f0874a0b9.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/1a2/cfa/770/1a2cfa7704586b7f57e462cb709aa503.png', 'https://habrastorage.org/getpro/habr/avatars/65a/38b/bbf/65a38bbbfcb735e8618133cfdc6e19a3.jpg']"
17'719430'Солнечный парк Дубая'Возобновляемые источники энергии многие люди считают одним из способов уменьшения последствий изменения климата. Одним из крупнейших проектов в данной области, реализуемым в южной пустыне Дубая,...'https://habr.com/ru/post/719430/'"Возобновляемые источники энергии многие люди считают одним из способов уменьшения последствий изменения климата. Одним из крупнейших проектов в данной области, реализуемым в южной пустыне Дубая, является Солнечная электростанция Мохаммеда бин Рашида Аль Мактума.

Парк солнечных батарей, уходящих за горизонт

Солнечный парк Дубая: общая информация

Парк солнечных батарей является уникальным проектом, который реализуется на площади в 44 квадратных километра. Он оснащен миллионами фотоэлектрических панелей, преобразующих солнечный свет в электроэнергию мощностью 1000 МВт и обеспечивающих питание более 320 000 домов.

Решение о строительстве солнечного парка было объявлено Его Высочеством Мохаммедом ибн Рашидом Аль Мактумом в 2012 году. Реализацию данного проекта осуществляет Управление по электричеству и воде Дубая DEWA с привлечением частного капитала размером примерно 40 миллиардов дирхам (правовая база Дубая позволяет участие частного сектора в подобных проектах)

Этапы строительства

Первая очередь парка была введена в эксплуатацию 22 октября 2013 года, ее мощность составила 13 МВт.

Строительство второй очереди парка солнечных батарей длилось до марта 2017 года. В результате запуска 2,3 миллионов солнечных панелей стало вырабатываться 200 МВт*ч энергии.

Реализация третьей фазы проекта мощностью 800 МВт началась в 2015 году.

Строительство четвертого этапа электростанции завершилось в 2022 году. Солнечный парк в 2019 году обеспечивал 3% от общего энергоснабжения в эмирате (на данный момент - 11,4%). До запуска электростанции основным источником энергии выступал природный газ.

В ближайшие пару лет парк солнечных батарей должен завершить пятую фазу. По прогнозам специалистов, она позволить снизить выбросы углерода на 6,5 миллионов в год. В рамках данного проекта будет построена крупнейшая в мире башня концентрированной солнечной энергии. Ее высота составит 260 метров, для получения энергии будут использоваться 70 000 гелиостатов. Такая конструкция обеспечит преобразование энергии солнечного света в тепловую, а также ее хранение в течение 15 часов.

Башня будет вырабатывать 700 МВт*ч энергии, что позволит обеспечить чистой энергией более 270 000 домов и сократить объем выделяемого углекислого газа на 1,4 млн тонн в год. Ожидается, что к концу 2023 года мощность солнечного парка составит 5000 МВт.

Зачем все это

В октябре 2022 года в ОАЭ была принята стратегическая инициатива по достижению к 2050 году нулевых углеродных выбросов, что обеспечит эмират экологически чистой энергией на 100%.

Специалисты DEWA отмечают, что для достижения данной цели потребуется производить более 42 000 МВт.

Кроме того DEWA уже 5 лет подряд получает самые низкие цены в мире на солнечную энергию (Levelized Cost of Energy или LCOE). К сожалению, наиболее свежие данные нашел только за 2020 год - 13,5 у.е./МВт

Посещение парка

Где еще можно посетить электростанцию Будущего? Конечно в Дубае!

Парк солнечной энергетики в Дубае открыт для посещения, на его территории работает Центр исследований и разработок, а также Инновационный центр, одной из задач которого является повышение осведомленности населения и который можно посетить всей семьей.

Площадь здания составляет 4 355 кв. метров выставочного пространства, на котором представлено:

выставочная зона, посвященная истории развития водоснабжения и электрификации в Дубае, инновационным изобретениям в данной области

30 интерактивных экспонатов, демонстрирующих разработки в сфере возобновляемых источников энергии. ( в том числе установки для опреснения воды)

выставка компонентов фотоэлектрической солнечной энергии. Связанные с ней технологии используются в спутниках и космических кораблях, ветряных турбинах, электромобилях и зданиях, о принципах их действия рассказывают гостям центра.

Инновационный парк солнечных батарей открывает свои двери для посетителей с воскресенье по четверг, он работает с 08:30 до 14:30 часов. Забронировать посещение центра инноваций можно на официальном сайте.

Если Вам понравилась информация, интересна жизнь в Дубае, инновации и инициативы этого города - буду благодарен за подписку на мой ТГ-канал Домохозяин в Дубае . Размещаю там статьи, которые не подходят по формату на Хабр (но вписываются в VC и Дзен)"'https://habrastorage.org/getpro/habr/upload_files/ee6/690/8a7/ee66908a77e46ad3e3adb0014c03e7d0.jpg'"['https://habrastorage.org/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/getpro/habr/upload_files/ee6/690/8a7/ee66908a77e46ad3e3adb0014c03e7d0.jpg', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b92/a90/ade/b92a90ade9ca9ed89d14b9d549805e07.jpg', 'https://habrastorage.org/r/w780q1/getpro/habr/upload_files/ee6/690/8a7/ee66908a77e46ad3e3adb0014c03e7d0.jpg']"
18'719420'Instagram* сможет работать без VPN?'Авторы приложения тестируют модуль обхода блокировок в странах-цензорах Популярная социальная сеть была запрещена в России в 2022 году. Для многих поклонников приложения это стало настоящим ударом, а...'https://habr.com/ru/post/719420/'"Авторы приложения тестируют модуль обхода блокировок в странах-цензорах

Популярная социальная сеть была запрещена в России в 2022 году. Для многих поклонников приложения это стало настоящим ударом, а трафик Instagram* понес огромные потери: по данным Brand Analytics на октябрь 2022 года, количество авторов (блогеров) сократилось с 38 млн до 17 млн за год, а количество отправленных сообщений упало со 135 млн до 40 млн за тот же период. Теперь, вероятно, владельцы соцсети ищут новые способы вернуть свою аудиторию. Одним из них может стать работа Instagram* с уже встроенным модулем обхода блокировок в странах-цензорах.

Что использует Instagram*

Во время тестирования обновленной версии приложения Instagram* одним из сотрудников компании i2crm было установлено, что приложение работает в обычном режиме без использования VPN-сервиса. Для выяснения причины компания обратилась к стороннему специалисту по реверс-инжинирингу. В результате реверса мобильного приложения удалось обнаружить, что в Android-версии Instagram* 260.0.0.23.115 arm64 появился модуль Psiphon .

Что такое реверс-инжиниринг Реверс-инжиниринг (обратная разработка) — это исследование некоторого готового устройства или программы, а также документации на него, с целью понять принцип его работы.

Реверс-инжиниринг приложения: как именно был обнаружен модуль Psiphon

Сервис Psiphon имеет открытый код, который опубликован на веб-хостинге для IT-проектов GitHub. Для обнаружения модуля, прежде всего, необходимо было ознакомиться с документацией по внедрению модуля в Android-приложение:

Было установлено, что для работы модуля Psiphon на смартфоне требуется несколько условий, а именно:

Разрешения для работы с сетью в AndroidManifest.xml .

Java код.

Нативная библиотека .

Вызов java-кода Psiphon модуля из java-кода Instagram*.

Первый этап

С помощью архиватора 7-zip был открыт apk-файл Instagram*, в котором были обнаружены файлы.

Среди этих данных были интересны:

AndroidManifest.xml — он предоставляет подробную информацию о приложении;

файлы classes.dex — classes9.dex — это скомпилированный java-код;

папка lib — нативные библиотеки.

Файл AndroidManifest.xml содержит много информации о приложении, но в данной ситуации специалистов интересовали разрешения на доступ в сеть. Так как приложение Instagram* активно использует интернет-соединение, то проверку разрешений можно пропустить, сделав вывод, что условие по доступу в сеть выполняется.

Второй этап: Java-код

Далее требовалась распаковка apk-файла в декомпиляторе Bytecode-viewer . В нем был обнаружен класс модуля Psiphon .

На этом этапе Java-часть в apk-файле Instagram* была обнаружена, что подтвердило второе условие для поддержки модуля Psiphon.

Данное расширение указывало на то, что файл является скомпилированным (преобразованным) java-кодом. Чтобы понять, что внутри java-кода, специалистам потребовалось преобразовать его в исходный вид, т.е. декомпилировать. В изначальном java-коде и был обнаружен модуль для обхода блокировок Psiphon.

Третий этап: работа с нативной библиотекой

«Заглянуть» внутрь java-кода и обнаружить класс модуля Psiphon удалось с помощью Bytecode-viewer. Реверс apk-файла позволил найти dex-файлы, а при их последующей декомпиляции обнаружить класс модуля Psiphon .

Далее, чтобы понять, как обеспечивается работа модуля на Android, необходимо было найти java-метод, который загружает нативную библиотеку. Когда этот метод был найден, специалисты занялись поиском нативной библиотеки. С ее помощью нужно было установить, какая часть кода отвечает за загрузку этой библиотеки на смартфон.

Нативная библиотека для 64-разрядных arm-процессоров в репозитории располагается также в открытом доступе на GitHub здесь и имеет имя «libtun2socks.so».

Для подтверждения использования модуля специалисты исследовали java-код и обнаружили метод «startRouting()», который отвечает за загрузку нативной части модуля.

В методе «startRouting()» был обнаружен интерфейс, в который передается имя нативной библиотеки. Сам интерфейс использует системный Android api-метод « loadLibrary() ». Этот метод является кодом самого Android и отвечает за загрузку нативной библиотеки в память устройства и делает ее экспортированные функции доступными для java-кода. В свою очередь это дает возможность взаимодействия со скомпилированным С/С++ кодом из java.

Вот так выглядит та же функция в декомпилированном java-коде:

При распаковке приложения расположение библиотек в каталоге обычно выглядит так: lib\<архитектура процессора>.

Однако по данному пути libtun2socks.so обнаружить не удалось. Поэтому пришлось заглянуть assets\lib, где приложение Instagram* также может хранить нативные библиотеки.

В папке находились два файла:

libs.spo -— архив с библиотеками;

metadata.txt — перечень библиотек с указанием sha-256 хэша и размера каждого файла.

Но и в metadata.txt нативная библиотека снова не была обнаружена. Все, что было известно изначально — Instagram* при первом запуске приложения автоматически распаковывает архив libs.spo в защищенную часть памяти устройства /data/data/com.instagram.android/lib-compressed/.

Таким образом, третье условие было не выполнено (наличие нативной библиотеки libtun2socks.so ). Из первых трех условий можно сделать вывод, что использование модуля невозможно из-за отсутствия ключевой библиотеки.

Специалисты решили проверить, добавили ли разработчики только код модуля или уже начали его активное внедрение.

Вызов java-кода Psiphon-модуля из java-кода Instagram* на примере установки в Android-приложение

Чтобы понять, как именно устанавливается модуль Psiphon в Android-приложение, можно рассмотреть пример из открытых источников

Создание модуля происходит с помощью метода newPsiphonTunnel(), его код выглядит так:

Метод newPsiphonTunnelImpl() выглядит так:

При установке модуля в Android встречается еще одна нативная библиотека gojni. При реверс-инжиниринге она не была замечена. При повторном изучении репозитория был обнаружен maven aar - модуль для интеграции Psiphon в проекты Android Studio.

Далее при открытии aar-файла архиватором 7-Zip специалисты нашли искомую библиотеку и ресурсы.

На основании этого можно сделать такой вывод: для работы Psiphon модуля требуется libtun2socks.so и libgojni.so.

После проведенных установок специалисты снова вернулись к Instagram* и зафиксировали пути, где хранятся библиотеки:

/data/data/com.instagram.android/lib-compressed/

<apk>/lib/<архитектура процессора> Библиотека вновь не была обнаружена. Тогда была сделана попытка найти Instagram*- код, который ссылается на метод newPsiphonTunnel().

При этой операции был найден вызов из кода Instagram* искомого Psiphon модуля. Данное исследование с установкой модуля Psiphon в Android показало, что в целом модуль не используется полноценно, а, как и предполагалось, находится на этапе внедрения. Вероятно, этот сервис компания Meta* может использовать в дальнейшем для того, чтобы избежать блокировок Instagram* со стороны стран-цензоров.

Что представляет собой сервис Psiphon?

VPN-сервис Psiphon разработан в 2006 году в Университете Торонто. Он предназначен для обхода цензуры со стороны госрегуляторов в таких странах, как Китай и Иран. Подробно о принципах работы VPN-сервисов можно прочитать в этой статье .

Psiphon имеет сложный механизм, и его трафик почти невозможно поймать, например, через системы фильтрации DPI. Он предоставляет доступ в интернет через прокси-сервер в другой стране, а если сервер становится недоступным, то меняет его автоматически. Теперь, по-видимому, Instagram* решил «зашить» модуль обхода блокировок непосредственно в приложение, чтобы избавить пользователей от необходимости искать варианты зайти в него.

Опасен ли модуль Psiphon с точки зрения передачи данных между пользователями Instagram*? Его создатели могут видеть домены, к которым происходит доступ, но не могут видеть пользовательские данные. Это объясняется тем, что модуль — это локальный прокси-сервер, на который перенаправляется зашифрованный Instagram*-трафик. Однако для его чтения недостаточно перехвата, требуется еще расшифровка. Иными словами, модуль может получать данные в обобщенном виде и использовать, например, для настройки рекламного трафика, но не может получать историю браузера и файлов cookies.

Почему Instagram* не использует методы Telegram

Трафик Instagram* блокируется с 14 марта 2022 года интернет-провайдерами России по требованию Генпрокуратуры РФ. Приложение не может самостоятельно обходить блокировки, как это делает Telegram, используя разные IP-адреса.

Telegram для обхода блокировок использует моментальное изменение IPv4-адресов на хостингах Amazon, Google, DigitalOcean. Если заблокировать эти адреса принудительно, то неизбежно произойдет сбой в работе других сайтов и приложений, базирующихся на данных хостинга. Этот способ не используется в Китае, где перечисленные сервера заблокированы госрегулятором.

Также Telegram использует IPv6-адреса, которые регулирующие органы пока не умеют массово выявлять и блокировать. Еще одним способом защиты от возможных блокировок является возможность proxy-подключений через протоколы SOCKS5 и MTProto и ботов автоматической настройки от провайдеров услуг proxy и VPN.

Передача сообщений между пользователями Telegram осуществляется напрямую по протоколу P2P с использованием встроенного Proxy, подобного Tor. Заблокировать такой протокол возможно лишь по конечным IP-адресам пользователей, то есть фактически отключив от сети всех.

Заключение

Исследование работы модуля Psiphon в Android-версии Instagram* 260.0.0.23.115 arm64 было проведено двумя способами: с помощью реверс-инжиниринга приложения и методом вызова java-кода Instagram* на примере установки в Android-приложение. Изучение было проведено с помощью информации, полученной из открытых источников и ресурсов.

Специалисты установили, что в настоящее время модуль не используется полноценно. Скорее всего, он тестируется и в дальнейшем будет встроен в приложение для того, чтобы избежать блокировок Instagram* со стороны регуляторов в странах-цензорах.

*Meta Platforms Inc. (Facebook, Instagram) — признана экстремистской, ее деятельность запрещена на территории России."'https://habr.com/share/publication/719420/cadcf983c0786cbc54fd5147a47d4452/'"['https://habrastorage.org/r/w1560/getpro/habr/upload_files/ade/066/d51/ade066d513c8bfabc74f81e6322c16c5.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/721/4cb/4b1/7214cb4b1c588646c48e08e9ab8ba38c.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/ef7/3bd/4c2/ef73bd4c2b5719c0bdd84672297aa2e9.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/c09/5cd/488/c095cd488a23e65382232bd2131c5994.png', 'https://habrastorage.org/r/w32/getpro/habr/avatars/b8d/9ec/825/b8d9ec8256891556ae410fe23b70ca65.png', 'https://mc.yandex.ru/watch/24049213', 'https://habr.com/share/publication/719420/cadcf983c0786cbc54fd5147a47d4452/', 'https://habrastorage.org/getpro/habr/avatars/b8d/9ec/825/b8d9ec8256891556ae410fe23b70ca65.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/e00/999/afd/e00999afd62b684e78ddec1a91de4932.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/5a2/002/fcc/5a2002fccdaaeafd411df9f0b55f4504.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/aad/65c/4a7/aad65c4a7bd6e1af6454aec08db521dc.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/637/d9b/0da/637d9b0da6cadcfefc0755da304357e3.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/aa9/1cb/1c5/aa91cb1c522a344bc36db329f0d06165.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/d97/e09/99e/d97e0999ebd3791f3a3b80a3b882b985.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/979/5db/e1f/9795dbe1f33a8cea2f58ede6323e174e.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/55b/182/daf/55b182daf21da1eb20eb6240a8712f20.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/1fe/517/0d3/1fe5170d33b9e4103ef9e1361c2e79bb.png', 'https://habrastorage.org/r/w1560/getpro/habr/upload_files/d75/1e9/de9/d751e9de9cb945184e2cb50c351f6de5.png']"
19'719416'1C (и не только) c PostgreSQL'Предисловие Уже несколько лет назад я столкнулся с проблемой производительности 1С на PostgreSQL в некоторых запросах, которые на MS SQL выполнялись относительно быстро. Тогда же выяснилось, что в...'https://habr.com/ru/post/719416/'"Предисловие

Уже несколько лет назад я столкнулся с проблемой производительности 1С на PostgreSQL в некоторых запросах, которые на MS SQL выполнялись относительно быстро. Тогда же выяснилось, что в 99% случаев такие запросы можно оптимизировать так, что они начинают выполняться даже быстрее, чем на MS SQL, всего навсего добавлением нужных индексов во временные таблицы.

Решение

Тогда же было ясно, что править типовую конфигурацию совсем не хочется. Ладно еще индексы постоянных таблиц, но для добавления индексов во временные таблицы средствами 1С потребуется править код. Поэтому решено было не править конфигурацию вообще, а индексировать нужные временные таблицы на лету средствами самого PostgreSQL. Для этой цели в нем уже давно имеется такая интересная команда, как CREATE EVENT TRIGGER. В нашем случае, интересен вызов событийного триггера сразу же после создания таблицы, то есть по событию ddl_command_end.

Разберем решение в упрощенном виде. Пусть у нас создается временная таблица tmp_tmp состоящая из уникального id, и еще каких-то полей. Необходимо создать уникальный индекc по id. При этом не следует забывать, что создаваться эта временная таблица может тремя путями:

CREATE TEMP TABLE ...

CREATE TEMP TABLE AS ...

SELECT ... INTO TEMP TABLE ...

Учитывая это создаем такую функцию для создания индекса:

CREATE OR REPLACE FUNCTION build_index_on_tmp_tmp() RETURNS event_trigger LANGUAGE plpgsql AS $$ BEGIN IF EXISTS ( SELECT 1 FROM pg_event_trigger_ddl_commands() E WHERE E.object_identity='pg_temp.tmp_tmp' AND tg_tag IN ('CREATE TABLE', 'CREATE TABLE AS', 'SELECT INTO')) THEN CREATE UNIQUE INDEX IF NOT EXISTS tmp_tmp_idx ON tmp_tmp(Id); END IF; END; $$;

А вызываться эта функция будет уже из событийного триггера:

CREATE EVENT TRIGGER build_index_on_tmp_tmp_tr ON ddl_command_end EXECUTE FUNCTION build_index_on_tmp_tmp();

Теперь при создании временной таблицы tmp_tmp любым из трех перечисленных путей, таблица окажется сразу же индексирована:

DROP TABLE IF EXISTS tmp_tmp; CREATE TEMP TABLE tmp_tmp (Id int, some_text text NULL); INSERT INTO tmp_tmp(Id) SELECT generate_series(1,1000000); DROP TABLE IF EXISTS tmp_tmp; CREATE TEMP TABLE tmp_tmp AS SELECT generate_series(1,1000000) AS Id, NULL::text AS some_text; DROP TABLE IF EXISTS tmp_tmp; SELECT generate_series(1,1000000) AS Id, NULL::text AS some_text INTO TEMP TABLE tmp_tmp;

Для сравнения посмотрим на разницу без триггера и с триггером на простейшем запросе

SELECT * FROM tmp_tmp WHERE Id=500000;

С индексом получаем

Index Scan using tmp_tmp_idx on tmp_tmp (cost=0.42..2.64 rows=1 width=36) (actual time=0.030..0.031 rows=1 loops=1) Index Cond: (id = 500000) Planning Time: 0.169 ms Execution Time: 0.043 ms

Без него

Seq Scan on tmp_tmp (cost=0.00..11449.69 rows=2810 width=36) (actual time=39.425..78.025 rows=1 loops=1) Filter: (id = 500000) Rows Removed by Filter: 999999 Planning Time: 0.112 ms Execution Time: 78.045 ms

Итоги

Данный лайф-хак применим далеко не только к 1C, но и к любой другой системе, в код которой нет желания или возможности залезть. Небольшим довеском непосредственно в PostgreSQL можно решить проблемы производительности многих запросов, вынудив планировщик отправиться по индексу. Иногда это еще потребует управления статистиками, но этот вопрос уже выходит за рамки текущей статьи."'https://habrastorage.org/getpro/habr/upload_files/804/2ee/117/8042ee1176d06befa6e4ffcbc83234e5.png'"['https://habrastorage.org/getpro/habr/upload_files/804/2ee/117/8042ee1176d06befa6e4ffcbc83234e5.png', 'https://mc.yandex.ru/watch/24049213', 'https://habrastorage.org/r/w32/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg', 'https://habrastorage.org/getpro/habr/avatars/2dd/134/e0e/2dd134e0ec42315f90bd89c4eee90f46.jpg']"
